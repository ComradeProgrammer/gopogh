Started by upstream project "Build_Cross" build number 9588
originally caused by:
 GitHub pull request #6150 of commit 805f1177654a78e5b257bfb7a86bac15b7f86a25, no merge conflicts.
Running as SYSTEM
[EnvInject] - Loading node environment variables.
[EnvInject] - Preparing an environment for the build.
[EnvInject] - Keeping Jenkins system variables.
[EnvInject] - Keeping Jenkins build variables.
[EnvInject] - Evaluating the Groovy script content
[EnvInject] - Injecting contributions.
Building remotely on GCP - Linux (linux-vbox kvm linux docker gcp-linux) in workspace /home/jenkins/workspace/KVM_Linux_integration
[WS-CLEANUP] Deleting project workspace...
[WS-CLEANUP] Deferred wipeout is used...
[WS-CLEANUP] Done
[KVM_Linux_integration] $ /bin/bash -xe /tmp/jenkins7639380502719659761.sh
+ set -e
+ gsutil -m cp -r gs://minikube-builds/6150/common.sh .
Copying gs://minikube-builds/6150/common.sh...
/ [0/1 files][    0.0 B/ 12.6 KiB]   0% Done                                    
/ [1/1 files][ 12.6 KiB/ 12.6 KiB] 100% Done                                    
Operation completed over 1 objects/12.6 KiB.                                     
+ gsutil cp gs://minikube-builds/6150/linux_integration_tests_kvm.sh .
Copying gs://minikube-builds/6150/linux_integration_tests_kvm.sh...
/ [0 files][    0.0 B/  1.5 KiB]                                                
/ [1 files][  1.5 KiB/  1.5 KiB]                                                
Operation completed over 1 objects/1.5 KiB.                                      
+ sudo gsutil cp gs://minikube-builds/6150/docker-machine-driver-kvm2 /usr/local/bin/docker-machine-driver-kvm2
Copying gs://minikube-builds/6150/docker-machine-driver-kvm2...
/ [0 files][    0.0 B/ 13.8 MiB]                                                
/ [1 files][ 13.8 MiB/ 13.8 MiB]                                                
Operation completed over 1 objects/13.8 MiB.                                     
+ sudo chmod +x /usr/local/bin/docker-machine-driver-kvm2
+ bash linux_integration_tests_kvm.sh
>> Starting at Fri Jan 10 12:32:36 UTC 2020

arch:      linux-amd64
build:     6150
driver:    kvm2
job:       KVM_Linux
test home: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
sudo:      
kernel:    #1 SMP Debian 4.9.189-3+deb9u2 (2019-11-11)
uptime:     12:32:36 up 15 min,  0 users,  load average: 0.23, 0.20, 0.27
kubectl:   Client Version: v1.17.0
docker:    19.03.5
go:        go version go1.13.4 linux/amd64
virsh:     3.0.0


>> Downloading test inputs from 6150 ...
minikube version: v1.6.2
commit: 2398af5b927db422a5323487d5adbd2ebe712fa9

>> Cleaning up after previous test runs ...
/usr/bin/virsh
>> virsh VM list after clean up (should be empty):
 Id    Name                           State
----------------------------------------------------

/usr/bin/vboxmanage
VBoxHeadless: no process found
VBoxHeadless: no process found
>> VirtualBox VM list after clean up (should be empty):
>> VirtualBox interface list after clean up (should be empty):
Sending build context to Docker daemon  209.5MB

Step 1/4 : FROM ubuntu:18.04
 ---> 4c108a37151f
Step 2/4 : RUN apt-get update &&     apt-get install -y kmod gcc wget xz-utils libc6-dev bc libelf-dev bison flex openssl libssl-dev libidn2-0 sudo libcap2 &&     rm -rf /var/lib/apt/lists/*
 ---> Using cache
 ---> 57bda160448b
Step 3/4 : COPY gvisor-addon /gvisor-addon
 ---> 91892090b40a
Step 4/4 : CMD ["/gvisor-addon"]
 ---> Running in 2233058d23dc
Removing intermediate container 2233058d23dc
 ---> 9b8fba33f966
Successfully built 9b8fba33f966
Successfully tagged gcr.io/k8s-minikube/gvisor-addon:2

>> Starting out/e2e-linux-amd64 at Fri Jan 10 12:32:59 UTC 2020
++ test -f /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/testout.txt
++ touch /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/testout.txt
++ out/e2e-linux-amd64 '-minikube-start-args=--vm-driver=kvm2 ' -expected-default-driver=kvm2 -test.timeout=70m -test.v -gvisor -binary=out/minikube-linux-amd64
++ tee /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/testout.txt
=== RUN   TestDownloadOnly
=== RUN   TestDownloadOnly/group
=== RUN   TestDownloadOnly/group/v1.11.10
=== RUN   TestDownloadOnly/group/v1.17.0
=== RUN   TestDownloadOnly/group/v1.17.0#01
=== RUN   TestDownloadOnly/group/ExpectedDefaultDriver
=== RUN   TestDownloadOnly/group/DeleteAll
=== RUN   TestDownloadOnly/group/DeleteAlwaysSucceeds
--- PASS: TestDownloadOnly (79.38s)
    --- PASS: TestDownloadOnly/group (79.34s)
        --- PASS: TestDownloadOnly/group/v1.11.10 (41.41s)
            aaa_download_only_test.go:61: (dbg) Run:  out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.11.10
            aaa_download_only_test.go:61: (dbg) Done: out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.11.10: (41.410198858s)
        --- PASS: TestDownloadOnly/group/v1.17.0 (35.22s)
            aaa_download_only_test.go:63: (dbg) Run:  out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.17.0
            aaa_download_only_test.go:63: (dbg) Done: out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.17.0: (35.223217115s)
        --- PASS: TestDownloadOnly/group/v1.17.0#01 (2.57s)
            aaa_download_only_test.go:63: (dbg) Run:  out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.17.0
            aaa_download_only_test.go:63: (dbg) Done: out/minikube-linux-amd64 start --download-only -p download-20200110T123259.374978512-4968 --force --alsologtostderr --kubernetes-version=v1.17.0: (2.572789458s)
        --- PASS: TestDownloadOnly/group/ExpectedDefaultDriver (0.04s)
            aaa_download_only_test.go:101: (dbg) Run:  out/minikube-linux-amd64 profile list --output json
        --- PASS: TestDownloadOnly/group/DeleteAll (0.05s)
            aaa_download_only_test.go:128: (dbg) Run:  out/minikube-linux-amd64 delete --all
        --- PASS: TestDownloadOnly/group/DeleteAlwaysSucceeds (0.04s)
            aaa_download_only_test.go:138: (dbg) Run:  out/minikube-linux-amd64 delete -p download-20200110T123259.374978512-4968
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p download-20200110T123259.374978512-4968
=== RUN   TestOffline
=== RUN   TestOffline/group
=== RUN   TestOffline/group/docker
=== PAUSE TestOffline/group/docker
=== RUN   TestOffline/group/crio
=== PAUSE TestOffline/group/crio
=== RUN   TestOffline/group/containerd
=== PAUSE TestOffline/group/containerd
=== CONT  TestOffline/group/docker
=== CONT  TestOffline/group/containerd
=== CONT  TestOffline/group/crio
--- FAIL: TestOffline (384.19s)
    --- FAIL: TestOffline/group (0.00s)
        --- FAIL: TestOffline/group/docker (277.48s)
            helpers.go:376: No need to wait for start slot, it is already 2020-01-10 12:34:18.751953282 +0000 UTC m=+79.396972030
            aab_offline_test.go:55: (dbg) Run:  out/minikube-linux-amd64 start -p offline-docker-20200110T123418.751994578-4968 --alsologtostderr -v=1 --wait=true --container-runtime docker --vm-driver=kvm2 
            aab_offline_test.go:55: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p offline-docker-20200110T123418.751994578-4968 --alsologtostderr -v=1 --wait=true --container-runtime docker --vm-driver=kvm2 : exit status 70 (4m32.040081561s)
                -- stdout --
                ! [offline-docker-20200110T123418.751994578-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox none])
                * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
                * Found network options:
                  - HTTP_PROXY=172.16.1.1:1
                * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
                  - env HTTP_PROXY=172.16.1.1:1
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:38:46.102108    2709 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                I0110 12:34:18.784017    5502 notify.go:125] Checking for updates...
                W0110 12:34:48.784534    5502 notify.go:56] Error getting json from minikube version url: error with http GET for endpoint https://storage.googleapis.com/minikube/releases.json: Get https://storage.googleapis.com/minikube/releases.json: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:34:48.832087    5502 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1037,"bootTime":1578658651,"procs":195,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
                I0110 12:34:48.832694    5502 start.go:266] virtualization: kvm host
                I0110 12:34:48.832987    5502 start.go:567] selectDriver: flag="kvm2", old=<nil>
                I0110 12:34:48.833015    5502 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:35:52.969646    5502 global.go:68] docker priority: 2, state: {Installed:true Healthy:false Error:exit status 1 Fix:Docker is not running. Try: restarting docker desktop. Doc:}
                I0110 12:35:54.955738    5502 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:35:54.955819    5502 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:35:55.159079    5502 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:35:55.159224    5502 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
                I0110 12:35:55.159267    5502 driver.go:128] requested: "kvm2"
                I0110 12:35:55.159281    5502 driver.go:132] choosing "kvm2" because it was requested
                I0110 12:35:55.159360    5502 driver.go:147] not recommending "none" due to priority: 2
                I0110 12:35:55.159377    5502 driver.go:142] not recommending "docker" due to health: exit status 1
                I0110 12:35:55.159394    5502 driver.go:165] Picked: kvm2
                I0110 12:35:55.159410    5502 driver.go:166] Alternatives: [virtualbox none]
                I0110 12:35:55.159529    5502 start.go:298] selected driver: kvm2
                I0110 12:35:55.159538    5502 start.go:597] validating driver "kvm2" against <nil>
                I0110 12:35:55.194409    5502 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:35:55.194560    5502 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:35:55.209124    5502 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
                I0110 12:35:55.209390    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
                I0110 12:35:55.209411    5502 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "33.958Âµs"
                I0110 12:35:55.209426    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
                I0110 12:35:55.209467    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
                I0110 12:35:55.209482    5502 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "53.006Âµs"
                I0110 12:35:55.209509    5502 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
                I0110 12:35:55.209527    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
                I0110 12:35:55.209547    5502 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "43.108Âµs"
                I0110 12:35:55.209535    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
                I0110 12:35:55.209637    5502 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "128.937Âµs"
                I0110 12:35:55.209658    5502 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
                I0110 12:35:55.209559    5502 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
                I0110 12:35:55.209624    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
                I0110 12:35:55.209678    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
                I0110 12:35:55.209701    5502 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "153.994Âµs"
                I0110 12:35:55.209726    5502 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
                I0110 12:35:55.209470    5502 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "83.509Âµs"
                I0110 12:35:55.209756    5502 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
                I0110 12:35:55.209680    5502 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "142.371Âµs"
                I0110 12:35:55.209768    5502 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
                I0110 12:35:55.209527    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
                I0110 12:35:55.209778    5502 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "259.152Âµs"
                I0110 12:35:55.209793    5502 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
                I0110 12:35:55.209434    5502 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
                I0110 12:35:55.209493    5502 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-docker-20200110T123418.751994578-4968/config.json ...
                I0110 12:35:55.209491    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
                I0110 12:35:55.209863    5502 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "388.597Âµs"
                I0110 12:35:55.209879    5502 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
                I0110 12:35:55.209528    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
                I0110 12:35:55.209898    5502 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "379.631Âµs"
                I0110 12:35:55.209923    5502 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
                I0110 12:35:55.209517    5502 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
                I0110 12:35:55.209932    5502 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "449.726Âµs"
                I0110 12:35:55.209938    5502 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
                I0110 12:35:55.209944    5502 cache.go:70] Successfully saved all images to host disk.
                I0110 12:35:55.209982    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-docker-20200110T123418.751994578-4968/config.json: {Name:mk0c544cc8238b04f67ad2ce1ad2e5b253f2fa0c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:35:55.210777    5502 cluster.go:96] Machine does not exist... provisioning new machine
                I0110 12:35:55.210958    5502 cluster.go:97] Provisioning machine with config: {Name:offline-docker-20200110T123418.751994578-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[HTTP_PROXY=172.16.1.1:1] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
                I0110 12:35:55.211441    5502 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:35:55.211497    5502 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:35:55.225121    5502 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:39885
                I0110 12:35:55.225770    5502 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:35:55.226506    5502 main.go:110] libmachine: Using API Version  1
                I0110 12:35:55.226537    5502 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:35:55.226931    5502 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:35:55.227172    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetMachineName
                I0110 12:35:55.227432    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:35:55.227666    5502 main.go:110] libmachine: Creating CA: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
                I0110 12:35:55.349818    5502 main.go:110] libmachine: Creating client certificate: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
                I0110 12:35:55.565587    5502 main.go:110] libmachine: Running pre-create checks...
                I0110 12:35:55.565635    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .PreCreateCheck
                I0110 12:35:55.566219    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetConfigRaw
                I0110 12:35:55.566776    5502 main.go:110] libmachine: Creating machine...
                I0110 12:35:55.566830    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .Create
                I0110 12:35:55.567070    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Creating KVM machine...
                I0110 12:35:55.889864    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968 ...
                I0110 12:35:55.889921    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
                I0110 12:35:55.889972    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | ERROR: logging before flag.Parse: I0110 12:35:55.889774    5695 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:35:55.890102    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
                I0110 12:35:56.021800    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | ERROR: logging before flag.Parse: I0110 12:35:56.021612    5695 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968/id_rsa...
                I0110 12:35:56.264728    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | ERROR: logging before flag.Parse: I0110 12:35:56.264521    5695 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968/offline-docker-20200110T123418.751994578-4968.rawdisk...
                I0110 12:35:56.264790    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Writing magic tar header
                I0110 12:35:56.264902    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Writing SSH key tar header
                I0110 12:35:56.264968    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | ERROR: logging before flag.Parse: I0110 12:35:56.264754    5695 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968 ...
                I0110 12:35:56.265010    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968 (perms=drwx------)
                I0110 12:35:56.265064    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968
                I0110 12:35:56.265101    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
                I0110 12:35:56.265180    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
                I0110 12:35:56.265583    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:35:56.265891    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
                I0110 12:35:56.265954    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
                I0110 12:35:56.266129    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
                I0110 12:35:56.266163    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
                I0110 12:35:56.266178    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
                I0110 12:35:56.266214    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home/jenkins
                I0110 12:35:56.266256    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
                I0110 12:35:56.266267    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Checking permissions on dir: /home
                I0110 12:35:56.266297    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Skipping /home - not owner
                I0110 12:35:56.266343    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Creating domain...
                I0110 12:35:56.313161    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Creating network...
                I0110 12:35:56.316393    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Ensuring networks are active...
                I0110 12:35:56.318845    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Ensuring network default is active
                I0110 12:35:56.319257    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Ensuring network minikube-net is active
                I0110 12:35:56.319947    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Getting domain xml...
                I0110 12:35:56.322718    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Creating domain...
                I0110 12:36:01.244153    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Waiting to get IP...
                I0110 12:36:01.251453    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 0/40
                I0110 12:36:04.258943    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 1/40
                I0110 12:36:07.266596    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 2/40
                I0110 12:36:10.274091    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 3/40
                I0110 12:36:13.282054    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 4/40
                I0110 12:36:16.289737    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 5/40
                I0110 12:36:19.297067    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 6/40
                I0110 12:36:22.304969    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 7/40
                I0110 12:36:25.312043    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 8/40
                I0110 12:36:28.321148    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 9/40
                I0110 12:36:31.329770    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 10/40
                I0110 12:36:34.336973    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Waiting for machine to come up 11/40
                I0110 12:36:37.344647    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Getting to WaitForSSH function...
                I0110 12:36:37.344682    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Found IP for machine: 192.168.39.49
                I0110 12:36:37.344697    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Waiting for SSH to be available...
                I0110 12:36:37.350896    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Using SSH client type: external
                I0110 12:36:37.350937    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968/id_rsa (-rw-------)
                I0110 12:36:37.350978    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.49 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-docker-20200110T123418.751994578-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
                I0110 12:36:37.351020    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | About to run SSH command:
                I0110 12:36:37.351100    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | exit 0
                I0110 12:36:37.516305    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | SSH cmd err, output: <nil>: 
                I0110 12:36:37.516923    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) KVM machine creation complete!
                I0110 12:36:37.517080    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetConfigRaw
                I0110 12:36:37.518139    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:37.518435    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:37.518667    5502 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
                I0110 12:36:37.518686    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetState
                I0110 12:36:37.522917    5502 main.go:110] libmachine: Detecting operating system of created instance...
                I0110 12:36:37.522939    5502 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:36:37.522947    5502 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:36:37.522957    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:37.529524    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:37.529754    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.529975    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.530154    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:37.530352    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:37.530582    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:37.530601    5502 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:36:37.662182    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:36:37.662218    5502 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:36:37.662237    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:37.669902    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:37.670157    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.670374    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.670584    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:37.670860    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:37.671071    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:37.671099    5502 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:36:37.792314    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:36:37.792382    5502 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:36:37.792397    5502 main.go:110] libmachine: Provisioning with buildroot...
                I0110 12:36:37.792412    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetMachineName
                I0110 12:36:37.792780    5502 main.go:110] libmachine: setting hostname "offline-docker-20200110T123418.751994578-4968"
                I0110 12:36:37.792813    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetMachineName
                I0110 12:36:37.793103    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:37.800723    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:37.800966    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.801180    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.801422    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:37.801701    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:37.801960    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:37.801990    5502 main.go:110] libmachine: About to run SSH command:
                sudo hostname offline-docker-20200110T123418.751994578-4968 && echo "offline-docker-20200110T123418.751994578-4968" | sudo tee /etc/hostname
                I0110 12:36:37.940476    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: offline-docker-20200110T123418.751994578-4968
                
                I0110 12:36:37.940519    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:37.948304    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:37.948632    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.948874    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:37.949139    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:37.949414    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:37.949626    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:37.949673    5502 main.go:110] libmachine: About to run SSH command:
                
                		if ! grep -xq '.*\soffline-docker-20200110T123418.751994578-4968' /etc/hosts; then
                			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
                				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 offline-docker-20200110T123418.751994578-4968/g' /etc/hosts;
                			else 
                				echo '127.0.1.1 offline-docker-20200110T123418.751994578-4968' | sudo tee -a /etc/hosts; 
                			fi
                		fi
                I0110 12:36:38.074210    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:36:38.074319    5502 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
                I0110 12:36:38.074338    5502 main.go:110] libmachine: setting up certificates
                I0110 12:36:38.074355    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetMachineName
                I0110 12:36:38.074707    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetIP
                I0110 12:36:38.082369    5502 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.offline-docker-20200110T123418.751994578-4968 san=[192.168.39.49 localhost]
                I0110 12:36:38.259912    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:38.267115    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:38.267365    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.267580    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:38.351852    5502 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
                I0110 12:36:38.352336    5502 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
                I0110 12:36:38.353560    5502 ssh_runner.go:194] server-key.pem: copied 1675 bytes
                I0110 12:36:38.381031    5502 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
                I0110 12:36:38.381445    5502 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
                I0110 12:36:38.382379    5502 ssh_runner.go:194] ca.pem: copied 1038 bytes
                I0110 12:36:38.407783    5502 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
                I0110 12:36:38.408123    5502 ssh_runner.go:175] Transferring 1164 bytes to /etc/docker/server.pem
                I0110 12:36:38.408971    5502 ssh_runner.go:194] server.pem: copied 1164 bytes
                I0110 12:36:38.427241    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetMachineName
                I0110 12:36:38.427818    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:38.428061    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:38.436171    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:38.436426    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.436635    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.436814    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:38.437052    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:38.437258    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:38.437280    5502 main.go:110] libmachine: About to run SSH command:
                df --output=fstype / | tail -n 1
                I0110 12:36:38.557423    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
                
                I0110 12:36:38.557451    5502 main.go:110] libmachine: root file system type: tmpfs
                I0110 12:36:38.557761    5502 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
                I0110 12:36:38.557805    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:38.565494    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:38.565808    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.566038    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.566254    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:38.566500    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:38.566679    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:38.566764    5502 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                Environment="HTTP_PROXY=172.16.1.1:1"
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP $MAINPID
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                " | sudo tee /lib/systemd/system/docker.service
                I0110 12:36:38.693386    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                Environment=HTTP_PROXY=172.16.1.1:1
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP 
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                
                I0110 12:36:38.693427    5502 main.go:110] libmachine: setting minikube options for container-runtime
                I0110 12:36:38.694008    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:38.701978    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:38.702277    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.702500    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.702759    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:38.703005    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:38.703196    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:38.703227    5502 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /etc/sysconfig && printf %s "
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                " | sudo tee /etc/sysconfig/crio.minikube
                I0110 12:36:38.829088    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                
                I0110 12:36:38.829120    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:38.836380    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:38.836660    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.836882    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:38.837135    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:38.837367    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:38.837598    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:38.837631    5502 main.go:110] libmachine: About to run SSH command:
                sudo systemctl daemon-reload
                I0110 12:36:39.130014    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:36:39.130064    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:39.138166    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:39.138414    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:39.138664    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:39.138937    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:39.139143    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:39.139314    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:39.139333    5502 main.go:110] libmachine: About to run SSH command:
                sudo systemctl -f restart crio
                I0110 12:36:46.652837    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:36:46.652883    5502 main.go:110] libmachine: Checking connection to Docker...
                I0110 12:36:46.652904    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetURL
                I0110 12:36:46.657788    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Using libvirt version 3000000
                I0110 12:36:46.665885    5502 main.go:110] libmachine: Docker is up and running!
                I0110 12:36:46.665909    5502 main.go:110] libmachine: Reticulating splines...
                I0110 12:36:46.665919    5502 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:36:46.665927    5502 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:36:46.665937    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:46.674271    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:46.674579    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.674830    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.675029    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:46.675242    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:46.675487    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:46.675510    5502 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:36:46.802507    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:36:46.802550    5502 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:36:46.802570    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:46.811236    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:46.811449    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.811642    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.811857    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:46.812076    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:46.812279    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:46.812303    5502 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:36:46.931546    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:36:46.931644    5502 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:36:46.931669    5502 cluster.go:418] Provisioned with Buildroot 2019.02.7
                I0110 12:36:46.931690    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:46.940101    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:46.940376    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.940615    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:46.940851    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:46.941083    5502 main.go:110] libmachine: Using SSH client type: native
                I0110 12:36:46.941294    5502 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.49 22 <nil> <nil>}
                I0110 12:36:46.941312    5502 main.go:110] libmachine: About to run SSH command:
                date +%s.%N
                I0110 12:36:47.059773    5502 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578659806.935190640
                
                I0110 12:36:47.059805    5502 cluster.go:197] guest clock: 1578659806.935190640
                I0110 12:36:47.059817    5502 cluster.go:210] Guest: 2020-01-10 12:36:46.93519064 +0000 UTC Remote: 2020-01-10 12:36:46.931675413 +0000 UTC m=+148.176728024 (delta=3.515227ms)
                I0110 12:36:47.059840    5502 cluster.go:181] guest clock delta is within tolerance: 3.515227ms
                I0110 12:36:47.059865    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetConfigRaw
                I0110 12:36:47.060757    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:47.061020    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:47.061301    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:47.069637    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:47.069885    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:47.070090    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:47.103976    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetIP
                ! You appear to be using a proxy, but your NO_PROXY environment does not include the minikube IP (192.168.39.49). Please see https://minikube.sigs.k8s.io/docs/reference/networking/proxy/ for more details
                I0110 12:36:47.112166    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:47.112399    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:47.113271    5502 ssh_runner.go:102] Run: nslookup kubernetes.io
                I0110 12:36:47.167971    5502 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
                I0110 12:36:47.207650    5502 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-docker-20200110T123418.751994578-4968/config.json ...
                I0110 12:36:47.208118    5502 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
                I0110 12:36:47.220865    5502 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:36:47.230026    5502 ssh_runner.go:102] Run: sudo systemctl stop crio
                I0110 12:36:47.383938    5502 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:36:47.394309    5502 ssh_runner.go:102] Run: sudo systemctl start docker
                I0110 12:36:48.485108    5502 ssh_runner.go:142] Completed: sudo systemctl start docker: (1.090758846s)
                I0110 12:36:48.485209    5502 ssh_runner.go:102] Run: docker version --format '{{.Server.Version}}'
                I0110 12:36:48.770269    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetURL
                I0110 12:36:48.775034    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) DBG | Using libvirt version 3000000
                I0110 12:36:48.782612    5502 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:36:48.782804    5502 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                I0110 12:36:48.784903    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:36:48.785786    5502 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:36:48.785836    5502 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:36:48.799778    5502 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:39325
                I0110 12:36:48.800559    5502 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:36:48.801396    5502 main.go:110] libmachine: Using API Version  1
                I0110 12:36:48.801425    5502 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:36:48.801977    5502 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:36:48.802257    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:48.802511    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .DriverName
                I0110 12:36:48.802725    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHHostname
                I0110 12:36:48.811793    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHPort
                I0110 12:36:48.812053    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHKeyPath
                I0110 12:36:48.812325    5502 main.go:110] libmachine: (offline-docker-20200110T123418.751994578-4968) Calling .GetSSHUsername
                I0110 12:36:48.851598    5502 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
                I0110 12:36:48.851660    5502 cache_images.go:75] couldn't get a local image daemon which might be ok: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851766    5502 image.go:73] retrieving image: index.docker.io/kubernetesui/metrics-scraper:v1.0.2
                I0110 12:36:48.851818    5502 image.go:73] retrieving image: k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:36:48.851836    5502 image.go:81] daemon lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851855    5502 image.go:81] daemon lookup for k8s.gcr.io/kube-proxy:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851838    5502 image.go:73] retrieving image: gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:36:48.851848    5502 image.go:73] retrieving image: k8s.gcr.io/etcd:3.4.3-0
                I0110 12:36:48.851899    5502 image.go:81] daemon lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851791    5502 image.go:73] retrieving image: k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:36:48.851918    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.851929    5502 image.go:81] daemon lookup for k8s.gcr.io/kube-addon-manager:v9.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851923    5502 image.go:73] retrieving image: k8s.gcr.io/pause:3.1
                I0110 12:36:48.851907    5502 image.go:81] daemon lookup for k8s.gcr.io/etcd:3.4.3-0: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851946    5502 image.go:81] daemon lookup for k8s.gcr.io/pause:3.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851775    5502 image.go:73] retrieving image: k8s.gcr.io/coredns:1.6.5
                I0110 12:36:48.851881    5502 image.go:73] retrieving image: index.docker.io/kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:36:48.851963    5502 image.go:81] daemon lookup for k8s.gcr.io/coredns:1.6.5: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851934    5502 image.go:73] retrieving image: k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:36:48.851961    5502 image.go:73] retrieving image: k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:36:48.851995    5502 image.go:81] daemon lookup for k8s.gcr.io/kube-scheduler:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851969    5502 image.go:81] daemon lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.851939    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.851962    5502 image.go:73] retrieving image: k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:36:48.852383    5502 image.go:81] daemon lookup for k8s.gcr.io/kube-apiserver:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.852417    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.852446    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.852584    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.852611    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.851979    5502 image.go:81] daemon lookup for k8s.gcr.io/kube-controller-manager:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:36:48.852746    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.852839    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.852952    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.852974    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853052    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853071    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853119    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853156    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853175    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853241    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853344    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853380    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853465    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853503    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:36:48.853547    5502 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:36:48.853576    5502 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                W0110 12:37:18.852506    5502 image.go:89] authn lookup for k8s.gcr.io/kube-proxy:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.852665    5502 image.go:89] authn lookup for k8s.gcr.io/kube-apiserver:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.852850    5502 image.go:89] authn lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1 (trying anon): Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853089    5502 image.go:89] authn lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853207    5502 image.go:89] authn lookup for k8s.gcr.io/kube-addon-manager:v9.0.2 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853322    5502 image.go:89] authn lookup for k8s.gcr.io/etcd:3.4.3-0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853454    5502 image.go:89] authn lookup for k8s.gcr.io/kube-controller-manager:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853525    5502 image.go:89] authn lookup for k8s.gcr.io/pause:3.1 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853606    5502 image.go:89] authn lookup for k8s.gcr.io/coredns:1.6.5 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853684    5502 image.go:89] authn lookup for k8s.gcr.io/kube-scheduler:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:37:18.853781    5502 image.go:89] authn lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:37:48.853023    5502 image.go:60] error retrieve Image k8s.gcr.io/kube-apiserver:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853072    5502 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:37:48.853078    5502 image.go:60] error retrieve Image gcr.io/k8s-minikube/storage-provisioner:v1.8.1 ref Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853107    5502 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: got empty img digest "" for gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:37:48.853123    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
                I0110 12:37:48.853090    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
                I0110 12:37:48.853022    5502 image.go:60] error retrieve Image k8s.gcr.io/kube-proxy:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853358    5502 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:37:48.853375    5502 image.go:60] error retrieve Image kubernetesui/metrics-scraper:v1.0.2 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853393    5502 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: got empty img digest "" for kubernetesui/metrics-scraper:v1.0.2
                I0110 12:37:48.853400    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
                I0110 12:37:48.853407    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
                I0110 12:37:48.853467    5502 image.go:60] error retrieve Image k8s.gcr.io/kube-addon-manager:v9.0.2 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853490    5502 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: got empty img digest "" for k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:37:48.853504    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
                I0110 12:37:48.853525    5502 image.go:60] error retrieve Image k8s.gcr.io/etcd:3.4.3-0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853545    5502 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: got empty img digest "" for k8s.gcr.io/etcd:3.4.3-0
                I0110 12:37:48.853563    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
                I0110 12:37:48.853691    5502 image.go:60] error retrieve Image k8s.gcr.io/kube-controller-manager:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853715    5502 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:37:48.853743    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
                I0110 12:37:48.853758    5502 image.go:60] error retrieve Image k8s.gcr.io/pause:3.1 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853778    5502 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: got empty img digest "" for k8s.gcr.io/pause:3.1
                I0110 12:37:48.853791    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
                I0110 12:37:48.853842    5502 image.go:60] error retrieve Image k8s.gcr.io/coredns:1.6.5 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853863    5502 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: got empty img digest "" for k8s.gcr.io/coredns:1.6.5
                I0110 12:37:48.853878    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
                I0110 12:37:48.853917    5502 image.go:60] error retrieve Image k8s.gcr.io/kube-scheduler:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.853935    5502 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:37:48.853949    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
                I0110 12:37:48.854006    5502 image.go:60] error retrieve Image kubernetesui/dashboard:v2.0.0-beta8 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:37:48.854022    5502 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: got empty img digest "" for kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:37:48.854051    5502 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
                I0110 12:37:48.861250    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:37:48.862171    5502 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:37:48.878781    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:37:48.885954    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
                I0110 12:37:48.885987    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
                I0110 12:37:48.886041    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
                I0110 12:37:48.886048    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
                I0110 12:37:48.886067    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:37:48.886051    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
                I0110 12:37:48.893706    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
                I0110 12:37:48.893813    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
                I0110 12:37:48.893826    5502 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:37:48.902191    5502 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:37:48.914021    5502 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:37:48.914060    5502 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:37:48.914087    5502 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
                I0110 12:37:48.914122    5502 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:37:48.914025    5502 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
                I0110 12:37:48.914145    5502 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:37:48.918333    5502 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:37:48.919217    5502 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:37:48.919358    5502 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:37:49.027452    5502 ssh_runner.go:194] pause_3.1: copied 356864 bytes
                I0110 12:37:49.067339    5502 docker.go:121] Loading image: /var/lib/minikube/images/pause_3.1
                I0110 12:37:49.067429    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/pause_3.1
                I0110 12:37:50.277299    5502 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
                I0110 12:37:50.465892    5502 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
                I0110 12:37:50.670146    5502 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
                I0110 12:37:51.161734    5502 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
                I0110 12:37:51.423895    5502 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
                I0110 12:37:51.468964    5502 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
                I0110 12:37:51.738564    5502 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
                I0110 12:37:51.869879    5502 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
                I0110 12:37:51.870192    5502 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
                I0110 12:37:52.284851    5502 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
                I0110 12:37:54.789739    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/pause_3.1: (5.722283524s)
                I0110 12:37:54.789779    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
                I0110 12:37:54.789797    5502 docker.go:121] Loading image: /var/lib/minikube/images/coredns_1.6.5
                I0110 12:37:54.789864    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/coredns_1.6.5
                I0110 12:37:56.641870    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/coredns_1.6.5: (1.851969905s)
                I0110 12:37:56.641907    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
                I0110 12:37:56.641933    5502 docker.go:121] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:37:56.641999    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:37:58.306785    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2: (1.664748277s)
                I0110 12:37:58.306823    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
                I0110 12:37:58.306844    5502 docker.go:121] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:37:58.306889    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:38:02.725744    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1: (4.418829915s)
                I0110 12:38:02.725784    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
                I0110 12:38:02.725811    5502 docker.go:121] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:38:02.725878    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:38:07.155680    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2: (4.429770668s)
                I0110 12:38:07.155722    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
                I0110 12:38:07.155738    5502 docker.go:121] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:38:07.155805    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:38:13.881955    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0: (6.726117327s)
                I0110 12:38:13.882017    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
                I0110 12:38:13.882043    5502 docker.go:121] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:38:13.882106    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:38:18.884905    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8: (5.002769877s)
                I0110 12:38:18.884944    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
                I0110 12:38:18.884973    5502 docker.go:121] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:38:18.885040    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:38:22.766389    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0: (3.881242356s)
                I0110 12:38:22.766437    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
                I0110 12:38:22.766464    5502 docker.go:121] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:38:22.766527    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:38:27.060516    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0: (4.293930632s)
                I0110 12:38:27.060546    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
                I0110 12:38:27.060557    5502 docker.go:121] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:38:27.060604    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:38:32.104645    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0: (5.044007658s)
                I0110 12:38:32.104696    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
                I0110 12:38:32.104722    5502 docker.go:121] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:38:32.104808    5502 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:38:43.269385    5502 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/etcd_3.4.3-0: (11.164554809s)
                I0110 12:38:43.269415    5502 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
                I0110 12:38:43.269433    5502 cache_images.go:93] Successfully loaded all cached images
                I0110 12:38:43.269439    5502 cache_images.go:94] LoadImages end
                I0110 12:38:43.269658    5502 kubeadm.go:390] kubelet [Unit]
                Wants=docker.socket
                
                [Service]
                ExecStart=
                ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=docker --fail-swap-on=false --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.39.49 --pod-manifest-path=/etc/kubernetes/manifests
                
                [Install]
                 config:
                {KubernetesVersion:v1.17.0 NodeIP:192.168.39.49 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false}
                I0110 12:38:43.269692    5502 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
                W0110 12:38:43.285968    5502 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
                stdout:
                
                stderr:
                 command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
                I0110 12:38:43.286107    5502 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
                I0110 12:38:43.286109    5502 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
                I0110 12:38:43.295716    5502 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
                I0110 12:38:43.296123    5502 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
                I0110 12:38:43.301556    5502 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
                I0110 12:38:43.331349    5502 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
                I0110 12:38:43.826206    5502 ssh_runner.go:194] kubeadm: copied 39342080 bytes
                I0110 12:38:44.292745    5502 ssh_runner.go:194] kubelet: copied 111560216 bytes
                I0110 12:38:44.308695    5502 ssh_runner.go:175] Transferring 1151 bytes to /var/tmp/minikube/kubeadm.yaml
                I0110 12:38:44.309916    5502 ssh_runner.go:194] kubeadm.yaml: copied 1151 bytes
                I0110 12:38:44.327031    5502 ssh_runner.go:175] Transferring 560 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                I0110 12:38:44.328196    5502 ssh_runner.go:194] 10-kubeadm.conf: copied 560 bytes
                I0110 12:38:44.346638    5502 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
                I0110 12:38:44.347783    5502 ssh_runner.go:194] kubelet.service: copied 349 bytes
                I0110 12:38:44.365695    5502 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
                I0110 12:38:44.366918    5502 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
                I0110 12:38:44.385434    5502 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
                I0110 12:38:44.386578    5502 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
                I0110 12:38:44.404021    5502 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
                I0110 12:38:44.404906    5502 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
                I0110 12:38:44.421950    5502 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
                I0110 12:38:44.423047    5502 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
                I0110 12:38:44.440105    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
                I0110 12:38:44.571959    5502 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.49
                I0110 12:38:44.572011    5502 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:44.919456    5502 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.crt ...
                I0110 12:38:44.919509    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.crt: {Name:mkc2e63b4c63ec44ff258fec4c133f04e387cd35 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:44.919792    5502 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.key ...
                I0110 12:38:44.919819    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.key: {Name:mk953238fa92cab1f7872ccfb2f0aeb9e74a96a5 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.128268    5502 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.crt ...
                I0110 12:38:45.128334    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.crt: {Name:mk28b1fc922b4908a64353fcb3c9af2b5e18437c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.128652    5502 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.key ...
                I0110 12:38:45.128684    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.key: {Name:mk24fb522892e09b5a068585677431df12c19752 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.128862    5502 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
                I0110 12:38:45.312204    5502 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
                I0110 12:38:45.312253    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.312507    5502 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
                I0110 12:38:45.312530    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.312680    5502 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.49 10.96.0.1 127.0.0.1 10.0.0.1]
                I0110 12:38:45.399334    5502 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
                I0110 12:38:45.399377    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.399619    5502 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
                I0110 12:38:45.399641    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.399750    5502 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
                I0110 12:38:45.539052    5502 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
                I0110 12:38:45.539094    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.539324    5502 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
                I0110 12:38:45.539345    5502 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:45.553445    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
                I0110 12:38:45.553983    5502 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
                I0110 12:38:45.555109    5502 ssh_runner.go:194] ca.crt: copied 1066 bytes
                I0110 12:38:45.586558    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
                I0110 12:38:45.588094    5502 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
                I0110 12:38:45.589827    5502 ssh_runner.go:194] ca.key: copied 1675 bytes
                I0110 12:38:45.612139    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
                I0110 12:38:45.612513    5502 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
                I0110 12:38:45.613676    5502 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
                I0110 12:38:45.637995    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
                I0110 12:38:45.638515    5502 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
                I0110 12:38:45.639700    5502 ssh_runner.go:194] apiserver.key: copied 1679 bytes
                I0110 12:38:45.664908    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
                I0110 12:38:45.665604    5502 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
                I0110 12:38:45.666529    5502 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
                I0110 12:38:45.693052    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
                I0110 12:38:45.693951    5502 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
                I0110 12:38:45.695807    5502 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
                I0110 12:38:45.726822    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
                I0110 12:38:45.727294    5502 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
                I0110 12:38:45.729500    5502 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
                I0110 12:38:45.763146    5502 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
                I0110 12:38:45.763598    5502 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
                I0110 12:38:45.764682    5502 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
                I0110 12:38:45.788194    5502 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
                I0110 12:38:45.788746    5502 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:38:45.789721    5502 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
                I0110 12:38:45.808707    5502 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
                I0110 12:38:45.809798    5502 ssh_runner.go:194] kubeconfig: copied 428 bytes
                I0110 12:38:45.827736    5502 ssh_runner.go:102] Run: openssl version
                I0110 12:38:45.837598    5502 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
                I0110 12:38:45.845726    5502 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
                I0110 12:38:45.853678    5502 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:38:45.869484    5502 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
                I0110 12:38:45.877637    5502 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
                I0110 12:38:45.885091    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
                I0110 12:38:46.104050    5502 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
                I0110 12:38:46.114225    5502 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
                stdout:
                
                stderr:
                ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
                ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
                ls: cannot access '/var/lib/minikube/etcd': No such file or directory
                I0110 12:38:46.114250    5502 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.49 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false}
                I0110 12:38:46.114294    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
                I0110 12:38:46.212910    5502 kubeadm.go:152] StartCluster complete in 98.623919ms
                I0110 12:38:46.213020    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-apiserver --format="{{.ID}}"
                I0110 12:38:46.275898    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.275929    5502 logs.go:180] No container was found matching "kube-apiserver"
                I0110 12:38:46.275998    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_coredns --format="{{.ID}}"
                I0110 12:38:46.326917    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.326955    5502 logs.go:180] No container was found matching "coredns"
                I0110 12:38:46.327029    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-scheduler --format="{{.ID}}"
                I0110 12:38:46.370338    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.370375    5502 logs.go:180] No container was found matching "kube-scheduler"
                I0110 12:38:46.370452    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-proxy --format="{{.ID}}"
                I0110 12:38:46.414184    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.414220    5502 logs.go:180] No container was found matching "kube-proxy"
                I0110 12:38:46.414300    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-addon-manager --format="{{.ID}}"
                I0110 12:38:46.458929    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.458965    5502 logs.go:180] No container was found matching "kube-addon-manager"
                I0110 12:38:46.459062    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format="{{.ID}}"
                I0110 12:38:46.518920    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.518955    5502 logs.go:180] No container was found matching "kubernetes-dashboard"
                I0110 12:38:46.519035    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_storage-provisioner --format="{{.ID}}"
                I0110 12:38:46.597765    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.597794    5502 logs.go:180] No container was found matching "storage-provisioner"
                I0110 12:38:46.597867    5502 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format="{{.ID}}"
                I0110 12:38:46.656609    5502 logs.go:178] 0 containers: []
                W0110 12:38:46.656648    5502 logs.go:180] No container was found matching "kube-controller-manager"
                I0110 12:38:46.656669    5502 logs.go:92] Gathering logs for kubelet ...
                I0110 12:38:46.656688    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
                I0110 12:38:46.678188    5502 logs.go:92] Gathering logs for dmesg ...
                I0110 12:38:46.678229    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
                I0110 12:38:46.697842    5502 logs.go:92] Gathering logs for Docker ...
                I0110 12:38:46.697881    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
                I0110 12:38:46.718749    5502 logs.go:92] Gathering logs for container status ...
                I0110 12:38:46.718788    5502 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
                I0110 12:38:48.851076    5502 ssh_runner.go:142] Completed: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a": (2.132264995s)
                W0110 12:38:50.790099    5502 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:38:46.212154    2716 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:38:46.212154    2716 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            aab_offline_test.go:58: [out/minikube-linux-amd64 start -p offline-docker-20200110T123418.751994578-4968 --alsologtostderr -v=1 --wait=true --container-runtime docker --vm-driver=kvm2 ] failed: exit status 70
            panic.go:563: *** TestOffline/group/docker FAILED at 2020-01-10 12:38:50.793432192 +0000 UTC m=+351.438451017
            panic.go:563: >>> TestOffline/group/docker FAILED: start of post-mortem logs >>>
            panic.go:563: (dbg) Run:  kubectl --context offline-docker-20200110T123418.751994578-4968 get po -A --show-labels
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-docker-20200110T123418.751994578-4968 get po -A --show-labels: exit status 1 (851.33536ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.49:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-docker-20200110T123418.751994578-4968 get po -A --show-labels: exit status 1
            panic.go:563: (dbg) kubectl --context offline-docker-20200110T123418.751994578-4968 get po -A --show-labels:
            panic.go:563: (dbg) Run:  kubectl --context offline-docker-20200110T123418.751994578-4968 describe node
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-docker-20200110T123418.751994578-4968 describe node: exit status 1 (251.669326ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.49:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-docker-20200110T123418.751994578-4968 describe node: exit status 1
            panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p offline-docker-20200110T123418.751994578-4968 logs --problems
            panic.go:563: (dbg) Done: out/minikube-linux-amd64 -p offline-docker-20200110T123418.751994578-4968 logs --problems: (3.054663789s)
            panic.go:563: TestOffline/group/docker logs: 
            panic.go:563: <<< TestOffline/group/docker FAILED: end of post-mortem logs <<<
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p offline-docker-20200110T123418.751994578-4968
            helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p offline-docker-20200110T123418.751994578-4968: (1.277951645s)
        --- FAIL: TestOffline/group/containerd (319.20s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:35:08.751930373 +0000 UTC m=+129.396949122 (sleeping 49.999970001s)  ...
            aab_offline_test.go:55: (dbg) Run:  out/minikube-linux-amd64 start -p offline-containerd-20200110T123508.752164285-4968 --alsologtostderr -v=1 --wait=true --container-runtime containerd --vm-driver=kvm2 
            aab_offline_test.go:55: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p offline-containerd-20200110T123508.752164285-4968 --alsologtostderr -v=1 --wait=true --container-runtime containerd --vm-driver=kvm2 : exit status 70 (4m25.864838772s)
                -- stdout --
                ! [offline-containerd-20200110T123508.752164285-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox none])
                * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
                * Found network options:
                  - HTTP_PROXY=172.16.1.1:1
                * Preparing Kubernetes v1.17.0 on containerd 1.2.10 ...
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:39:34.049641    2379 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                I0110 12:35:08.788660    5534 notify.go:125] Checking for updates...
                W0110 12:35:38.789144    5534 notify.go:56] Error getting json from minikube version url: error with http GET for endpoint https://storage.googleapis.com/minikube/releases.json: Get https://storage.googleapis.com/minikube/releases.json: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:35:38.840655    5534 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1087,"bootTime":1578658651,"procs":197,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
                I0110 12:35:38.841334    5534 start.go:266] virtualization: kvm host
                I0110 12:35:38.841570    5534 start.go:567] selectDriver: flag="kvm2", old=<nil>
                I0110 12:35:38.841593    5534 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:36:43.027730    5534 global.go:68] docker priority: 2, state: {Installed:true Healthy:false Error:exit status 1 Fix:Docker is not running. Try: restarting docker desktop. Doc:}
                I0110 12:36:45.009117    5534 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:36:45.009206    5534 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:36:45.220944    5534 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:36:45.221036    5534 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
                I0110 12:36:45.221080    5534 driver.go:128] requested: "kvm2"
                I0110 12:36:45.221095    5534 driver.go:132] choosing "kvm2" because it was requested
                I0110 12:36:45.221122    5534 driver.go:147] not recommending "none" due to priority: 2
                I0110 12:36:45.221140    5534 driver.go:142] not recommending "docker" due to health: exit status 1
                I0110 12:36:45.221153    5534 driver.go:165] Picked: kvm2
                I0110 12:36:45.221170    5534 driver.go:166] Alternatives: [virtualbox none]
                I0110 12:36:45.221290    5534 start.go:298] selected driver: kvm2
                I0110 12:36:45.221296    5534 start.go:597] validating driver "kvm2" against <nil>
                I0110 12:36:45.251233    5534 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:36:45.251375    5534 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:36:45.264498    5534 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
                I0110 12:36:45.264760    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
                I0110 12:36:45.264793    5534 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "45.732Âµs"
                I0110 12:36:45.264776    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
                I0110 12:36:45.264842    5534 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "84.005Âµs"
                I0110 12:36:45.264843    5534 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
                I0110 12:36:45.264797    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
                I0110 12:36:45.264856    5534 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
                I0110 12:36:45.264864    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
                I0110 12:36:45.264856    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
                I0110 12:36:45.264887    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
                I0110 12:36:45.264893    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
                I0110 12:36:45.264899    5534 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "25.617Âµs"
                I0110 12:36:45.264913    5534 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
                I0110 12:36:45.264876    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
                I0110 12:36:45.264927    5534 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "76.34Âµs"
                I0110 12:36:45.264893    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
                I0110 12:36:45.264893    5534 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "81.702Âµs"
                I0110 12:36:45.264808    5534 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-containerd-20200110T123508.752164285-4968/config.json ...
                I0110 12:36:45.264888    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
                I0110 12:36:45.264982    5534 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "109.402Âµs"
                I0110 12:36:45.264992    5534 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
                I0110 12:36:45.264903    5534 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "26.838Âµs"
                I0110 12:36:45.265004    5534 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
                I0110 12:36:45.264935    5534 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
                I0110 12:36:45.264864    5534 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
                I0110 12:36:45.265023    5534 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "182.989Âµs"
                I0110 12:36:45.265032    5534 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
                I0110 12:36:45.264865    5534 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "92.763Âµs"
                I0110 12:36:45.265043    5534 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
                I0110 12:36:45.264877    5534 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "40.547Âµs"
                I0110 12:36:45.265053    5534 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
                I0110 12:36:45.264970    5534 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
                I0110 12:36:45.264946    5534 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "70.432Âµs"
                I0110 12:36:45.265075    5534 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
                I0110 12:36:45.265126    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-containerd-20200110T123508.752164285-4968/config.json: {Name:mkc0a91534eb7df79a8983ee48db09c885935ab8 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:36:45.265154    5534 cache.go:70] Successfully saved all images to host disk.
                I0110 12:36:45.265436    5534 cluster.go:96] Machine does not exist... provisioning new machine
                I0110 12:36:45.265459    5534 cluster.go:97] Provisioning machine with config: {Name:offline-containerd-20200110T123508.752164285-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:containerd HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
                I0110 12:36:45.266173    5534 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:36:45.266284    5534 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:36:45.279651    5534 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:46839
                I0110 12:36:45.280186    5534 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:36:45.280993    5534 main.go:110] libmachine: Using API Version  1
                I0110 12:36:45.281021    5534 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:36:45.281557    5534 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:36:45.281762    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetMachineName
                I0110 12:36:45.281985    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:36:45.282241    5534 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
                I0110 12:36:45.282298    5534 main.go:110] libmachine: Decoding PEM data...
                I0110 12:36:45.282317    5534 main.go:110] libmachine: Parsing certificate...
                I0110 12:36:45.282420    5534 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
                I0110 12:36:45.282455    5534 main.go:110] libmachine: Decoding PEM data...
                I0110 12:36:45.282473    5534 main.go:110] libmachine: Parsing certificate...
                I0110 12:36:45.282531    5534 main.go:110] libmachine: Running pre-create checks...
                I0110 12:36:45.282545    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .PreCreateCheck
                I0110 12:36:45.282875    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetConfigRaw
                I0110 12:36:45.283415    5534 main.go:110] libmachine: Creating machine...
                I0110 12:36:45.283436    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .Create
                I0110 12:36:45.283598    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Creating KVM machine...
                I0110 12:36:45.287074    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968 ...
                I0110 12:36:45.287129    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
                I0110 12:36:45.287148    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | ERROR: logging before flag.Parse: I0110 12:36:45.287040    6076 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:36:45.287256    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
                I0110 12:36:45.417705    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | ERROR: logging before flag.Parse: I0110 12:36:45.417492    6076 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968/id_rsa...
                I0110 12:36:45.679076    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | ERROR: logging before flag.Parse: I0110 12:36:45.678853    6076 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968/offline-containerd-20200110T123508.752164285-4968.rawdisk...
                I0110 12:36:45.679130    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Writing magic tar header
                I0110 12:36:45.679178    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Writing SSH key tar header
                I0110 12:36:45.679217    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | ERROR: logging before flag.Parse: I0110 12:36:45.679079    6076 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968 ...
                I0110 12:36:45.679355    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968
                I0110 12:36:45.679391    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968 (perms=drwx------)
                I0110 12:36:45.679406    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
                I0110 12:36:45.679425    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:36:45.679444    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
                I0110 12:36:45.679462    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
                I0110 12:36:45.679486    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home/jenkins
                I0110 12:36:45.679512    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
                I0110 12:36:45.679532    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
                I0110 12:36:45.679548    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
                I0110 12:36:45.679578    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
                I0110 12:36:45.679611    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
                I0110 12:36:45.679638    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Checking permissions on dir: /home
                I0110 12:36:45.679664    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Skipping /home - not owner
                I0110 12:36:45.679681    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Creating domain...
                I0110 12:36:45.826983    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Creating network...
                I0110 12:36:45.830655    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Ensuring networks are active...
                I0110 12:36:45.833454    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Ensuring network default is active
                I0110 12:36:45.833919    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Ensuring network minikube-net is active
                I0110 12:36:45.834408    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Getting domain xml...
                I0110 12:36:45.837320    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Creating domain...
                I0110 12:36:46.323006    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Waiting to get IP...
                I0110 12:36:46.332825    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 0/40
                I0110 12:36:49.340603    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 1/40
                I0110 12:36:52.349007    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 2/40
                I0110 12:36:55.356571    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 3/40
                I0110 12:36:58.364748    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 4/40
                I0110 12:37:01.372404    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 5/40
                I0110 12:37:04.379981    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 6/40
                I0110 12:37:07.388073    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 7/40
                I0110 12:37:10.396270    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 8/40
                I0110 12:37:13.404700    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 9/40
                I0110 12:37:16.412580    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 10/40
                I0110 12:37:19.420237    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Waiting for machine to come up 11/40
                I0110 12:37:22.428948    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Getting to WaitForSSH function...
                I0110 12:37:22.428997    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Found IP for machine: 192.168.39.194
                I0110 12:37:22.429022    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Waiting for SSH to be available...
                I0110 12:37:22.452756    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Using SSH client type: external
                I0110 12:37:22.452826    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968/id_rsa (-rw-------)
                I0110 12:37:22.452876    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.194 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-containerd-20200110T123508.752164285-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
                I0110 12:37:22.452930    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | About to run SSH command:
                I0110 12:37:22.452955    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | exit 0
                I0110 12:37:22.603609    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | SSH cmd err, output: <nil>: 
                I0110 12:37:22.604318    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) KVM machine creation complete!
                I0110 12:37:22.604399    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetConfigRaw
                I0110 12:37:22.605490    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:22.605786    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:22.605997    5534 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
                I0110 12:37:22.606027    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetState
                I0110 12:37:22.610022    5534 main.go:110] libmachine: Detecting operating system of created instance...
                I0110 12:37:22.610052    5534 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:37:22.610065    5534 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:37:22.610082    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:22.616790    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:22.617004    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.617194    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.617391    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:22.617683    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:22.617877    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:22.617897    5534 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:37:22.745478    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:37:22.745515    5534 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:37:22.745533    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:22.753382    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:22.753643    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.753922    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.754197    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:22.754437    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:22.754611    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:22.754629    5534 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:37:22.875530    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:37:22.875615    5534 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:37:22.875626    5534 main.go:110] libmachine: Provisioning with buildroot...
                I0110 12:37:22.875659    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetMachineName
                I0110 12:37:22.875978    5534 main.go:110] libmachine: setting hostname "offline-containerd-20200110T123508.752164285-4968"
                I0110 12:37:22.875998    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetMachineName
                I0110 12:37:22.876372    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:22.884737    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:22.885038    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.885305    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:22.885505    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:22.885784    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:22.885983    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:22.886009    5534 main.go:110] libmachine: About to run SSH command:
                sudo hostname offline-containerd-20200110T123508.752164285-4968 && echo "offline-containerd-20200110T123508.752164285-4968" | sudo tee /etc/hostname
                I0110 12:37:23.024412    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: offline-containerd-20200110T123508.752164285-4968
                
                I0110 12:37:23.024467    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.032140    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.032438    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.032667    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.032866    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.033121    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:23.033339    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:23.033373    5534 main.go:110] libmachine: About to run SSH command:
                
                		if ! grep -xq '.*\soffline-containerd-20200110T123508.752164285-4968' /etc/hosts; then
                			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
                				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 offline-containerd-20200110T123508.752164285-4968/g' /etc/hosts;
                			else 
                				echo '127.0.1.1 offline-containerd-20200110T123508.752164285-4968' | sudo tee -a /etc/hosts; 
                			fi
                		fi
                I0110 12:37:23.159746    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:37:23.159847    5534 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
                I0110 12:37:23.159863    5534 main.go:110] libmachine: setting up certificates
                I0110 12:37:23.159880    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetMachineName
                I0110 12:37:23.160246    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetIP
                I0110 12:37:23.168159    5534 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.offline-containerd-20200110T123508.752164285-4968 san=[192.168.39.194 localhost]
                I0110 12:37:23.290122    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.298221    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.298436    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.298656    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.383895    5534 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
                I0110 12:37:23.384285    5534 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
                I0110 12:37:23.385317    5534 ssh_runner.go:194] ca.pem: copied 1038 bytes
                I0110 12:37:23.410854    5534 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
                I0110 12:37:23.411349    5534 ssh_runner.go:175] Transferring 1168 bytes to /etc/docker/server.pem
                I0110 12:37:23.412232    5534 ssh_runner.go:194] server.pem: copied 1168 bytes
                I0110 12:37:23.434749    5534 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
                I0110 12:37:23.435207    5534 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
                I0110 12:37:23.436048    5534 ssh_runner.go:194] server-key.pem: copied 1675 bytes
                I0110 12:37:23.453820    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetMachineName
                I0110 12:37:23.454429    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:23.454689    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.462852    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.463124    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.463371    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.463581    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.463837    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:23.464146    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:23.464173    5534 main.go:110] libmachine: About to run SSH command:
                df --output=fstype / | tail -n 1
                I0110 12:37:23.585918    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
                
                I0110 12:37:23.585966    5534 main.go:110] libmachine: root file system type: tmpfs
                I0110 12:37:23.586141    5534 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
                I0110 12:37:23.586174    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.594705    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.594955    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.595166    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.595371    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.595650    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:23.595828    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:23.595931    5534 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP $MAINPID
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                " | sudo tee /lib/systemd/system/docker.service
                I0110 12:37:23.725954    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP 
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                
                I0110 12:37:23.725994    5534 main.go:110] libmachine: setting minikube options for container-runtime
                I0110 12:37:23.726093    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.734712    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.734962    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.735217    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.735428    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.735646    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:23.735816    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:23.735838    5534 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /etc/sysconfig && printf %s "
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                " | sudo tee /etc/sysconfig/crio.minikube
                I0110 12:37:23.864378    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                
                I0110 12:37:23.864419    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:23.872776    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:23.873020    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.873273    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:23.873472    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:23.873737    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:23.873988    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:23.874020    5534 main.go:110] libmachine: About to run SSH command:
                sudo systemctl daemon-reload
                I0110 12:37:24.145987    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:37:24.146035    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:24.154189    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:24.154427    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:24.154643    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:24.154839    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:24.155069    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:24.155333    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:24.155361    5534 main.go:110] libmachine: About to run SSH command:
                sudo systemctl -f restart crio
                I0110 12:37:32.198155    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:37:32.198185    5534 main.go:110] libmachine: Checking connection to Docker...
                I0110 12:37:32.198197    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetURL
                I0110 12:37:32.202628    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Using libvirt version 3000000
                I0110 12:37:32.210427    5534 main.go:110] libmachine: Docker is up and running!
                I0110 12:37:32.210457    5534 main.go:110] libmachine: Reticulating splines...
                I0110 12:37:32.210474    5534 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:37:32.210493    5534 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:37:32.210519    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:32.217908    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:32.218149    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.218340    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.218507    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:32.218751    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:32.218985    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:32.219009    5534 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:37:32.341977    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:37:32.342032    5534 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:37:32.342051    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:32.351505    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:32.351821    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.352060    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.352325    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:32.352601    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:32.352780    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:32.352803    5534 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:37:32.476405    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:37:32.476483    5534 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:37:32.476492    5534 cluster.go:418] Provisioned with Buildroot 2019.02.7
                I0110 12:37:32.476503    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:32.485362    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:32.485587    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.485807    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.486004    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:32.486212    5534 main.go:110] libmachine: Using SSH client type: native
                I0110 12:37:32.486399    5534 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.194 22 <nil> <nil>}
                I0110 12:37:32.486460    5534 main.go:110] libmachine: About to run SSH command:
                date +%s.%N
                I0110 12:37:32.608110    5534 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578659852.529746363
                
                I0110 12:37:32.608159    5534 cluster.go:197] guest clock: 1578659852.529746363
                I0110 12:37:32.608174    5534 cluster.go:210] Guest: 2020-01-10 12:37:32.529746363 +0000 UTC Remote: 2020-01-10 12:37:32.476495599 +0000 UTC m=+143.720705362 (delta=53.250764ms)
                I0110 12:37:32.608256    5534 cluster.go:181] guest clock delta is within tolerance: 53.250764ms
                I0110 12:37:32.608288    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetConfigRaw
                I0110 12:37:32.609806    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:32.610057    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:32.610302    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:32.617949    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:32.618176    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:32.618361    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:32.653398    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetIP
                ! You appear to be using a proxy, but your NO_PROXY environment does not include the minikube IP (192.168.39.194). Please see https://minikube.sigs.k8s.io/docs/reference/networking/proxy/ for more details
                I0110 12:37:32.661873    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:32.662120    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:32.662835    5534 ssh_runner.go:102] Run: nslookup kubernetes.io
                I0110 12:37:32.712435    5534 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
                I0110 12:37:32.751326    5534 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-containerd-20200110T123508.752164285-4968/config.json ...
                I0110 12:37:32.751628    5534 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:37:32.764626    5534 ssh_runner.go:102] Run: sudo systemctl stop crio
                I0110 12:37:33.000585    5534 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:37:33.013995    5534 ssh_runner.go:102] Run: systemctl is-active --quiet service docker
                I0110 12:37:33.022177    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
                image-endpoint: unix:///run/containerd/containerd.sock
                " | sudo tee /etc/crictl.yaml"
                I0110 12:37:33.040796    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc/containerd && printf %s "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" | base64 -d | sudo tee /etc/containerd/config.toml"
                I0110 12:37:33.057490    5534 ssh_runner.go:102] Run: sudo modprobe br_netfilter
                I0110 12:37:33.077329    5534 ssh_runner.go:102] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
                I0110 12:37:33.085849    5534 ssh_runner.go:102] Run: sudo systemctl restart containerd
                I0110 12:37:33.106190    5534 ssh_runner.go:102] Run: containerd --version
                I0110 12:37:33.234311    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetURL
                I0110 12:37:33.239382    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) DBG | Using libvirt version 3000000
                I0110 12:37:33.247018    5534 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:37:33.247177    5534 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                I0110 12:37:33.250096    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:37:33.250970    5534 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:37:33.251036    5534 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:37:33.265297    5534 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:44453
                I0110 12:37:33.266002    5534 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:37:33.266865    5534 main.go:110] libmachine: Using API Version  1
                I0110 12:37:33.266911    5534 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:37:33.267407    5534 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:37:33.267667    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:33.267897    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .DriverName
                I0110 12:37:33.268143    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHHostname
                I0110 12:37:33.276293    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHPort
                I0110 12:37:33.276581    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHKeyPath
                I0110 12:37:33.276812    5534 main.go:110] libmachine: (offline-containerd-20200110T123508.752164285-4968) Calling .GetSSHUsername
                I0110 12:37:33.330373    5534 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
                I0110 12:37:33.330414    5534 cache_images.go:75] couldn't get a local image daemon which might be ok: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330482    5534 image.go:73] retrieving image: index.docker.io/kubernetesui/metrics-scraper:v1.0.2
                I0110 12:37:33.330502    5534 image.go:73] retrieving image: k8s.gcr.io/coredns:1.6.5
                I0110 12:37:33.330561    5534 image.go:81] daemon lookup for k8s.gcr.io/coredns:1.6.5: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330579    5534 image.go:73] retrieving image: index.docker.io/kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:37:33.330579    5534 image.go:73] retrieving image: k8s.gcr.io/etcd:3.4.3-0
                I0110 12:37:33.330607    5534 image.go:81] daemon lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330617    5534 image.go:81] daemon lookup for k8s.gcr.io/etcd:3.4.3-0: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330555    5534 image.go:73] retrieving image: gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:37:33.330635    5534 image.go:73] retrieving image: k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:37:33.330610    5534 image.go:73] retrieving image: k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:37:33.330651    5534 image.go:81] daemon lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330660    5534 image.go:81] daemon lookup for k8s.gcr.io/kube-proxy:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330664    5534 image.go:81] daemon lookup for k8s.gcr.io/kube-scheduler:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330579    5534 image.go:73] retrieving image: k8s.gcr.io/pause:3.1
                I0110 12:37:33.330705    5534 image.go:81] daemon lookup for k8s.gcr.io/pause:3.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.330644    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.330764    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330826    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.330860    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330892    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.330923    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330661    5534 image.go:73] retrieving image: k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:37:33.330958    5534 image.go:81] daemon lookup for k8s.gcr.io/kube-apiserver:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.331012    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331032    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330552    5534 image.go:73] retrieving image: k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:37:33.331059    5534 image.go:81] daemon lookup for k8s.gcr.io/kube-addon-manager:v9.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.331104    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331119    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330538    5534 image.go:81] daemon lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.331145    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331160    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.330683    5534 image.go:73] retrieving image: k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:37:33.331212    5534 image.go:81] daemon lookup for k8s.gcr.io/kube-controller-manager:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:37:33.331223    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331279    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.331333    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331351    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.331438    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331454    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.331540    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331587    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:37:33.331649    5534 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:37:33.331669    5534 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                W0110 12:38:03.331137    5534 image.go:89] authn lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331198    5534 image.go:89] authn lookup for k8s.gcr.io/etcd:3.4.3-0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331139    5534 image.go:89] authn lookup for k8s.gcr.io/coredns:1.6.5 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331359    5534 image.go:89] authn lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331299    5534 image.go:89] authn lookup for k8s.gcr.io/kube-apiserver:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331360    5534 image.go:89] authn lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1 (trying anon): Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331542    5534 image.go:89] authn lookup for k8s.gcr.io/kube-addon-manager:v9.0.2 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331571    5534 image.go:89] authn lookup for k8s.gcr.io/kube-scheduler:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331695    5534 image.go:89] authn lookup for k8s.gcr.io/pause:3.1 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.331865    5534 image.go:89] authn lookup for k8s.gcr.io/kube-proxy:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:03.332608    5534 image.go:89] authn lookup for k8s.gcr.io/kube-controller-manager:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:38:33.331637    5534 image.go:60] error retrieve Image k8s.gcr.io/etcd:3.4.3-0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331684    5534 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: got empty img digest "" for k8s.gcr.io/etcd:3.4.3-0
                I0110 12:38:33.331710    5534 image.go:60] error retrieve Image kubernetesui/metrics-scraper:v1.0.2 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331740    5534 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: got empty img digest "" for kubernetesui/metrics-scraper:v1.0.2
                I0110 12:38:33.331844    5534 image.go:60] error retrieve Image gcr.io/k8s-minikube/storage-provisioner:v1.8.1 ref Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331877    5534 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: got empty img digest "" for gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:38:33.331764    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
                I0110 12:38:33.331617    5534 image.go:60] error retrieve Image k8s.gcr.io/coredns:1.6.5 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331920    5534 image.go:60] error retrieve Image kubernetesui/dashboard:v2.0.0-beta8 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331940    5534 image.go:60] error retrieve Image k8s.gcr.io/kube-addon-manager:v9.0.2 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.331953    5534 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: got empty img digest "" for kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:38:33.331985    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
                I0110 12:38:33.331864    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
                I0110 12:38:33.331956    5534 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: got empty img digest "" for k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:38:33.332057    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
                I0110 12:38:33.331938    5534 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: got empty img digest "" for k8s.gcr.io/coredns:1.6.5
                I0110 12:38:33.332072    5534 image.go:60] error retrieve Image k8s.gcr.io/kube-proxy:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.332089    5534 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:38:33.332149    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
                I0110 12:38:33.331895    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
                I0110 12:38:33.331943    5534 image.go:60] error retrieve Image k8s.gcr.io/pause:3.1 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.332211    5534 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: got empty img digest "" for k8s.gcr.io/pause:3.1
                I0110 12:38:33.332216    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
                I0110 12:38:33.332249    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
                I0110 12:38:33.334760    5534 image.go:60] error retrieve Image k8s.gcr.io/kube-scheduler:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.334793    5534 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:38:33.334810    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
                I0110 12:38:33.335050    5534 image.go:60] error retrieve Image k8s.gcr.io/kube-apiserver:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.335085    5534 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:38:33.335085    5534 image.go:60] error retrieve Image k8s.gcr.io/kube-controller-manager:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:38:33.335103    5534 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:38:33.335117    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
                I0110 12:38:33.335117    5534 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
                I0110 12:38:33.361544    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
                I0110 12:38:33.361669    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
                I0110 12:38:33.362537    5534 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
                I0110 12:38:33.362545    5534 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:38:33.364902    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
                I0110 12:38:33.365241    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
                I0110 12:38:33.370585    5534 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:38:33.370589    5534 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:38:33.371099    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
                I0110 12:38:33.371156    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
                I0110 12:38:33.371181    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:38:33.371163    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:38:33.375784    5534 ssh_runner.go:194] pause_3.1: copied 356864 bytes
                I0110 12:38:33.375994    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
                I0110 12:38:33.377735    5534 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:38:33.377766    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:38:33.380714    5534 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:38:33.380826    5534 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:38:33.380833    5534 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:38:33.380851    5534 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:38:33.388082    5534 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:38:33.388192    5534 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
                I0110 12:38:33.404006    5534 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:38:33.523648    5534 containerd.go:235] Loading image: /var/lib/minikube/images/pause_3.1
                I0110 12:38:33.523753    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/pause_3.1
                I0110 12:38:34.769989    5534 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
                I0110 12:38:34.801646    5534 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
                I0110 12:38:35.211222    5534 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
                I0110 12:38:35.903510    5534 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
                I0110 12:38:35.935380    5534 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
                I0110 12:38:36.019142    5534 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
                I0110 12:38:36.447242    5534 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
                I0110 12:38:36.479675    5534 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
                I0110 12:38:36.510063    5534 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
                I0110 12:38:36.883492    5534 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
                I0110 12:38:42.901677    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/pause_3.1: (9.377880323s)
                I0110 12:38:42.901755    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
                I0110 12:38:42.901791    5534 containerd.go:235] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:38:42.901875    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:38:46.140362    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/metrics-scraper_v1.0.2: (3.238412174s)
                I0110 12:38:46.140416    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
                I0110 12:38:46.140435    5534 containerd.go:235] Loading image: /var/lib/minikube/images/coredns_1.6.5
                I0110 12:38:46.140495    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/coredns_1.6.5
                I0110 12:38:48.214296    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/coredns_1.6.5: (2.073770717s)
                I0110 12:38:48.214332    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
                I0110 12:38:48.214348    5534 containerd.go:235] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:38:48.214396    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:38:52.747528    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/storage-provisioner_v1.8.1: (4.533100354s)
                I0110 12:38:52.747565    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
                I0110 12:38:52.747590    5534 containerd.go:235] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:38:52.747658    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:38:57.675377    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/dashboard_v2.0.0-beta8: (4.927677292s)
                I0110 12:38:57.675413    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
                I0110 12:38:57.675442    5534 containerd.go:235] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:38:57.675509    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:39:01.745871    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-addon-manager_v9.0.2: (4.070321127s)
                I0110 12:39:01.745910    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
                I0110 12:39:01.745925    5534 containerd.go:235] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:39:01.745986    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:39:06.106970    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-scheduler_v1.17.0: (4.360948025s)
                I0110 12:39:06.107018    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
                I0110 12:39:06.107050    5534 containerd.go:235] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:39:06.107098    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:39:10.468054    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-proxy_v1.17.0: (4.360922617s)
                I0110 12:39:10.468087    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
                I0110 12:39:10.468108    5534 containerd.go:235] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:39:10.468167    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:39:15.584799    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-apiserver_v1.17.0: (5.116556919s)
                I0110 12:39:15.584859    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
                I0110 12:39:15.584878    5534 containerd.go:235] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:39:15.584923    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:39:20.291299    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-controller-manager_v1.17.0: (4.706331222s)
                I0110 12:39:20.291353    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
                I0110 12:39:20.291387    5534 containerd.go:235] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:39:20.291470    5534 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:39:31.989742    5534 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/etcd_3.4.3-0: (11.6982287s)
                I0110 12:39:31.989780    5534 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
                I0110 12:39:31.989806    5534 cache_images.go:93] Successfully loaded all cached images
                I0110 12:39:31.989815    5534 cache_images.go:94] LoadImages end
                I0110 12:39:31.990064    5534 kubeadm.go:390] kubelet [Unit]
                Wants=containerd.service
                
                [Service]
                ExecStart=
                ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --fail-swap-on=false --hostname-override=minikube --image-service-endpoint=unix:///run/containerd/containerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --network-plugin=cni --node-ip=192.168.39.194 --pod-manifest-path=/etc/kubernetes/manifests --runtime-request-timeout=15m
                
                [Install]
                 config:
                {KubernetesVersion:v1.17.0 NodeIP:192.168.39.194 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:39:31.990128    5534 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
                W0110 12:39:32.008811    5534 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
                stdout:
                
                stderr:
                 command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
                I0110 12:39:32.008936    5534 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
                I0110 12:39:32.008936    5534 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
                I0110 12:39:32.018864    5534 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
                I0110 12:39:32.019412    5534 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
                I0110 12:39:32.020768    5534 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
                I0110 12:39:32.025287    5534 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
                I0110 12:39:32.454378    5534 ssh_runner.go:194] kubeadm: copied 39342080 bytes
                I0110 12:39:32.995189    5534 ssh_runner.go:194] kubelet: copied 111560216 bytes
                I0110 12:39:33.010502    5534 ssh_runner.go:175] Transferring 1159 bytes to /var/tmp/minikube/kubeadm.yaml
                I0110 12:39:33.011509    5534 ssh_runner.go:194] kubeadm.yaml: copied 1159 bytes
                I0110 12:39:33.030704    5534 ssh_runner.go:175] Transferring 749 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                I0110 12:39:33.031713    5534 ssh_runner.go:194] 10-kubeadm.conf: copied 749 bytes
                I0110 12:39:33.056732    5534 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
                I0110 12:39:33.057794    5534 ssh_runner.go:194] kubelet.service: copied 349 bytes
                I0110 12:39:33.081293    5534 ssh_runner.go:175] Transferring 341 bytes to /etc/cni/net.d/k8s.conf
                I0110 12:39:33.082435    5534 ssh_runner.go:194] k8s.conf: copied 341 bytes
                I0110 12:39:33.103649    5534 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
                I0110 12:39:33.104782    5534 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
                I0110 12:39:33.124338    5534 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
                I0110 12:39:33.125394    5534 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
                I0110 12:39:33.144309    5534 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
                I0110 12:39:33.145058    5534 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
                I0110 12:39:33.164537    5534 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
                I0110 12:39:33.165398    5534 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
                I0110 12:39:33.184718    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
                I0110 12:39:33.321415    5534 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.194
                I0110 12:39:33.321460    5534 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.321667    5534 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
                I0110 12:39:33.326682    5534 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
                I0110 12:39:33.326722    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.327062    5534 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
                I0110 12:39:33.327098    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.327329    5534 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.194 10.96.0.1 127.0.0.1 10.0.0.1]
                I0110 12:39:33.332227    5534 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
                I0110 12:39:33.332273    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.332560    5534 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
                I0110 12:39:33.332588    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.332786    5534 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
                I0110 12:39:33.338193    5534 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
                I0110 12:39:33.338239    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.338529    5534 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
                I0110 12:39:33.338559    5534 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:39:33.355381    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
                I0110 12:39:33.357027    5534 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
                I0110 12:39:33.363348    5534 ssh_runner.go:194] ca.crt: copied 1066 bytes
                I0110 12:39:33.404266    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
                I0110 12:39:33.404728    5534 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
                I0110 12:39:33.407675    5534 ssh_runner.go:194] ca.key: copied 1675 bytes
                I0110 12:39:33.437361    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
                I0110 12:39:33.437896    5534 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
                I0110 12:39:33.438830    5534 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
                I0110 12:39:33.483738    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
                I0110 12:39:33.484850    5534 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
                I0110 12:39:33.487009    5534 ssh_runner.go:194] apiserver.key: copied 1679 bytes
                I0110 12:39:33.532536    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
                I0110 12:39:33.532990    5534 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
                I0110 12:39:33.533810    5534 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
                I0110 12:39:33.562704    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
                I0110 12:39:33.563752    5534 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
                I0110 12:39:33.566050    5534 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
                I0110 12:39:33.598928    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
                I0110 12:39:33.599384    5534 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
                I0110 12:39:33.600410    5534 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
                I0110 12:39:33.643751    5534 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
                I0110 12:39:33.644203    5534 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
                I0110 12:39:33.645811    5534 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
                I0110 12:39:33.685872    5534 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
                I0110 12:39:33.686444    5534 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:39:33.688130    5534 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
                I0110 12:39:33.714259    5534 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
                I0110 12:39:33.715214    5534 ssh_runner.go:194] kubeconfig: copied 428 bytes
                I0110 12:39:33.734879    5534 ssh_runner.go:102] Run: openssl version
                I0110 12:39:33.743443    5534 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
                I0110 12:39:33.750937    5534 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
                I0110 12:39:33.759327    5534 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:39:33.779590    5534 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
                I0110 12:39:33.788460    5534 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
                I0110 12:39:33.796516    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
                I0110 12:39:34.053061    5534 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
                I0110 12:39:34.066530    5534 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
                stdout:
                
                stderr:
                ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
                ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
                ls: cannot access '/var/lib/minikube/etcd': No such file or directory
                I0110 12:39:34.066566    5534 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.194 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:39:34.066610    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
                I0110 12:39:34.175152    5534 kubeadm.go:152] StartCluster complete in 108.557355ms
                I0110 12:39:34.175298    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-apiserver --state=Running --quiet
                I0110 12:39:34.287995    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.288029    5534 logs.go:180] No container was found matching "kube-apiserver"
                I0110 12:39:34.288097    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=coredns --state=Running --quiet
                I0110 12:39:34.337250    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.337289    5534 logs.go:180] No container was found matching "coredns"
                I0110 12:39:34.337365    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-scheduler --state=Running --quiet
                I0110 12:39:34.363795    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.363835    5534 logs.go:180] No container was found matching "kube-scheduler"
                I0110 12:39:34.363909    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-proxy --state=Running --quiet
                I0110 12:39:34.390875    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.390913    5534 logs.go:180] No container was found matching "kube-proxy"
                I0110 12:39:34.390999    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-addon-manager --state=Running --quiet
                I0110 12:39:34.417000    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.417040    5534 logs.go:180] No container was found matching "kube-addon-manager"
                I0110 12:39:34.417126    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kubernetes-dashboard --state=Running --quiet
                I0110 12:39:34.445841    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.445880    5534 logs.go:180] No container was found matching "kubernetes-dashboard"
                I0110 12:39:34.445968    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=storage-provisioner --state=Running --quiet
                I0110 12:39:34.475745    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.475779    5534 logs.go:180] No container was found matching "storage-provisioner"
                I0110 12:39:34.475853    5534 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-controller-manager --state=Running --quiet
                I0110 12:39:34.511166    5534 logs.go:178] 0 containers: []
                W0110 12:39:34.511216    5534 logs.go:180] No container was found matching "kube-controller-manager"
                I0110 12:39:34.511239    5534 logs.go:92] Gathering logs for containerd ...
                I0110 12:39:34.511258    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u containerd -n 400"
                I0110 12:39:34.532529    5534 logs.go:92] Gathering logs for container status ...
                I0110 12:39:34.532564    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
                I0110 12:39:34.584001    5534 logs.go:92] Gathering logs for kubelet ...
                I0110 12:39:34.584042    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
                I0110 12:39:34.601301    5534 logs.go:92] Gathering logs for dmesg ...
                I0110 12:39:34.601372    5534 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
                W0110 12:39:34.615149    5534 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:39:34.172056    2386 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:39:34.172056    2386 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            aab_offline_test.go:58: [out/minikube-linux-amd64 start -p offline-containerd-20200110T123508.752164285-4968 --alsologtostderr -v=1 --wait=true --container-runtime containerd --vm-driver=kvm2 ] failed: exit status 70
            panic.go:563: *** TestOffline/group/containerd FAILED at 2020-01-10 12:39:34.619477055 +0000 UTC m=+395.264495939
            panic.go:563: >>> TestOffline/group/containerd FAILED: start of post-mortem logs >>>
            panic.go:563: (dbg) Run:  kubectl --context offline-containerd-20200110T123508.752164285-4968 get po -A --show-labels
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-containerd-20200110T123508.752164285-4968 get po -A --show-labels: exit status 1 (241.227195ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.194:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-containerd-20200110T123508.752164285-4968 get po -A --show-labels: exit status 1
            panic.go:563: (dbg) kubectl --context offline-containerd-20200110T123508.752164285-4968 get po -A --show-labels:
            panic.go:563: (dbg) Run:  kubectl --context offline-containerd-20200110T123508.752164285-4968 describe node
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-containerd-20200110T123508.752164285-4968 describe node: exit status 1 (81.143089ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.194:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-containerd-20200110T123508.752164285-4968 describe node: exit status 1
            panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p offline-containerd-20200110T123508.752164285-4968 logs --problems
            panic.go:563: TestOffline/group/containerd logs: 
            panic.go:563: <<< TestOffline/group/containerd FAILED: end of post-mortem logs <<<
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p offline-containerd-20200110T123508.752164285-4968
            helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p offline-containerd-20200110T123508.752164285-4968: (2.130303457s)
        --- FAIL: TestOffline/group/crio (384.19s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:35:58.751930373 +0000 UTC m=+179.396949122 (sleeping 1m39.999913809s)  ...
            aab_offline_test.go:55: (dbg) Run:  out/minikube-linux-amd64 start -p offline-crio-20200110T123558.75214308-4968 --alsologtostderr -v=1 --wait=true --container-runtime crio --vm-driver=kvm2 
            aab_offline_test.go:55: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p offline-crio-20200110T123558.75214308-4968 --alsologtostderr -v=1 --wait=true --container-runtime crio --vm-driver=kvm2 : exit status 70 (4m41.810933007s)
                -- stdout --
                ! [offline-crio-20200110T123558.75214308-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox none])
                * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
                * Found network options:
                  - HTTP_PROXY=172.16.1.1:1
                * Preparing Kubernetes v1.17.0 on CRI-O 1.16.0 ...
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:40:40.063917    2562 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                I0110 12:35:58.787486    5832 notify.go:125] Checking for updates...
                W0110 12:36:28.787999    5832 notify.go:56] Error getting json from minikube version url: error with http GET for endpoint https://storage.googleapis.com/minikube/releases.json: Get https://storage.googleapis.com/minikube/releases.json: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:36:28.847390    5832 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1137,"bootTime":1578658651,"procs":207,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
                I0110 12:36:28.848877    5832 start.go:266] virtualization: kvm host
                I0110 12:36:28.849474    5832 start.go:567] selectDriver: flag="kvm2", old=<nil>
                I0110 12:36:28.849519    5832 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:36:28.849654    5832 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
                I0110 12:37:33.041970    5832 global.go:68] docker priority: 2, state: {Installed:true Healthy:false Error:exit status 1 Fix:Docker is not running. Try: restarting docker desktop. Doc:}
                I0110 12:37:35.055053    5832 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:37:35.055133    5832 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:37:35.264905    5832 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:37:35.264953    5832 driver.go:128] requested: "kvm2"
                I0110 12:37:35.264962    5832 driver.go:132] choosing "kvm2" because it was requested
                I0110 12:37:35.264967    5832 driver.go:147] not recommending "none" due to priority: 2
                I0110 12:37:35.264973    5832 driver.go:142] not recommending "docker" due to health: exit status 1
                I0110 12:37:35.264983    5832 driver.go:165] Picked: kvm2
                I0110 12:37:35.264991    5832 driver.go:166] Alternatives: [virtualbox none]
                I0110 12:37:35.265105    5832 start.go:298] selected driver: kvm2
                I0110 12:37:35.265111    5832 start.go:597] validating driver "kvm2" against <nil>
                I0110 12:37:35.297499    5832 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:37:35.297697    5832 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:37:35.314131    5832 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
                I0110 12:37:35.314428    5832 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-crio-20200110T123558.75214308-4968/config.json ...
                I0110 12:37:35.314436    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
                I0110 12:37:35.314435    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
                I0110 12:37:35.314499    5832 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "96.141Âµs"
                I0110 12:37:35.314512    5832 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
                I0110 12:37:35.314471    5832 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "64.2Âµs"
                I0110 12:37:35.314517    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
                I0110 12:37:35.314525    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
                I0110 12:37:35.314552    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
                I0110 12:37:35.314561    5832 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "25.203Âµs"
                I0110 12:37:35.314563    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
                I0110 12:37:35.314564    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-crio-20200110T123558.75214308-4968/config.json: {Name:mked0add38bf6e48c51b11aed69711adb29435fd Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:37:35.314590    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
                I0110 12:37:35.314586    5832 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "55.642Âµs"
                I0110 12:37:35.314589    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
                I0110 12:37:35.314600    5832 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "22.973Âµs"
                I0110 12:37:35.314604    5832 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
                I0110 12:37:35.314612    5832 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
                I0110 12:37:35.314598    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
                I0110 12:37:35.314625    5832 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "44.448Âµs"
                I0110 12:37:35.314635    5832 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
                I0110 12:37:35.314609    5832 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "44Âµs"
                I0110 12:37:35.314660    5832 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
                I0110 12:37:35.314529    5832 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "33.902Âµs"
                I0110 12:37:35.314670    5832 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
                I0110 12:37:35.314556    5832 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "62.354Âµs"
                I0110 12:37:35.314689    5832 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
                I0110 12:37:35.314565    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
                I0110 12:37:35.314701    5832 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "153.922Âµs"
                I0110 12:37:35.314720    5832 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
                I0110 12:37:35.314523    5832 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
                I0110 12:37:35.314579    5832 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
                I0110 12:37:35.314612    5832 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
                I0110 12:37:35.314749    5832 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "147.116Âµs"
                I0110 12:37:35.314763    5832 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
                I0110 12:37:35.314771    5832 cache.go:70] Successfully saved all images to host disk.
                I0110 12:37:35.314896    5832 cluster.go:96] Machine does not exist... provisioning new machine
                I0110 12:37:35.314914    5832 cluster.go:97] Provisioning machine with config: {Name:offline-crio-20200110T123558.75214308-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:crio HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:crio CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
                I0110 12:37:35.315099    5832 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:37:35.315149    5832 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:37:35.327819    5832 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:43789
                I0110 12:37:35.329089    5832 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:37:35.329990    5832 main.go:110] libmachine: Using API Version  1
                I0110 12:37:35.330026    5832 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:37:35.330456    5832 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:37:35.330708    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetMachineName
                I0110 12:37:35.331010    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:37:35.331261    5832 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
                I0110 12:37:35.331304    5832 main.go:110] libmachine: Decoding PEM data...
                I0110 12:37:35.331346    5832 main.go:110] libmachine: Parsing certificate...
                I0110 12:37:35.331446    5832 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
                I0110 12:37:35.331481    5832 main.go:110] libmachine: Decoding PEM data...
                I0110 12:37:35.331499    5832 main.go:110] libmachine: Parsing certificate...
                I0110 12:37:35.331556    5832 main.go:110] libmachine: Running pre-create checks...
                I0110 12:37:35.331573    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .PreCreateCheck
                I0110 12:37:35.331969    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetConfigRaw
                I0110 12:37:35.332450    5832 main.go:110] libmachine: Creating machine...
                I0110 12:37:35.332470    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .Create
                I0110 12:37:35.332638    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Creating KVM machine...
                I0110 12:37:35.336874    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968 ...
                I0110 12:37:35.336906    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
                I0110 12:37:35.336978    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | ERROR: logging before flag.Parse: I0110 12:37:35.336845    6385 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:37:35.337074    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
                I0110 12:37:35.496499    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | ERROR: logging before flag.Parse: I0110 12:37:35.496314    6385 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968/id_rsa...
                I0110 12:37:35.814809    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | ERROR: logging before flag.Parse: I0110 12:37:35.814679    6385 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968/offline-crio-20200110T123558.75214308-4968.rawdisk...
                I0110 12:37:35.814851    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Writing magic tar header
                I0110 12:37:35.814883    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Writing SSH key tar header
                I0110 12:37:35.814922    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | ERROR: logging before flag.Parse: I0110 12:37:35.814827    6385 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968 ...
                I0110 12:37:35.815057    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968
                I0110 12:37:35.815123    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968 (perms=drwx------)
                I0110 12:37:35.815141    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
                I0110 12:37:35.815164    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:37:35.815191    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
                I0110 12:37:35.815231    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
                I0110 12:37:35.815271    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
                I0110 12:37:35.815299    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
                I0110 12:37:35.815431    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
                I0110 12:37:35.815453    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
                I0110 12:37:35.815473    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home/jenkins
                I0110 12:37:35.815493    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Checking permissions on dir: /home
                I0110 12:37:35.815511    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Skipping /home - not owner
                I0110 12:37:35.815529    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
                I0110 12:37:35.815549    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Creating domain...
                I0110 12:37:35.845303    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Creating network...
                I0110 12:37:35.848895    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Ensuring networks are active...
                I0110 12:37:35.851732    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Ensuring network default is active
                I0110 12:37:35.852343    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Ensuring network minikube-net is active
                I0110 12:37:35.852877    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Getting domain xml...
                I0110 12:37:35.856255    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Creating domain...
                I0110 12:37:36.356945    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Waiting to get IP...
                I0110 12:37:36.364830    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 0/40
                I0110 12:37:39.373329    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 1/40
                I0110 12:37:42.381383    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 2/40
                I0110 12:37:45.390283    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 3/40
                I0110 12:37:48.398871    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 4/40
                I0110 12:37:51.410864    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 5/40
                I0110 12:37:54.419475    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 6/40
                I0110 12:37:57.429128    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 7/40
                I0110 12:38:00.438147    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 8/40
                I0110 12:38:03.446839    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 9/40
                I0110 12:38:06.456324    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 10/40
                I0110 12:38:09.467006    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 11/40
                I0110 12:38:12.475040    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Waiting for machine to come up 12/40
                I0110 12:38:15.498320    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Found IP for machine: 192.168.39.202
                I0110 12:38:15.498390    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Waiting for SSH to be available...
                I0110 12:38:15.498404    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Getting to WaitForSSH function...
                I0110 12:38:15.506682    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Using SSH client type: external
                I0110 12:38:15.506747    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968/id_rsa (-rw-------)
                I0110 12:38:15.506826    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.202 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/offline-crio-20200110T123558.75214308-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
                I0110 12:38:15.506866    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | About to run SSH command:
                I0110 12:38:15.506884    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | exit 0
                I0110 12:38:15.655119    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | SSH cmd err, output: <nil>: 
                I0110 12:38:15.655967    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) KVM machine creation complete!
                I0110 12:38:15.656056    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetConfigRaw
                I0110 12:38:15.656940    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:15.657190    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:15.657431    5832 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
                I0110 12:38:15.657455    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetState
                I0110 12:38:15.662399    5832 main.go:110] libmachine: Detecting operating system of created instance...
                I0110 12:38:15.662437    5832 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:38:15.662451    5832 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:38:15.662475    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:15.670217    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:15.670469    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.670666    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.670893    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:15.671133    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:15.671387    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:15.671408    5832 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:38:15.805815    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:38:15.805845    5832 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:38:15.805856    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:15.814725    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:15.814963    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.815237    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.815468    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:15.815699    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:15.815871    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:15.815889    5832 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:38:15.944089    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:38:15.944159    5832 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:38:15.944172    5832 main.go:110] libmachine: Provisioning with buildroot...
                I0110 12:38:15.944188    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetMachineName
                I0110 12:38:15.944570    5832 main.go:110] libmachine: setting hostname "offline-crio-20200110T123558.75214308-4968"
                I0110 12:38:15.944606    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetMachineName
                I0110 12:38:15.944861    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:15.954113    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:15.954366    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.954629    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:15.954908    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:15.955147    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:15.955331    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:15.955352    5832 main.go:110] libmachine: About to run SSH command:
                sudo hostname offline-crio-20200110T123558.75214308-4968 && echo "offline-crio-20200110T123558.75214308-4968" | sudo tee /etc/hostname
                I0110 12:38:16.096715    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: offline-crio-20200110T123558.75214308-4968
                
                I0110 12:38:16.096772    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:16.106797    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:16.107082    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.107384    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.107694    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:16.107949    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:16.108125    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:16.108154    5832 main.go:110] libmachine: About to run SSH command:
                
                		if ! grep -xq '.*\soffline-crio-20200110T123558.75214308-4968' /etc/hosts; then
                			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
                				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 offline-crio-20200110T123558.75214308-4968/g' /etc/hosts;
                			else 
                				echo '127.0.1.1 offline-crio-20200110T123558.75214308-4968' | sudo tee -a /etc/hosts; 
                			fi
                		fi
                I0110 12:38:16.237195    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:38:16.237344    5832 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
                I0110 12:38:16.237368    5832 main.go:110] libmachine: setting up certificates
                I0110 12:38:16.237393    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetMachineName
                I0110 12:38:16.237702    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetIP
                I0110 12:38:16.247763    5832 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.offline-crio-20200110T123558.75214308-4968 san=[192.168.39.202 localhost]
                I0110 12:38:16.624233    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:16.633143    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:16.633418    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.633624    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:16.720566    5832 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
                I0110 12:38:16.721036    5832 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
                I0110 12:38:16.722072    5832 ssh_runner.go:194] ca.pem: copied 1038 bytes
                I0110 12:38:16.749492    5832 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
                I0110 12:38:16.750015    5832 ssh_runner.go:175] Transferring 1159 bytes to /etc/docker/server.pem
                I0110 12:38:16.750934    5832 ssh_runner.go:194] server.pem: copied 1159 bytes
                I0110 12:38:16.774435    5832 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
                I0110 12:38:16.775027    5832 ssh_runner.go:175] Transferring 1679 bytes to /etc/docker/server-key.pem
                I0110 12:38:16.775978    5832 ssh_runner.go:194] server-key.pem: copied 1679 bytes
                I0110 12:38:16.795807    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetMachineName
                I0110 12:38:16.796403    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:16.796644    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:16.806426    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:16.806672    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.806874    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.807068    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:16.807305    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:16.807489    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:16.807516    5832 main.go:110] libmachine: About to run SSH command:
                df --output=fstype / | tail -n 1
                I0110 12:38:16.931343    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
                
                I0110 12:38:16.931378    5832 main.go:110] libmachine: root file system type: tmpfs
                I0110 12:38:16.931714    5832 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
                I0110 12:38:16.931748    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:16.940970    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:16.941267    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.941504    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:16.941704    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:16.941938    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:16.942182    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:16.942309    5832 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP $MAINPID
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                " | sudo tee /lib/systemd/system/docker.service
                I0110 12:38:17.068851    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP 
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                
                I0110 12:38:17.068884    5832 main.go:110] libmachine: setting minikube options for container-runtime
                I0110 12:38:17.069005    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:17.078160    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:17.078411    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.078596    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.078835    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:17.079083    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:17.079268    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:17.079321    5832 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /etc/sysconfig && printf %s "
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                " | sudo tee /etc/sysconfig/crio.minikube
                I0110 12:38:17.203923    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                
                I0110 12:38:17.203965    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:17.229231    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:17.229525    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.229717    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.229906    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:17.230146    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:17.230348    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:17.230373    5832 main.go:110] libmachine: About to run SSH command:
                sudo systemctl daemon-reload
                I0110 12:38:17.551047    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:38:17.551077    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:17.560360    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:17.560610    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.560796    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:17.560976    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:17.561174    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:17.561400    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:17.561427    5832 main.go:110] libmachine: About to run SSH command:
                sudo systemctl -f restart crio
                I0110 12:38:23.230610    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:38:23.230712    5832 main.go:110] libmachine: Checking connection to Docker...
                I0110 12:38:23.230733    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetURL
                I0110 12:38:23.237657    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Using libvirt version 3000000
                I0110 12:38:23.247865    5832 main.go:110] libmachine: Docker is up and running!
                I0110 12:38:23.247900    5832 main.go:110] libmachine: Reticulating splines...
                I0110 12:38:23.247919    5832 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:38:23.247928    5832 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:38:23.247938    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:23.256793    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:23.257054    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.257331    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.257636    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:23.257883    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:23.258122    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:23.258145    5832 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:38:23.381620    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:38:23.381663    5832 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:38:23.381680    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:23.390962    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:23.391204    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.391418    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.391589    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:23.391873    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:23.392043    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:23.392065    5832 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:38:23.511750    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:38:23.511810    5832 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:38:23.511822    5832 cluster.go:418] Provisioned with Buildroot 2019.02.7
                I0110 12:38:23.511872    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:23.521150    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:23.521384    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.521640    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.521816    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:23.522055    5832 main.go:110] libmachine: Using SSH client type: native
                I0110 12:38:23.522212    5832 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.202 22 <nil> <nil>}
                I0110 12:38:23.522228    5832 main.go:110] libmachine: About to run SSH command:
                date +%s.%N
                I0110 12:38:23.648556    5832 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578659903.513143243
                
                I0110 12:38:23.648585    5832 cluster.go:197] guest clock: 1578659903.513143243
                I0110 12:38:23.648601    5832 cluster.go:210] Guest: 2020-01-10 12:38:23.513143243 +0000 UTC Remote: 2020-01-10 12:38:23.511827025 +0000 UTC m=+144.756872363 (delta=1.316218ms)
                I0110 12:38:23.648641    5832 cluster.go:181] guest clock delta is within tolerance: 1.316218ms
                I0110 12:38:23.648678    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetConfigRaw
                I0110 12:38:23.649465    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:23.649701    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:23.649951    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:23.659350    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:23.659602    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:23.659855    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:23.699002    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetIP
                ! You appear to be using a proxy, but your NO_PROXY environment does not include the minikube IP (192.168.39.202). Please see https://minikube.sigs.k8s.io/docs/reference/networking/proxy/ for more details
                I0110 12:38:23.709287    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:23.709528    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:23.710282    5832 ssh_runner.go:102] Run: nslookup kubernetes.io
                I0110 12:38:23.761681    5832 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
                I0110 12:38:23.806355    5832 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/offline-crio-20200110T123558.75214308-4968/config.json ...
                I0110 12:38:23.806788    5832 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
                I0110 12:38:23.822638    5832 ssh_runner.go:102] Run: systemctl is-active --quiet service docker
                I0110 12:38:23.832754    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///var/run/crio/crio.sock
                image-endpoint: unix:///var/run/crio/crio.sock
                " | sudo tee /etc/crictl.yaml"
                I0110 12:38:23.852672    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc/crio && printf %s "# The CRI-O configuration file specifies all of the available configuration
# options and command-line flags for the crio(8) OCI Kubernetes Container Runtime
# daemon, but in a TOML format that can be more easily modified and versioned.
#
# Please refer to crio.conf(5) for details of all configuration options.

# CRI-O supports partial configuration reload during runtime, which can be
# done by sending SIGHUP to the running process. Currently supported options
# are explicitly mentioned with: 'This option supports live configuration
# reload'.

# CRI-O reads its storage defaults from the containers-storage.conf(5) file
# located at /etc/containers/storage.conf. Modify this storage configuration if
# you want to change the system's defaults. If you want to modify storage just
# for CRI-O, you can change the storage configuration options here.
[crio]

# Path to the "root directory". CRI-O stores all of its data, including
# containers images, in this directory.
root = "/var/lib/containers/storage"

# Path to the "run directory". CRI-O stores all of its state in this directory.
runroot = "/var/run/containers/storage"

# Storage driver used to manage the storage of images and containers. Please
# refer to containers-storage.conf(5) to see all available storage drivers.
storage_driver = "overlay"

# List to pass options to the storage driver. Please refer to
# containers-storage.conf(5) to see all available storage options.
#storage_option = [
#]

# If set to false, in-memory locking will be used instead of file-based locking.
# **Deprecated** this option will be removed in the future.
file_locking = false

# Path to the lock file.
# **Deprecated** this option will be removed in the future.
file_locking_path = "/run/crio.lock"


# The crio.api table contains settings for the kubelet/gRPC interface.
[crio.api]

# Path to AF_LOCAL socket on which CRI-O will listen.
listen = "/var/run/crio/crio.sock"

# IP address on which the stream server will listen.
stream_address = "127.0.0.1"

# The port on which the stream server will listen.
stream_port = "0"

# Enable encrypted TLS transport of the stream server.
stream_enable_tls = false

# Path to the x509 certificate file used to serve the encrypted stream. This
# file can change, and CRI-O will automatically pick up the changes within 5
# minutes.
stream_tls_cert = ""

# Path to the key file used to serve the encrypted stream. This file can
# change, and CRI-O will automatically pick up the changes within 5 minutes.
stream_tls_key = ""

# Path to the x509 CA(s) file used to verify and authenticate client
# communication with the encrypted stream. This file can change, and CRI-O will
# automatically pick up the changes within 5 minutes.
stream_tls_ca = ""

# Maximum grpc send message size in bytes. If not set or &lt;=0, then CRI-O will default to 16 * 1024 * 1024.
grpc_max_send_msg_size = 16777216

# Maximum grpc receive message size. If not set or &lt;= 0, then CRI-O will default to 16 * 1024 * 1024.
grpc_max_recv_msg_size = 16777216

# The crio.runtime table contains settings pertaining to the OCI runtime used
# and options for how to set up and manage the OCI runtime.
[crio.runtime]

# A list of ulimits to be set in containers by default, specified as
# "<ulimit name>=<soft limit>:<hard limit>", for example:
# "nofile=1024:2048"
# If nothing is set here, settings will be inherited from the CRI-O daemon
#default_ulimits = [
#]

# default_runtime is the _name_ of the OCI runtime to be used as the default.
# The name is matched against the runtimes map below.
default_runtime = "runc"

# If true, the runtime will not use pivot_root, but instead use MS_MOVE.
no_pivot = true

# Path to the conmon binary, used for monitoring the OCI runtime.
conmon = "/usr/libexec/crio/conmon"

# Cgroup setting for conmon
conmon_cgroup = "pod"

# Environment variable list for the conmon process, used for passing necessary
# environment variables to conmon or the runtime.
conmon_env = [
	"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin",
]

# If true, SELinux will be used for pod separation on the host.
selinux = false

# Path to the seccomp.json profile which is used as the default seccomp profile
# for the runtime. If not specified, then the internal default seccomp profile
# will be used.
seccomp_profile = ""

# Used to change the name of the default AppArmor profile of CRI-O. The default
# profile name is "crio-default-" followed by the version string of CRI-O.
apparmor_profile = "crio-default"

# Cgroup management implementation used for the runtime.
cgroup_manager = "cgroupfs"

# List of default capabilities for containers. If it is empty or commented out,
# only the capabilities defined in the containers json file by the user/kube
# will be added.
default_capabilities = [
	"CHOWN",
	"DAC_OVERRIDE",
	"FSETID",
	"FOWNER",
	"NET_RAW",
	"SETGID",
	"SETUID",
	"SETPCAP",
	"NET_BIND_SERVICE",
	"SYS_CHROOT",
	"KILL",
]

# List of default sysctls. If it is empty or commented out, only the sysctls
# defined in the container json file by the user/kube will be added.
default_sysctls = [
]

# List of additional devices. specified as
# "<device-on-host>:<device-on-container>:<permissions>", for example: "--device=/dev/sdc:/dev/xvdc:rwm".
#If it is empty or commented out, only the devices
# defined in the container json file by the user/kube will be added.
additional_devices = [
]

# Path to OCI hooks directories for automatically executed hooks.
hooks_dir = [
]

# List of default mounts for each container. **Deprecated:** this option will
# be removed in future versions in favor of default_mounts_file.
default_mounts = [
]

# Path to the file specifying the defaults mounts for each container. The
# format of the config is /SRC:/DST, one mount per line. Notice that CRI-O reads
# its default mounts from the following two files:
#
#   1) /etc/containers/mounts.conf (i.e., default_mounts_file): This is the
#      override file, where users can either add in their own default mounts, or
#      override the default mounts shipped with the package.
#
#   2) /usr/share/containers/mounts.conf: This is the default file read for
#      mounts. If you want CRI-O to read from a different, specific mounts file,
#      you can change the default_mounts_file. Note, if this is done, CRI-O will
#      only add mounts it finds in this file.
#
#default_mounts_file = ""

# Maximum number of processes allowed in a container.
pids_limit = 1024

# Maximum sized allowed for the container log file. Negative numbers indicate
# that no size limit is imposed. If it is positive, it must be >= 8192 to
# match/exceed conmon's read buffer. The file is truncated and re-opened so the
# limit is never exceeded.
log_size_max = -1

# Whether container output should be logged to journald in addition to the kuberentes log file
log_to_journald = false

# Path to directory in which container exit files are written to by conmon.
container_exits_dir = "/var/run/crio/exits"

# Path to directory for container attach sockets.
container_attach_socket_dir = "/var/run/crio"

# If set to true, all containers will run in read-only mode.
read_only = false

# Changes the verbosity of the logs based on the level it is set to. Options
# are fatal, panic, error, warn, info, and debug. This option supports live
# configuration reload.
log_level = "error"

# The default log directory where all logs will go unless directly specified by the kubelet
log_dir = "/var/log/crio/pods"

# The UID mappings for the user namespace of each container. A range is
# specified in the form containerUID:HostUID:Size. Multiple ranges must be
# separated by comma.
uid_mappings = ""

# The GID mappings for the user namespace of each container. A range is
# specified in the form containerGID:HostGID:Size. Multiple ranges must be
# separated by comma.
gid_mappings = ""

# The minimal amount of time in seconds to wait before issuing a timeout
# regarding the proper termination of the container.
ctr_stop_timeout = 0

# ManageNetworkNSLifecycle determines whether we pin and remove network namespace
# and manage its lifecycle.
manage_network_ns_lifecycle = false

# The "crio.runtime.runtimes" table defines a list of OCI compatible runtimes.
# The runtime to use is picked based on the runtime_handler provided by the CRI.
# If no runtime_handler is provided, the runtime will be picked based on the level
# of trust of the workload.

[crio.runtime.runtimes.runc]
runtime_path = "/usr/bin/runc"
runtime_type = "oci"
runtime_root = "/run/runc"


# The crio.image table contains settings pertaining to the management of OCI images.
#
# CRI-O reads its configured registries defaults from the system wide
# containers-registries.conf(5) located in /etc/containers/registries.conf. If
# you want to modify just CRI-O, you can change the registries configuration in
# this file. Otherwise, leave insecure_registries and registries commented out to
# use the system's defaults from /etc/containers/registries.conf.
[crio.image]

# Default transport for pulling images from a remote container storage.
default_transport = "docker://"

# The path to a file containing credentials necessary for pulling images from
# secure registries. The file is similar to that of /var/lib/kubelet/config.json
global_auth_file = ""

# The image used to instantiate infra containers.
# This option supports live configuration reload.
pause_image = "k8s.gcr.io/pause:3.1"

# The path to a file containing credentials specific for pulling the pause_image from
# above. The file is similar to that of /var/lib/kubelet/config.json
# This option supports live configuration reload.
pause_image_auth_file = ""

# The command to run to have a container stay in the paused state.
# This option supports live configuration reload.
pause_command = "/pause"

# Path to the file which decides what sort of policy we use when deciding
# whether or not to trust an image that we've pulled. It is not recommended that
# this option be used, as the default behavior of using the system-wide default
# policy (i.e., /etc/containers/policy.json) is most often preferred. Please
# refer to containers-policy.json(5) for more details.
signature_policy = ""

# Controls how image volumes are handled. The valid values are mkdir, bind and
# ignore; the latter will ignore volumes entirely.
image_volumes = "mkdir"

# List of registries to be used when pulling an unqualified image (e.g.,
# "alpine:latest"). By default, registries is set to "docker.io" for
# compatibility reasons. Depending on your workload and usecase you may add more
# registries (e.g., "quay.io", "registry.fedoraproject.org",
# "registry.opensuse.org", etc.).
registries = [
	"docker.io"
]


# The crio.network table containers settings pertaining to the management of
# CNI plugins.
[crio.network]

# Path to the directory where CNI configuration files are located.
network_dir = "/etc/cni/net.d/"

# Paths to directories where CNI plugin binaries are located.
plugin_dirs = [
	"/opt/cni/bin/",
]
" | base64 -d | sudo tee /etc/crio/crio.conf"
                I0110 12:38:23.879700    5832 ssh_runner.go:102] Run: sudo modprobe br_netfilter
                I0110 12:38:23.901847    5832 ssh_runner.go:102] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
                I0110 12:38:23.914259    5832 ssh_runner.go:102] Run: sudo systemctl restart crio
                I0110 12:38:24.362942    5832 ssh_runner.go:102] Run: crio --version
                I0110 12:38:24.506174    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetURL
                I0110 12:38:24.511108    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) DBG | Using libvirt version 3000000
                I0110 12:38:24.520083    5832 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:24.520215    5832 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                I0110 12:38:24.522495    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:38:24.523070    5832 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
                I0110 12:38:24.523130    5832 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:38:24.538237    5832 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:33695
                I0110 12:38:24.538850    5832 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:38:24.539542    5832 main.go:110] libmachine: Using API Version  1
                I0110 12:38:24.539565    5832 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:38:24.540011    5832 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:38:24.540254    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:24.540454    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .DriverName
                I0110 12:38:24.540674    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHHostname
                I0110 12:38:24.550606    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHPort
                I0110 12:38:24.550866    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHKeyPath
                I0110 12:38:24.551085    5832 main.go:110] libmachine: (offline-crio-20200110T123558.75214308-4968) Calling .GetSSHUsername
                I0110 12:38:24.585834    5832 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
                I0110 12:38:24.585887    5832 cache_images.go:75] couldn't get a local image daemon which might be ok: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.585977    5832 image.go:73] retrieving image: index.docker.io/kubernetesui/metrics-scraper:v1.0.2
                I0110 12:38:24.586014    5832 image.go:73] retrieving image: k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:38:24.586033    5832 image.go:73] retrieving image: k8s.gcr.io/coredns:1.6.5
                I0110 12:38:24.586063    5832 image.go:81] daemon lookup for k8s.gcr.io/kube-proxy:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586068    5832 image.go:81] daemon lookup for k8s.gcr.io/coredns:1.6.5: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586087    5832 image.go:73] retrieving image: gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:38:24.586083    5832 image.go:73] retrieving image: k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:38:24.586112    5832 image.go:81] daemon lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586061    5832 image.go:73] retrieving image: k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:38:24.586122    5832 image.go:81] daemon lookup for k8s.gcr.io/kube-apiserver:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586134    5832 image.go:81] daemon lookup for k8s.gcr.io/kube-addon-manager:v9.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.585979    5832 image.go:73] retrieving image: k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:38:24.586134    5832 image.go:73] retrieving image: k8s.gcr.io/etcd:3.4.3-0
                I0110 12:38:24.586152    5832 image.go:73] retrieving image: index.docker.io/kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:38:24.586177    5832 image.go:81] daemon lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586176    5832 image.go:81] daemon lookup for k8s.gcr.io/etcd:3.4.3-0: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586039    5832 image.go:81] daemon lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586067    5832 image.go:73] retrieving image: k8s.gcr.io/pause:3.1
                I0110 12:38:24.586239    5832 image.go:81] daemon lookup for k8s.gcr.io/pause:3.1: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586131    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586274    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586153    5832 image.go:81] daemon lookup for k8s.gcr.io/kube-controller-manager:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586311    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586335    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586420    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586459    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586558    5832 image.go:73] retrieving image: k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:38:24.586614    5832 image.go:81] daemon lookup for k8s.gcr.io/kube-scheduler:v1.17.0: unable to parse docker host `172.16.1.1:1`
                I0110 12:38:24.586597    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586672    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586817    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586843    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586870    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586892    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.586947    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.586966    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.587017    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.587042    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.587102    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.587122    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.587185    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.587200    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                I0110 12:38:24.587276    5832 main.go:96] stdlog: keychain.go:109 Unable to read "/home/jenkins/.docker/config.json": open /home/jenkins/.docker/config.json: no such file or directory
                I0110 12:38:24.587293    5832 main.go:96] stdlog: options.go:51 No matching credentials were found, falling back on anonymous
                W0110 12:38:54.586644    5832 image.go:89] authn lookup for k8s.gcr.io/kube-controller-manager:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.586708    5832 image.go:89] authn lookup for k8s.gcr.io/coredns:1.6.5 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.586641    5832 image.go:89] authn lookup for k8s.gcr.io/kube-proxy:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.586904    5832 image.go:89] authn lookup for gcr.io/k8s-minikube/storage-provisioner:v1.8.1 (trying anon): Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587049    5832 image.go:89] authn lookup for k8s.gcr.io/kube-apiserver:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587079    5832 image.go:89] authn lookup for k8s.gcr.io/kube-addon-manager:v9.0.2 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587187    5832 image.go:89] authn lookup for index.docker.io/kubernetesui/dashboard:v2.0.0-beta8 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587260    5832 image.go:89] authn lookup for k8s.gcr.io/etcd:3.4.3-0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587360    5832 image.go:89] authn lookup for index.docker.io/kubernetesui/metrics-scraper:v1.0.2 (trying anon): Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587485    5832 image.go:89] authn lookup for k8s.gcr.io/pause:3.1 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                W0110 12:38:54.587495    5832 image.go:89] authn lookup for k8s.gcr.io/kube-scheduler:v1.17.0 (trying anon): Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout
                I0110 12:39:24.587069    5832 image.go:60] error retrieve Image k8s.gcr.io/coredns:1.6.5 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587121    5832 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: got empty img digest "" for k8s.gcr.io/coredns:1.6.5
                I0110 12:39:24.587147    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
                I0110 12:39:24.587145    5832 image.go:60] error retrieve Image k8s.gcr.io/kube-proxy:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587177    5832 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:39:24.587188    5832 image.go:60] error retrieve Image gcr.io/k8s-minikube/storage-provisioner:v1.8.1 ref Get https://gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587174    5832 image.go:60] error retrieve Image k8s.gcr.io/kube-controller-manager:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587209    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
                I0110 12:39:24.587236    5832 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:39:24.587254    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
                I0110 12:39:24.587216    5832 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: got empty img digest "" for gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:39:24.587290    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
                I0110 12:39:24.587296    5832 image.go:60] error retrieve Image k8s.gcr.io/kube-addon-manager:v9.0.2 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587313    5832 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: got empty img digest "" for k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:39:24.587332    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
                I0110 12:39:24.587393    5832 image.go:60] error retrieve Image kubernetesui/dashboard:v2.0.0-beta8 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587420    5832 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: got empty img digest "" for kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:39:24.587432    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
                I0110 12:39:24.587466    5832 image.go:60] error retrieve Image k8s.gcr.io/etcd:3.4.3-0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587486    5832 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: got empty img digest "" for k8s.gcr.io/etcd:3.4.3-0
                I0110 12:39:24.587498    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
                I0110 12:39:24.587553    5832 image.go:60] error retrieve Image kubernetesui/metrics-scraper:v1.0.2 ref Get https://index.docker.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587567    5832 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: got empty img digest "" for kubernetesui/metrics-scraper:v1.0.2
                I0110 12:39:24.587579    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
                I0110 12:39:24.587561    5832 image.go:60] error retrieve Image k8s.gcr.io/kube-apiserver:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587624    5832 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:39:24.587670    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
                I0110 12:39:24.587709    5832 image.go:60] error retrieve Image k8s.gcr.io/pause:3.1 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587753    5832 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: got empty img digest "" for k8s.gcr.io/pause:3.1
                I0110 12:39:24.587766    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
                I0110 12:39:24.587803    5832 image.go:60] error retrieve Image k8s.gcr.io/kube-scheduler:v1.17.0 ref Get https://k8s.gcr.io/v2/: proxyconnect tcp: dial tcp 172.16.1.1:1: i/o timeout 
                I0110 12:39:24.587846    5832 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: got empty img digest "" for k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:39:24.587881    5832 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
                I0110 12:39:24.597405    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
                I0110 12:39:24.598229    5832 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
                I0110 12:39:24.604648    5832 ssh_runner.go:194] pause_3.1: copied 356864 bytes
                I0110 12:39:24.614711    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
                I0110 12:39:24.620387    5832 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:39:24.620468    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
                I0110 12:39:24.620575    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:39:24.620709    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
                I0110 12:39:24.620774    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:39:24.622527    5832 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:39:24.622563    5832 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:39:24.622592    5832 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
                I0110 12:39:24.622565    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
                I0110 12:39:24.622634    5832 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:39:24.624699    5832 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:39:24.631472    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
                I0110 12:39:24.631516    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
                I0110 12:39:24.642671    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:39:24.648773    5832 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:39:24.702614    5832 crio.go:138] Loading image: /var/lib/minikube/images/pause_3.1
                I0110 12:39:24.702701    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/pause_3.1
                I0110 12:39:24.707915    5832 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:39:24.707923    5832 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:39:24.719342    5832 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:39:24.725105    5832 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:39:25.582565    5832 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
                I0110 12:39:25.843155    5832 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
                I0110 12:39:26.235084    5832 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
                I0110 12:39:26.672956    5832 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
                I0110 12:39:27.025769    5832 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
                I0110 12:39:27.140660    5832 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
                I0110 12:39:27.268379    5832 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
                I0110 12:39:27.398137    5832 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
                I0110 12:39:27.483630    5832 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
                I0110 12:39:27.805515    5832 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
                I0110 12:39:31.603949    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/pause_3.1: (6.901216375s)
                I0110 12:39:31.603987    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
                I0110 12:39:31.604010    5832 crio.go:138] Loading image: /var/lib/minikube/images/coredns_1.6.5
                I0110 12:39:31.604067    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/coredns_1.6.5
                I0110 12:39:37.089996    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/coredns_1.6.5: (5.485897195s)
                I0110 12:39:37.090035    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
                I0110 12:39:37.090060    5832 crio.go:138] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:39:37.090127    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:39:40.699838    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/metrics-scraper_v1.0.2: (3.609680517s)
                I0110 12:39:40.699877    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
                I0110 12:39:40.699902    5832 crio.go:138] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:39:40.699965    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:39:45.772545    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/storage-provisioner_v1.8.1: (5.072543516s)
                I0110 12:39:45.772577    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
                I0110 12:39:45.772598    5832 crio.go:138] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:39:45.772673    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:39:52.927398    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2: (7.154692474s)
                I0110 12:39:52.927439    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
                I0110 12:39:52.927466    5832 crio.go:138] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:39:52.927528    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:39:57.780229    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8: (4.852669648s)
                I0110 12:39:57.780270    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
                I0110 12:39:57.780296    5832 crio.go:138] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:39:57.780361    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:40:04.675164    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/kube-scheduler_v1.17.0: (6.894765773s)
                I0110 12:40:04.675207    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
                I0110 12:40:04.675221    5832 crio.go:138] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:40:04.675284    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:40:11.127871    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/kube-proxy_v1.17.0: (6.45254484s)
                I0110 12:40:11.127902    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
                I0110 12:40:11.127913    5832 crio.go:138] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:40:11.127975    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:40:17.871791    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0: (6.743785065s)
                I0110 12:40:17.871825    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
                I0110 12:40:17.871843    5832 crio.go:138] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:40:17.871888    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:40:24.439896    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/kube-apiserver_v1.17.0: (6.567978399s)
                I0110 12:40:24.439933    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
                I0110 12:40:24.439960    5832 crio.go:138] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:40:24.440018    5832 ssh_runner.go:102] Run: sudo podman load -i /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:40:38.078305    5832 ssh_runner.go:142] Completed: sudo podman load -i /var/lib/minikube/images/etcd_3.4.3-0: (13.638256185s)
                I0110 12:40:38.078359    5832 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
                I0110 12:40:38.078378    5832 cache_images.go:93] Successfully loaded all cached images
                I0110 12:40:38.078385    5832 cache_images.go:94] LoadImages end
                I0110 12:40:38.078562    5832 kubeadm.go:390] kubelet [Unit]
                Wants=docker.socket
                
                [Service]
                ExecStart=
                ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=/var/run/crio/crio.sock --fail-swap-on=false --hostname-override=minikube --image-service-endpoint=/var/run/crio/crio.sock --kubeconfig=/etc/kubernetes/kubelet.conf --network-plugin=cni --node-ip=192.168.39.202 --pod-manifest-path=/etc/kubernetes/manifests --runtime-request-timeout=15m
                
                [Install]
                 config:
                {KubernetesVersion:v1.17.0 NodeIP:192.168.39.202 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:crio CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:40:38.078597    5832 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
                W0110 12:40:38.093840    5832 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
                stdout:
                
                stderr:
                 command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
                I0110 12:40:38.094007    5832 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
                I0110 12:40:38.094053    5832 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
                I0110 12:40:38.106089    5832 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
                I0110 12:40:38.106620    5832 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
                I0110 12:40:38.107823    5832 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
                I0110 12:40:38.109704    5832 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
                I0110 12:40:38.542601    5832 ssh_runner.go:194] kubeadm: copied 39342080 bytes
                I0110 12:40:38.973074    5832 ssh_runner.go:194] kubelet: copied 111560216 bytes
                I0110 12:40:38.988394    5832 ssh_runner.go:175] Transferring 1151 bytes to /var/tmp/minikube/kubeadm.yaml
                I0110 12:40:38.989937    5832 ssh_runner.go:194] kubeadm.yaml: copied 1151 bytes
                I0110 12:40:39.007125    5832 ssh_runner.go:175] Transferring 714 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                I0110 12:40:39.008811    5832 ssh_runner.go:194] 10-kubeadm.conf: copied 714 bytes
                I0110 12:40:39.026611    5832 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
                I0110 12:40:39.027973    5832 ssh_runner.go:194] kubelet.service: copied 349 bytes
                I0110 12:40:39.048104    5832 ssh_runner.go:175] Transferring 341 bytes to /etc/cni/net.d/k8s.conf
                I0110 12:40:39.049196    5832 ssh_runner.go:194] k8s.conf: copied 341 bytes
                I0110 12:40:39.072349    5832 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
                I0110 12:40:39.073523    5832 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
                I0110 12:40:39.091621    5832 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
                I0110 12:40:39.092652    5832 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
                I0110 12:40:39.110503    5832 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
                I0110 12:40:39.111498    5832 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
                I0110 12:40:39.129287    5832 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
                I0110 12:40:39.130626    5832 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
                I0110 12:40:39.147264    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
                I0110 12:40:39.282481    5832 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.202
                I0110 12:40:39.282517    5832 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.282735    5832 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
                I0110 12:40:39.286047    5832 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
                I0110 12:40:39.286075    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.286313    5832 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
                I0110 12:40:39.286333    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.286482    5832 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.202 10.96.0.1 127.0.0.1 10.0.0.1]
                I0110 12:40:39.290006    5832 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
                I0110 12:40:39.290038    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.290279    5832 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
                I0110 12:40:39.290303    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.290497    5832 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
                I0110 12:40:39.294033    5832 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
                I0110 12:40:39.294062    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.294273    5832 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
                I0110 12:40:39.294303    5832 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:40:39.308064    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
                I0110 12:40:39.308692    5832 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
                I0110 12:40:39.310278    5832 ssh_runner.go:194] ca.crt: copied 1066 bytes
                I0110 12:40:39.379713    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
                I0110 12:40:39.380467    5832 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
                I0110 12:40:39.381996    5832 ssh_runner.go:194] ca.key: copied 1675 bytes
                I0110 12:40:39.421477    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
                I0110 12:40:39.421947    5832 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
                I0110 12:40:39.423836    5832 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
                I0110 12:40:39.451224    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
                I0110 12:40:39.452036    5832 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
                I0110 12:40:39.453871    5832 ssh_runner.go:194] apiserver.key: copied 1679 bytes
                I0110 12:40:39.482826    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
                I0110 12:40:39.483598    5832 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
                I0110 12:40:39.484911    5832 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
                I0110 12:40:39.520856    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
                I0110 12:40:39.521629    5832 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
                I0110 12:40:39.523020    5832 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
                I0110 12:40:39.558606    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
                I0110 12:40:39.559214    5832 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
                I0110 12:40:39.560181    5832 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
                I0110 12:40:39.598965    5832 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
                I0110 12:40:39.599801    5832 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
                I0110 12:40:39.600982    5832 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
                I0110 12:40:39.647447    5832 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
                I0110 12:40:39.648038    5832 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:40:39.649069    5832 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
                I0110 12:40:39.678735    5832 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
                I0110 12:40:39.679819    5832 ssh_runner.go:194] kubeconfig: copied 428 bytes
                I0110 12:40:39.706227    5832 ssh_runner.go:102] Run: openssl version
                I0110 12:40:39.717630    5832 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
                I0110 12:40:39.733437    5832 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
                I0110 12:40:39.743929    5832 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:40:39.776182    5832 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
                I0110 12:40:39.788680    5832 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
                I0110 12:40:39.801891    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
                I0110 12:40:40.069012    5832 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
                I0110 12:40:40.080727    5832 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
                stdout:
                
                stderr:
                ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
                ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
                ls: cannot access '/var/lib/minikube/etcd': No such file or directory
                I0110 12:40:40.080757    5832 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.202 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:crio CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:40:40.080803    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
                I0110 12:40:40.171260    5832 kubeadm.go:152] StartCluster complete in 90.476935ms
                I0110 12:40:40.171363    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-apiserver --state=Running --quiet
                I0110 12:40:40.279752    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.279783    5832 logs.go:180] No container was found matching "kube-apiserver"
                I0110 12:40:40.279838    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=coredns --state=Running --quiet
                I0110 12:40:40.313868    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.313908    5832 logs.go:180] No container was found matching "coredns"
                I0110 12:40:40.313966    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-scheduler --state=Running --quiet
                I0110 12:40:40.336679    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.336705    5832 logs.go:180] No container was found matching "kube-scheduler"
                I0110 12:40:40.336760    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-proxy --state=Running --quiet
                I0110 12:40:40.362153    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.362230    5832 logs.go:180] No container was found matching "kube-proxy"
                I0110 12:40:40.362286    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-addon-manager --state=Running --quiet
                I0110 12:40:40.385346    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.385390    5832 logs.go:180] No container was found matching "kube-addon-manager"
                I0110 12:40:40.385452    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kubernetes-dashboard --state=Running --quiet
                I0110 12:40:40.408939    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.408985    5832 logs.go:180] No container was found matching "kubernetes-dashboard"
                I0110 12:40:40.409062    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=storage-provisioner --state=Running --quiet
                I0110 12:40:40.431612    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.431645    5832 logs.go:180] No container was found matching "storage-provisioner"
                I0110 12:40:40.431697    5832 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-controller-manager --state=Running --quiet
                I0110 12:40:40.454046    5832 logs.go:178] 0 containers: []
                W0110 12:40:40.454086    5832 logs.go:180] No container was found matching "kube-controller-manager"
                I0110 12:40:40.454104    5832 logs.go:92] Gathering logs for kubelet ...
                I0110 12:40:40.454147    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
                I0110 12:40:40.469749    5832 logs.go:92] Gathering logs for dmesg ...
                I0110 12:40:40.469783    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
                I0110 12:40:40.487907    5832 logs.go:92] Gathering logs for CRI-O ...
                I0110 12:40:40.487943    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u crio -n 400"
                I0110 12:40:40.520133    5832 logs.go:92] Gathering logs for container status ...
                I0110 12:40:40.520208    5832 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
                W0110 12:40:40.560881    5832 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:40:40.167597    2570 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:40:40.167597    2570 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            aab_offline_test.go:58: [out/minikube-linux-amd64 start -p offline-crio-20200110T123558.75214308-4968 --alsologtostderr -v=1 --wait=true --container-runtime crio --vm-driver=kvm2 ] failed: exit status 70
            panic.go:563: *** TestOffline/group/crio FAILED at 2020-01-10 12:40:40.564790367 +0000 UTC m=+461.209809239
            panic.go:563: >>> TestOffline/group/crio FAILED: start of post-mortem logs >>>
            panic.go:563: (dbg) Run:  kubectl --context offline-crio-20200110T123558.75214308-4968 get po -A --show-labels
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-crio-20200110T123558.75214308-4968 get po -A --show-labels: exit status 1 (204.154257ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.202:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-crio-20200110T123558.75214308-4968 get po -A --show-labels: exit status 1
            panic.go:563: (dbg) kubectl --context offline-crio-20200110T123558.75214308-4968 get po -A --show-labels:
            panic.go:563: (dbg) Run:  kubectl --context offline-crio-20200110T123558.75214308-4968 describe node
            panic.go:563: (dbg) Non-zero exit: kubectl --context offline-crio-20200110T123558.75214308-4968 describe node: exit status 1 (83.582643ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.202:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context offline-crio-20200110T123558.75214308-4968 describe node: exit status 1
            panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p offline-crio-20200110T123558.75214308-4968 logs --problems
            panic.go:563: TestOffline/group/crio logs: 
            panic.go:563: <<< TestOffline/group/crio FAILED: end of post-mortem logs <<<
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p offline-crio-20200110T123558.75214308-4968
            helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p offline-crio-20200110T123558.75214308-4968: (1.58602332s)
=== RUN   TestAddons
--- FAIL: TestAddons (114.67s)
    helpers.go:376: No need to wait for start slot, it is already 2020-01-10 12:40:42.949515178 +0000 UTC m=+463.594533952
    addons_test.go:45: (dbg) Run:  out/minikube-linux-amd64 start -p addons-20200110T124042.949563487-4968 --wait=false --memory=2600 --alsologtostderr -v=1 --addons=ingress --addons=registry --addons=metrics-server --vm-driver=kvm2 
    addons_test.go:45: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p addons-20200110T124042.949563487-4968 --wait=false --memory=2600 --alsologtostderr -v=1 --addons=ingress --addons=registry --addons=metrics-server --vm-driver=kvm2 : exit status 70 (1m49.045651274s)
        -- stdout --
        * [addons-20200110T124042.949563487-4968] minikube v1.6.2 on Debian 9.11
          - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
          - MINIKUBE_BIN=out/minikube-linux-amd64
          - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
          - MINIKUBE_LOCATION=6150
        * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
        * Creating kvm2 VM (CPUs=2, Memory=2600MB, Disk=20000MB) ...
        * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
        * Pulling images ...
        * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:42:29.307850    2861 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * Launching Kubernetes ... 
        
        -- /stdout --
        ** stderr ** 
        I0110 12:40:42.987999    6998 notify.go:125] Checking for updates...
        I0110 12:40:43.116439    6998 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1392,"bootTime":1578658651,"procs":200,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
        I0110 12:40:43.117095    6998 start.go:266] virtualization: kvm host
        I0110 12:40:43.117387    6998 start.go:567] selectDriver: flag="kvm2", old=<nil>
        I0110 12:40:43.117416    6998 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:40:43.235511    6998 global.go:68] docker priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:40:45.234316    6998 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:40:45.234388    6998 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:40:45.440500    6998 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:40:45.440597    6998 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
        I0110 12:40:45.440639    6998 driver.go:128] requested: "kvm2"
        I0110 12:40:45.440648    6998 driver.go:132] choosing "kvm2" because it was requested
        I0110 12:40:45.440655    6998 driver.go:147] not recommending "docker" due to priority: 2
        I0110 12:40:45.440665    6998 driver.go:147] not recommending "none" due to priority: 2
        I0110 12:40:45.440672    6998 driver.go:165] Picked: kvm2
        I0110 12:40:45.440682    6998 driver.go:166] Alternatives: [virtualbox docker none]
        I0110 12:40:45.440757    6998 start.go:298] selected driver: kvm2
        I0110 12:40:45.440762    6998 start.go:597] validating driver "kvm2" against <nil>
        I0110 12:40:45.474544    6998 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:40:45.474699    6998 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:40:45.489327    6998 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
        I0110 12:40:45.489558    6998 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/addons-20200110T124042.949563487-4968/config.json ...
        I0110 12:40:45.489646    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
        I0110 12:40:45.489662    6998 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "37.815Âµs"
        I0110 12:40:45.489677    6998 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
        I0110 12:40:45.489697    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
        I0110 12:40:45.489693    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
        I0110 12:40:45.489716    6998 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "48.398Âµs"
        I0110 12:40:45.489668    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/addons-20200110T124042.949563487-4968/config.json: {Name:mkdd42631f225cf796a1ce60f406da2780cb361f Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:40:45.489766    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
        I0110 12:40:45.489707    6998 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "19.786Âµs"
        I0110 12:40:45.489789    6998 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "44.172Âµs"
        I0110 12:40:45.489794    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
        I0110 12:40:45.489804    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
        I0110 12:40:45.489844    6998 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "55.007Âµs"
        I0110 12:40:45.489856    6998 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
        I0110 12:40:45.489774    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
        I0110 12:40:45.489873    6998 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "127.77Âµs"
        I0110 12:40:45.489799    6998 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
        I0110 12:40:45.489737    6998 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
        I0110 12:40:45.489772    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
        I0110 12:40:45.489900    6998 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "145.276Âµs"
        I0110 12:40:45.489910    6998 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
        I0110 12:40:45.489780    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
        I0110 12:40:45.489918    6998 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "153.988Âµs"
        I0110 12:40:45.489927    6998 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
        I0110 12:40:45.489729    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
        I0110 12:40:45.489940    6998 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "238.417Âµs"
        I0110 12:40:45.489949    6998 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
        I0110 12:40:45.489805    6998 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
        I0110 12:40:45.489811    6998 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "52.863Âµs"
        I0110 12:40:45.489969    6998 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
        I0110 12:40:45.489823    6998 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
        I0110 12:40:45.489979    6998 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "177.022Âµs"
        I0110 12:40:45.489991    6998 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
        I0110 12:40:45.489882    6998 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
        I0110 12:40:45.490000    6998 cache.go:70] Successfully saved all images to host disk.
        I0110 12:40:45.490008    6998 cluster.go:96] Machine does not exist... provisioning new machine
        I0110 12:40:45.490020    6998 cluster.go:97] Provisioning machine with config: {Name:addons-20200110T124042.949563487-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2600 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
        I0110 12:40:45.490295    6998 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
        I0110 12:40:45.490342    6998 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:40:45.504079    6998 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:43561
        I0110 12:40:45.504635    6998 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:40:45.505415    6998 main.go:110] libmachine: Using API Version  1
        I0110 12:40:45.505457    6998 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:40:45.505985    6998 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:40:45.506261    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetMachineName
        I0110 12:40:45.506475    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:40:45.506818    6998 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
        I0110 12:40:45.506865    6998 main.go:110] libmachine: Decoding PEM data...
        I0110 12:40:45.506882    6998 main.go:110] libmachine: Parsing certificate...
        I0110 12:40:45.506986    6998 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
        I0110 12:40:45.507015    6998 main.go:110] libmachine: Decoding PEM data...
        I0110 12:40:45.507028    6998 main.go:110] libmachine: Parsing certificate...
        I0110 12:40:45.507093    6998 main.go:110] libmachine: Running pre-create checks...
        I0110 12:40:45.507108    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .PreCreateCheck
        I0110 12:40:45.507514    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetConfigRaw
        I0110 12:40:45.508079    6998 main.go:110] libmachine: Creating machine...
        I0110 12:40:45.508111    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .Create
        I0110 12:40:45.508337    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Creating KVM machine...
        I0110 12:40:45.869986    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968 ...
        I0110 12:40:45.870041    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | ERROR: logging before flag.Parse: I0110 12:40:45.869876    7161 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
        I0110 12:40:45.870060    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
        I0110 12:40:45.870161    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
        I0110 12:40:45.999595    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | ERROR: logging before flag.Parse: I0110 12:40:45.999412    7161 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968/id_rsa...
        I0110 12:40:46.495541    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | ERROR: logging before flag.Parse: I0110 12:40:46.495343    7161 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968/addons-20200110T124042.949563487-4968.rawdisk...
        I0110 12:40:46.495585    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Writing magic tar header
        I0110 12:40:46.495605    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Writing SSH key tar header
        I0110 12:40:46.495621    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | ERROR: logging before flag.Parse: I0110 12:40:46.495549    7161 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968 ...
        I0110 12:40:46.495788    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968
        I0110 12:40:46.495830    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
        I0110 12:40:46.495868    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968 (perms=drwx------)
        I0110 12:40:46.495901    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
        I0110 12:40:46.495935    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
        I0110 12:40:46.495966    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
        I0110 12:40:46.495993    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
        I0110 12:40:46.496026    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
        I0110 12:40:46.496056    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
        I0110 12:40:46.496109    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
        I0110 12:40:46.496129    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
        I0110 12:40:46.496159    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Creating domain...
        I0110 12:40:46.496205    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home/jenkins
        I0110 12:40:46.496245    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Checking permissions on dir: /home
        I0110 12:40:46.496263    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Skipping /home - not owner
        I0110 12:40:46.528330    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Creating network...
        I0110 12:40:46.531738    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Ensuring networks are active...
        I0110 12:40:46.534693    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Ensuring network default is active
        I0110 12:40:46.535221    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Ensuring network minikube-net is active
        I0110 12:40:46.535882    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Getting domain xml...
        I0110 12:40:46.538866    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Creating domain...
        I0110 12:40:47.018436    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Waiting to get IP...
        I0110 12:40:47.026085    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 0/40
        I0110 12:40:50.033548    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 1/40
        I0110 12:40:53.040706    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 2/40
        I0110 12:40:56.047702    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 3/40
        I0110 12:40:59.055515    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 4/40
        I0110 12:41:02.063150    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 5/40
        I0110 12:41:05.071192    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 6/40
        I0110 12:41:08.079367    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 7/40
        I0110 12:41:11.086445    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 8/40
        I0110 12:41:14.094309    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 9/40
        I0110 12:41:17.101794    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 10/40
        I0110 12:41:20.108909    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Waiting for machine to come up 11/40
        I0110 12:41:23.115840    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Getting to WaitForSSH function...
        I0110 12:41:23.115876    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Found IP for machine: 192.168.39.50
        I0110 12:41:23.115897    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Waiting for SSH to be available...
        I0110 12:41:23.140514    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Using SSH client type: external
        I0110 12:41:23.140564    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968/id_rsa (-rw-------)
        I0110 12:41:23.140663    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.50 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/addons-20200110T124042.949563487-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:41:23.140697    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | About to run SSH command:
        I0110 12:41:23.140719    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | exit 0
        I0110 12:41:23.292491    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | SSH cmd err, output: <nil>: 
        I0110 12:41:23.293181    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) KVM machine creation complete!
        I0110 12:41:23.293320    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetConfigRaw
        I0110 12:41:23.294103    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:23.294312    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:23.294606    6998 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
        I0110 12:41:23.294625    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetState
        I0110 12:41:23.298554    6998 main.go:110] libmachine: Detecting operating system of created instance...
        I0110 12:41:23.298577    6998 main.go:110] libmachine: Waiting for SSH to be available...
        I0110 12:41:23.298584    6998 main.go:110] libmachine: Getting to WaitForSSH function...
        I0110 12:41:23.298593    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:23.304935    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:23.305138    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.305352    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.305525    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:23.305723    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:23.305962    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:23.305982    6998 main.go:110] libmachine: About to run SSH command:
        exit 0
        I0110 12:41:23.437128    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:41:23.437170    6998 main.go:110] libmachine: Detecting the provisioner...
        I0110 12:41:23.437199    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:23.444778    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:23.445027    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.445315    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.445542    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:23.445798    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:23.446101    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:23.446125    6998 main.go:110] libmachine: About to run SSH command:
        cat /etc/os-release
        I0110 12:41:23.575601    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
        VERSION=2019.02.7
        ID=buildroot
        VERSION_ID=2019.02.7
        PRETTY_NAME="Buildroot 2019.02.7"
        
        I0110 12:41:23.575669    6998 main.go:110] libmachine: found compatible host: buildroot
        I0110 12:41:23.575685    6998 main.go:110] libmachine: Provisioning with buildroot...
        I0110 12:41:23.575702    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetMachineName
        I0110 12:41:23.576058    6998 main.go:110] libmachine: setting hostname "addons-20200110T124042.949563487-4968"
        I0110 12:41:23.576097    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetMachineName
        I0110 12:41:23.576329    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:23.584000    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:23.584244    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.584459    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.584665    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:23.584923    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:23.585107    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:23.585149    6998 main.go:110] libmachine: About to run SSH command:
        sudo hostname addons-20200110T124042.949563487-4968 && echo "addons-20200110T124042.949563487-4968" | sudo tee /etc/hostname
        I0110 12:41:23.733006    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: addons-20200110T124042.949563487-4968
        
        I0110 12:41:23.733042    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:23.740348    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:23.740581    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.740751    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:23.740959    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:23.741207    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:23.741404    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:23.741435    6998 main.go:110] libmachine: About to run SSH command:
        
        		if ! grep -xq '.*\saddons-20200110T124042.949563487-4968' /etc/hosts; then
        			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
        				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 addons-20200110T124042.949563487-4968/g' /etc/hosts;
        			else 
        				echo '127.0.1.1 addons-20200110T124042.949563487-4968' | sudo tee -a /etc/hosts; 
        			fi
        		fi
        I0110 12:41:23.874028    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:41:23.874134    6998 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
        I0110 12:41:23.874144    6998 main.go:110] libmachine: setting up certificates
        I0110 12:41:23.874166    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetMachineName
        I0110 12:41:23.874514    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetIP
        I0110 12:41:23.882399    6998 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.addons-20200110T124042.949563487-4968 san=[192.168.39.50 localhost]
        I0110 12:41:24.030332    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.037680    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.037905    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.038099    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.127751    6998 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
        I0110 12:41:24.128195    6998 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
        I0110 12:41:24.129237    6998 ssh_runner.go:194] ca.pem: copied 1038 bytes
        I0110 12:41:24.153711    6998 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
        I0110 12:41:24.154128    6998 ssh_runner.go:175] Transferring 1151 bytes to /etc/docker/server.pem
        I0110 12:41:24.155028    6998 ssh_runner.go:194] server.pem: copied 1151 bytes
        I0110 12:41:24.177943    6998 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
        I0110 12:41:24.178588    6998 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
        I0110 12:41:24.179447    6998 ssh_runner.go:194] server-key.pem: copied 1675 bytes
        I0110 12:41:24.197735    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetMachineName
        I0110 12:41:24.198290    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:24.198536    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.206503    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.206795    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.207013    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.207229    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.207444    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:24.207688    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:24.207709    6998 main.go:110] libmachine: About to run SSH command:
        df --output=fstype / | tail -n 1
        I0110 12:41:24.341675    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
        
        I0110 12:41:24.341711    6998 main.go:110] libmachine: root file system type: tmpfs
        I0110 12:41:24.341892    6998 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
        I0110 12:41:24.341933    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.349661    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.349882    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.350132    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.350330    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.350563    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:24.350832    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:24.350964    6998 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
        ExecReload=/bin/kill -s HUP $MAINPID
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        " | sudo tee /lib/systemd/system/docker.service
        I0110 12:41:24.492672    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
        ExecReload=/bin/kill -s HUP 
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        
        I0110 12:41:24.492718    6998 main.go:110] libmachine: setting minikube options for container-runtime
        I0110 12:41:24.492834    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.500701    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.500952    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.501236    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.501489    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.501748    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:24.501953    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:24.501995    6998 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /etc/sysconfig && printf %s "
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        " | sudo tee /etc/sysconfig/crio.minikube
        I0110 12:41:24.639865    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        
        I0110 12:41:24.639898    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.647325    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.647567    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.647778    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.647954    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.648181    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:24.648407    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:24.648426    6998 main.go:110] libmachine: About to run SSH command:
        sudo systemctl daemon-reload
        I0110 12:41:24.920079    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:41:24.920116    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:24.928213    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:24.928483    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.928713    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:24.928962    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:24.929247    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:24.929517    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:24.929545    6998 main.go:110] libmachine: About to run SSH command:
        sudo systemctl -f restart crio
        I0110 12:41:32.669805    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:41:32.669840    6998 main.go:110] libmachine: Checking connection to Docker...
        I0110 12:41:32.669858    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetURL
        I0110 12:41:32.674266    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Using libvirt version 3000000
        I0110 12:41:32.681863    6998 main.go:110] libmachine: Docker is up and running!
        I0110 12:41:32.681885    6998 main.go:110] libmachine: Reticulating splines...
        I0110 12:41:32.681895    6998 main.go:110] libmachine: Waiting for SSH to be available...
        I0110 12:41:32.681902    6998 main.go:110] libmachine: Getting to WaitForSSH function...
        I0110 12:41:32.681912    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:32.689312    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:32.689615    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.689842    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.690032    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:32.690274    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:32.690488    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:32.690511    6998 main.go:110] libmachine: About to run SSH command:
        exit 0
        I0110 12:41:32.821818    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:41:32.821868    6998 main.go:110] libmachine: Detecting the provisioner...
        I0110 12:41:32.821886    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:32.829358    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:32.829580    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.829815    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.830020    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:32.830217    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:32.830455    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:32.830483    6998 main.go:110] libmachine: About to run SSH command:
        cat /etc/os-release
        I0110 12:41:32.959744    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
        VERSION=2019.02.7
        ID=buildroot
        VERSION_ID=2019.02.7
        PRETTY_NAME="Buildroot 2019.02.7"
        
        I0110 12:41:32.959822    6998 main.go:110] libmachine: found compatible host: buildroot
        I0110 12:41:32.959838    6998 cluster.go:418] Provisioned with Buildroot 2019.02.7
        I0110 12:41:32.959857    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:32.967884    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:32.968131    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.968410    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:32.968638    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:32.968892    6998 main.go:110] libmachine: Using SSH client type: native
        I0110 12:41:32.969123    6998 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.50 22 <nil> <nil>}
        I0110 12:41:32.969149    6998 main.go:110] libmachine: About to run SSH command:
        date +%s.%N
        I0110 12:41:33.095685    6998 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578660092.976168959
        
        I0110 12:41:33.095716    6998 cluster.go:197] guest clock: 1578660092.976168959
        I0110 12:41:33.095726    6998 cluster.go:210] Guest: 2020-01-10 12:41:32.976168959 +0000 UTC Remote: 2020-01-10 12:41:32.959843398 +0000 UTC m=+50.006899560 (delta=16.325561ms)
        I0110 12:41:33.095749    6998 cluster.go:181] guest clock delta is within tolerance: 16.325561ms
        I0110 12:41:33.095774    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetConfigRaw
        I0110 12:41:33.096617    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:33.096946    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:33.097170    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:33.104780    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:33.105043    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:33.105291    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:33.143756    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetIP
        I0110 12:41:33.151186    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:33.151421    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:33.152228    6998 ssh_runner.go:102] Run: nslookup kubernetes.io
        I0110 12:41:33.199230    6998 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
        I0110 12:41:33.237269    6998 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/addons-20200110T124042.949563487-4968/config.json ...
        I0110 12:41:33.237641    6998 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
        I0110 12:41:33.249856    6998 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:41:33.259047    6998 ssh_runner.go:102] Run: sudo systemctl stop crio
        I0110 12:41:33.415597    6998 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:41:33.427840    6998 ssh_runner.go:102] Run: sudo systemctl start docker
        I0110 12:41:34.473619    6998 ssh_runner.go:142] Completed: sudo systemctl start docker: (1.045737175s)
        I0110 12:41:34.473707    6998 ssh_runner.go:102] Run: docker version --format '{{.Server.Version}}'
        I0110 12:41:34.735604    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetURL
        I0110 12:41:34.739573    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) DBG | Using libvirt version 3000000
        I0110 12:41:34.746332    6998 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:41:34.746449    6998 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
        I0110 12:41:34.750321    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:41:34.751009    6998 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
        I0110 12:41:34.751074    6998 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:41:34.764498    6998 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:40529
        I0110 12:41:34.765193    6998 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:41:34.765809    6998 main.go:110] libmachine: Using API Version  1
        I0110 12:41:34.765831    6998 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:41:34.766283    6998 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:41:34.766517    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:34.766712    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .DriverName
        I0110 12:41:34.766946    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHHostname
        I0110 12:41:34.774502    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHPort
        I0110 12:41:34.774748    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHKeyPath
        I0110 12:41:34.774955    6998 main.go:110] libmachine: (addons-20200110T124042.949563487-4968) Calling .GetSSHUsername
        I0110 12:41:34.816591    6998 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
        I0110 12:41:34.819445    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/metrics-scraper:v1.0.2
        I0110 12:41:34.819465    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/dashboard:v2.0.0-beta8
        I0110 12:41:34.819476    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-proxy:v1.17.0
        I0110 12:41:34.819465    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/etcd:3.4.3-0
        I0110 12:41:34.819704    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-apiserver:v1.17.0
        I0110 12:41:34.819725    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-scheduler:v1.17.0
        I0110 12:41:34.819727    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-addon-manager:v9.0.2
        I0110 12:41:34.819758    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-controller-manager:v1.17.0
        I0110 12:41:34.819789    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/pause:3.1
        I0110 12:41:34.820178    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' gcr.io/k8s-minikube/storage-provisioner:v1.8.1
        I0110 12:41:34.820447    6998 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/coredns:1.6.5
        I0110 12:41:35.333930    6998 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: "k8s.gcr.io/kube-scheduler:v1.17.0" does not exist at hash "sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28" in container runtime
        I0110 12:41:35.334019    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
        I0110 12:41:35.333980    6998 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: "k8s.gcr.io/kube-addon-manager:v9.0.2" does not exist at hash "sha256:bd12a212f9dcbafe64323774c6b937dec3099d65f39a8d29896cf0d1d0c906cf" in container runtime
        I0110 12:41:35.334144    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
        I0110 12:41:35.344519    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:41:35.345108    6998 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:41:35.362568    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
        I0110 12:41:35.400508    6998 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: "kubernetesui/metrics-scraper:v1.0.2" does not exist at hash "sha256:3b08661dc379d9f80155be9d658f71578988640357ebae1aab287d6954c723d1" in container runtime
        I0110 12:41:35.400552    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
        I0110 12:41:35.410013    6998 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: "k8s.gcr.io/kube-controller-manager:v1.17.0" does not exist at hash "sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056" in container runtime
        I0110 12:41:35.410049    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
        I0110 12:41:35.417804    6998 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: "k8s.gcr.io/etcd:3.4.3-0" does not exist at hash "sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f" in container runtime
        I0110 12:41:35.417856    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
        I0110 12:41:35.419315    6998 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: "k8s.gcr.io/kube-apiserver:v1.17.0" does not exist at hash "sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2" in container runtime
        I0110 12:41:35.419337    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
        I0110 12:41:35.427053    6998 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
        I0110 12:41:35.428041    6998 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: "k8s.gcr.io/kube-proxy:v1.17.0" does not exist at hash "sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19" in container runtime
        I0110 12:41:35.428062    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
        I0110 12:41:35.434219    6998 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: "k8s.gcr.io/coredns:1.6.5" does not exist at hash "sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61" in container runtime
        I0110 12:41:35.434245    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
        I0110 12:41:35.443813    6998 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: "kubernetesui/dashboard:v2.0.0-beta8" does not exist at hash "sha256:eb51a359752560a66f314602e87155b75f428fb838bf951079ff1f9621958c0c" in container runtime
        I0110 12:41:35.443845    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
        I0110 12:41:35.446626    6998 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" does not exist at hash "sha256:4689081edb103a9e8174bf23a255bfbe0b2d9ed82edc907abab6989d1c60f02c" in container runtime
        I0110 12:41:35.446654    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
        I0110 12:41:35.463406    6998 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: "k8s.gcr.io/pause:3.1" does not exist at hash "sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e" in container runtime
        I0110 12:41:35.463437    6998 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
        I0110 12:41:35.498923    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
        I0110 12:41:35.498964    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:41:35.498949    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:41:35.504915    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:41:35.505871    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
        I0110 12:41:35.520153    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
        I0110 12:41:35.536409    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
        I0110 12:41:35.537338    6998 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:41:35.537364    6998 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:41:35.537338    6998 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:41:35.537903    6998 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:41:35.538003    6998 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
        I0110 12:41:35.541972    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
        I0110 12:41:35.552712    6998 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
        I0110 12:41:35.553414    6998 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
        I0110 12:41:35.566173    6998 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
        I0110 12:41:35.578624    6998 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
        I0110 12:41:35.596420    6998 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
        I0110 12:41:35.689276    6998 ssh_runner.go:194] pause_3.1: copied 356864 bytes
        I0110 12:41:35.747334    6998 docker.go:121] Loading image: /var/lib/minikube/images/pause_3.1
        I0110 12:41:35.747433    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/pause_3.1
        I0110 12:41:36.536789    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
        I0110 12:41:36.595928    6998 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
        I0110 12:41:36.657603    6998 docker.go:121] Loading image: /var/lib/minikube/images/coredns_1.6.5
        I0110 12:41:36.657697    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/coredns_1.6.5
        I0110 12:41:36.906794    6998 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
        I0110 12:41:37.245201    6998 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
        I0110 12:41:37.280800    6998 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
        I0110 12:41:37.298198    6998 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
        I0110 12:41:37.708688    6998 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
        I0110 12:41:37.994330    6998 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
        I0110 12:41:38.095915    6998 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
        I0110 12:41:38.157299    6998 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
        I0110 12:41:38.507053    6998 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
        I0110 12:41:42.274549    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/coredns_1.6.5: (5.616819742s)
        I0110 12:41:42.274592    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
        I0110 12:41:42.274620    6998 docker.go:121] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
        I0110 12:41:42.274699    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2
        I0110 12:41:45.311000    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2: (3.036269451s)
        I0110 12:41:45.311030    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
        I0110 12:41:45.311041    6998 docker.go:121] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
        I0110 12:41:45.311090    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1
        I0110 12:41:47.520961    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1: (2.209851178s)
        I0110 12:41:47.520995    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
        I0110 12:41:47.521017    6998 docker.go:121] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
        I0110 12:41:47.521077    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2
        I0110 12:41:52.997571    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2: (5.476464135s)
        I0110 12:41:52.997599    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
        I0110 12:41:52.997613    6998 docker.go:121] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:41:52.997660    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:41:58.904373    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0: (5.906684214s)
        I0110 12:41:58.904411    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
        I0110 12:41:58.904425    6998 docker.go:121] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
        I0110 12:41:58.904471    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8
        I0110 12:42:01.822989    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8: (2.918497984s)
        I0110 12:42:01.823028    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
        I0110 12:42:01.823053    6998 docker.go:121] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:42:01.823129    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:42:06.784541    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0: (4.961375088s)
        I0110 12:42:06.784595    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
        I0110 12:42:06.784617    6998 docker.go:121] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:42:06.784693    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:42:11.601606    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0: (4.81688583s)
        I0110 12:42:11.601658    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
        I0110 12:42:11.601677    6998 docker.go:121] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:42:11.601726    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:42:16.774445    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0: (5.172685745s)
        I0110 12:42:16.774488    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
        I0110 12:42:16.774518    6998 docker.go:121] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:42:16.774580    6998 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:42:27.303574    6998 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/etcd_3.4.3-0: (10.528950155s)
        I0110 12:42:27.303621    6998 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
        I0110 12:42:27.303640    6998 cache_images.go:93] Successfully loaded all cached images
        I0110 12:42:27.303650    6998 cache_images.go:94] LoadImages end
        I0110 12:42:27.303867    6998 kubeadm.go:390] kubelet [Unit]
        Wants=docker.socket
        
        [Service]
        ExecStart=
        ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=docker --fail-swap-on=false --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.39.50 --pod-manifest-path=/etc/kubernetes/manifests
        
        [Install]
         config:
        {KubernetesVersion:v1.17.0 NodeIP:192.168.39.50 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false}
        I0110 12:42:27.303916    6998 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
        W0110 12:42:27.319091    6998 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
        stdout:
        
        stderr:
         command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
        I0110 12:42:27.319538    6998 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
        I0110 12:42:27.319575    6998 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
        I0110 12:42:27.326350    6998 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
        I0110 12:42:27.326905    6998 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
        I0110 12:42:27.328390    6998 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
        I0110 12:42:27.332010    6998 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
        I0110 12:42:27.851556    6998 ssh_runner.go:194] kubeadm: copied 39342080 bytes
        I0110 12:42:28.342197    6998 ssh_runner.go:194] kubelet: copied 111560216 bytes
        I0110 12:42:28.358210    6998 ssh_runner.go:175] Transferring 1151 bytes to /var/tmp/minikube/kubeadm.yaml
        I0110 12:42:28.359359    6998 ssh_runner.go:194] kubeadm.yaml: copied 1151 bytes
        I0110 12:42:28.375984    6998 ssh_runner.go:175] Transferring 560 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        I0110 12:42:28.377148    6998 ssh_runner.go:194] 10-kubeadm.conf: copied 560 bytes
        I0110 12:42:28.393471    6998 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
        I0110 12:42:28.394609    6998 ssh_runner.go:194] kubelet.service: copied 349 bytes
        I0110 12:42:28.415113    6998 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
        I0110 12:42:28.416287    6998 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
        I0110 12:42:28.435810    6998 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
        I0110 12:42:28.436617    6998 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
        I0110 12:42:28.454119    6998 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
        I0110 12:42:28.455093    6998 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
        I0110 12:42:28.473855    6998 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
        I0110 12:42:28.475330    6998 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
        I0110 12:42:28.492824    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
        I0110 12:42:28.640288    6998 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.50
        I0110 12:42:28.640344    6998 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.640630    6998 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
        I0110 12:42:28.645544    6998 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
        I0110 12:42:28.645587    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.645969    6998 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
        I0110 12:42:28.646009    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.646194    6998 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.50 10.96.0.1 127.0.0.1 10.0.0.1]
        I0110 12:42:28.651224    6998 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
        I0110 12:42:28.651272    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.651579    6998 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
        I0110 12:42:28.651619    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.651822    6998 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
        I0110 12:42:28.656961    6998 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
        I0110 12:42:28.657020    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.657402    6998 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
        I0110 12:42:28.657444    6998 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:42:28.676199    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
        I0110 12:42:28.676931    6998 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
        I0110 12:42:28.678657    6998 ssh_runner.go:194] ca.crt: copied 1066 bytes
        I0110 12:42:28.726012    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
        I0110 12:42:28.726412    6998 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
        I0110 12:42:28.727675    6998 ssh_runner.go:194] ca.key: copied 1675 bytes
        I0110 12:42:28.752836    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
        I0110 12:42:28.753269    6998 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
        I0110 12:42:28.754109    6998 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
        I0110 12:42:28.780596    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
        I0110 12:42:28.781014    6998 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
        I0110 12:42:28.782025    6998 ssh_runner.go:194] apiserver.key: copied 1679 bytes
        I0110 12:42:28.810969    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
        I0110 12:42:28.811686    6998 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
        I0110 12:42:28.812647    6998 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
        I0110 12:42:28.842951    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
        I0110 12:42:28.843768    6998 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
        I0110 12:42:28.844900    6998 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
        I0110 12:42:28.879213    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
        I0110 12:42:28.879835    6998 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
        I0110 12:42:28.880698    6998 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
        I0110 12:42:28.911871    6998 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
        I0110 12:42:28.912326    6998 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
        I0110 12:42:28.913378    6998 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
        I0110 12:42:28.945171    6998 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
        I0110 12:42:28.945803    6998 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:42:28.946819    6998 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
        I0110 12:42:28.976868    6998 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
        I0110 12:42:28.979130    6998 ssh_runner.go:194] kubeconfig: copied 428 bytes
        I0110 12:42:29.005507    6998 ssh_runner.go:102] Run: openssl version
        I0110 12:42:29.027184    6998 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
        I0110 12:42:29.036319    6998 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
        I0110 12:42:29.044424    6998 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:42:29.065203    6998 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
        I0110 12:42:29.073750    6998 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
        I0110 12:42:29.081881    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
        I0110 12:42:29.311649    6998 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
        I0110 12:42:29.323048    6998 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
        stdout:
        
        stderr:
        ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
        ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
        ls: cannot access '/var/lib/minikube/etcd': No such file or directory
        I0110 12:42:29.323081    6998 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.50 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false}
        I0110 12:42:29.323140    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
        I0110 12:42:29.416979    6998 kubeadm.go:152] StartCluster complete in 93.8726ms
        I0110 12:42:29.417105    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-apiserver --format="{{.ID}}"
        I0110 12:42:29.485747    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.485785    6998 logs.go:180] No container was found matching "kube-apiserver"
        I0110 12:42:29.485875    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_coredns --format="{{.ID}}"
        I0110 12:42:29.532493    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.532527    6998 logs.go:180] No container was found matching "coredns"
        I0110 12:42:29.532603    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-scheduler --format="{{.ID}}"
        I0110 12:42:29.577364    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.577405    6998 logs.go:180] No container was found matching "kube-scheduler"
        I0110 12:42:29.577479    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-proxy --format="{{.ID}}"
        I0110 12:42:29.627887    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.627924    6998 logs.go:180] No container was found matching "kube-proxy"
        I0110 12:42:29.627998    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-addon-manager --format="{{.ID}}"
        I0110 12:42:29.672905    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.672929    6998 logs.go:180] No container was found matching "kube-addon-manager"
        I0110 12:42:29.672997    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format="{{.ID}}"
        I0110 12:42:29.717398    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.717431    6998 logs.go:180] No container was found matching "kubernetes-dashboard"
        I0110 12:42:29.717503    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_storage-provisioner --format="{{.ID}}"
        I0110 12:42:29.763784    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.763818    6998 logs.go:180] No container was found matching "storage-provisioner"
        I0110 12:42:29.763893    6998 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format="{{.ID}}"
        I0110 12:42:29.810473    6998 logs.go:178] 0 containers: []
        W0110 12:42:29.810506    6998 logs.go:180] No container was found matching "kube-controller-manager"
        I0110 12:42:29.810523    6998 logs.go:92] Gathering logs for kubelet ...
        I0110 12:42:29.810540    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
        I0110 12:42:29.826658    6998 logs.go:92] Gathering logs for dmesg ...
        I0110 12:42:29.826705    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
        I0110 12:42:29.840346    6998 logs.go:92] Gathering logs for Docker ...
        I0110 12:42:29.840388    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
        I0110 12:42:29.859039    6998 logs.go:92] Gathering logs for container status ...
        I0110 12:42:29.859089    6998 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
        I0110 12:42:31.992830    6998 ssh_runner.go:142] Completed: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a": (2.13371648s)
        W0110 12:42:31.993032    6998 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:42:29.413237    2869 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        * 
        X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:42:29.413237    2869 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * 
        * minikube is exiting due to an error. If the above message is not useful, open an issue:
          - https://github.com/kubernetes/minikube/issues/new/choose
        
        ** /stderr **
    addons_test.go:47: [out/minikube-linux-amd64 start -p addons-20200110T124042.949563487-4968 --wait=false --memory=2600 --alsologtostderr -v=1 --addons=ingress --addons=registry --addons=metrics-server --vm-driver=kvm2 ] failed: exit status 70
    panic.go:563: *** TestAddons FAILED at 2020-01-10 12:42:31.996743378 +0000 UTC m=+572.641762205
    panic.go:563: >>> TestAddons FAILED: start of post-mortem logs >>>
    panic.go:563: (dbg) Run:  kubectl --context addons-20200110T124042.949563487-4968 get po -A --show-labels
    panic.go:563: (dbg) Non-zero exit: kubectl --context addons-20200110T124042.949563487-4968 get po -A --show-labels: exit status 1 (240.842003ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.50:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    panic.go:563: kubectl --context addons-20200110T124042.949563487-4968 get po -A --show-labels: exit status 1
    panic.go:563: (dbg) kubectl --context addons-20200110T124042.949563487-4968 get po -A --show-labels:
    panic.go:563: (dbg) Run:  kubectl --context addons-20200110T124042.949563487-4968 describe node
    panic.go:563: (dbg) Non-zero exit: kubectl --context addons-20200110T124042.949563487-4968 describe node: exit status 1 (57.476846ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.50:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    panic.go:563: kubectl --context addons-20200110T124042.949563487-4968 describe node: exit status 1
    panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p addons-20200110T124042.949563487-4968 logs --problems
    panic.go:563: (dbg) Done: out/minikube-linux-amd64 -p addons-20200110T124042.949563487-4968 logs --problems: (3.275467414s)
    panic.go:563: TestAddons logs: 
    panic.go:563: <<< TestAddons FAILED: end of post-mortem logs <<<
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p addons-20200110T124042.949563487-4968
    helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p addons-20200110T124042.949563487-4968: (2.048390874s)
=== RUN   TestDockerFlags
=== PAUSE TestDockerFlags
=== RUN   TestKVMDriverInstallOrUpdate
=== PAUSE TestKVMDriverInstallOrUpdate
=== RUN   TestHyperKitDriverInstallOrUpdate
--- SKIP: TestHyperKitDriverInstallOrUpdate (0.00s)
    driver_install_or_update_test.go:101: Skip if not darwin.
=== RUN   TestFunctional
=== RUN   TestFunctional/serial
=== RUN   TestFunctional/serial/CopySyncFile
=== RUN   TestFunctional/serial/StartWithProxy
=== RUN   TestFunctional/serial/KubeContext
=== RUN   TestFunctional/serial/KubectlGetPods
=== RUN   TestFunctional/serial/CacheCmd
=== RUN   TestFunctional/serial/CacheCmd/cache
=== RUN   TestFunctional/serial/CacheCmd/cache/add
=== RUN   TestFunctional/serial/CacheCmd/cache/delete_busybox:1.28.4-glibc
=== RUN   TestFunctional/serial/CacheCmd/cache/list
=== RUN   TestFunctional/serial/CacheCmd/cache/verify_cache_inside_node
=== RUN   TestFunctional/serial/CacheCmd/cache/cache_reload
=== PAUSE TestFunctional
=== RUN   TestGvisorAddon
=== PAUSE TestGvisorAddon
=== RUN   TestChangeNoneUser
--- SKIP: TestChangeNoneUser (0.00s)
    none_test.go:39: Only test none driver.
=== RUN   TestStartStop
=== PAUSE TestStartStop
=== RUN   TestVersionUpgrade
=== PAUSE TestVersionUpgrade
=== CONT  TestDockerFlags
=== CONT  TestStartStop
=== CONT  TestFunctional
=== RUN   TestStartStop/group
=== RUN   TestFunctional/parallel
=== CONT  TestGvisorAddon
=== CONT  TestVersionUpgrade
=== RUN   TestStartStop/group/old-docker
=== CONT  TestKVMDriverInstallOrUpdate
=== PAUSE TestStartStop/group/old-docker
=== RUN   TestStartStop/group/newest-cni
=== PAUSE TestStartStop/group/newest-cni
=== RUN   TestStartStop/group/containerd
=== PAUSE TestStartStop/group/containerd
=== RUN   TestStartStop/group/crio
=== RUN   TestFunctional/parallel/AddonManager
=== PAUSE TestFunctional/parallel/AddonManager
=== RUN   TestFunctional/parallel/ComponentHealth
=== PAUSE TestStartStop/group/crio
=== CONT  TestStartStop/group/old-docker
=== PAUSE TestFunctional/parallel/ComponentHealth
=== RUN   TestFunctional/parallel/ConfigCmd
=== CONT  TestStartStop/group/containerd
=== PAUSE TestFunctional/parallel/ConfigCmd
=== CONT  TestStartStop/group/newest-cni
=== RUN   TestFunctional/parallel/DashboardCmd
=== PAUSE TestFunctional/parallel/DashboardCmd
=== RUN   TestFunctional/parallel/DNS
=== PAUSE TestFunctional/parallel/DNS
=== RUN   TestFunctional/parallel/StatusCmd
=== PAUSE TestFunctional/parallel/StatusCmd
=== RUN   TestFunctional/parallel/LogsCmd
=== PAUSE TestFunctional/parallel/LogsCmd
=== RUN   TestFunctional/parallel/MountCmd
=== PAUSE TestFunctional/parallel/MountCmd
=== RUN   TestFunctional/parallel/ProfileCmd
=== PAUSE TestFunctional/parallel/ProfileCmd
=== RUN   TestFunctional/parallel/ServiceCmd
=== PAUSE TestFunctional/parallel/ServiceCmd
=== RUN   TestFunctional/parallel/AddonsCmd
=== PAUSE TestFunctional/parallel/AddonsCmd
=== RUN   TestFunctional/parallel/PersistentVolumeClaim
=== PAUSE TestFunctional/parallel/PersistentVolumeClaim
=== RUN   TestFunctional/parallel/TunnelCmd
=== PAUSE TestFunctional/parallel/TunnelCmd
=== RUN   TestFunctional/parallel/SSHCmd
=== PAUSE TestFunctional/parallel/SSHCmd
=== RUN   TestFunctional/parallel/MySQL
=== PAUSE TestFunctional/parallel/MySQL
=== RUN   TestFunctional/parallel/FileSync
=== PAUSE TestFunctional/parallel/FileSync
=== RUN   TestFunctional/parallel/UpdateContextCmd
=== PAUSE TestFunctional/parallel/UpdateContextCmd
=== CONT  TestStartStop/group/crio
    > docker-machine-driver-kvm2.sha256: 65 B / 65 B [-------] 100.00% ? p/s 0s    > docker-machine-driver-kvm2: 1.05 MiB / 48.57 MiB [>_______] 2.15% ? p/s ?    > docker-machine-driver-kvm2: 2.68 MiB / 48.57 MiB [>_______] 5.51% ? p/s ?    > docker-machine-driver-kvm2: 3.30 MiB / 48.57 MiB [>_______] 6.80% ? p/s ?    > docker-machine-driver-kvm2: 3.60 MiB / 48.57 MiB  7.41% 4.25 MiB p/s ETA     > docker-machine-driver-kvm2: 3.94 MiB / 48.57 MiB  8.12% 4.25 MiB p/s ETA     > docker-machine-driver-kvm2: 4.30 MiB / 48.57 MiB  8.85% 4.25 MiB p/s ETA     > docker-machine-driver-kvm2: 4.60 MiB / 48.57 MiB  9.47% 4.09 MiB p/s ETA     > docker-machine-driver-kvm2: 5.00 MiB / 48.57 MiB  10.30% 4.09 MiB p/s ETA    > docker-machine-driver-kvm2: 5.41 MiB / 48.57 MiB  11.14% 4.09 MiB p/s ETA    > docker-machine-driver-kvm2: 5.86 MiB / 48.57 MiB  12.07% 3.96 MiB p/s ETA    > docker-machine-driver-kvm2: 6.21 MiB / 48.57 MiB  12.78% 3.96 MiB p/s ETA    > docker-machine-driver-kvm2: 6.69 MiB / 48.57 MiB  13.78% 3.96 MiB p/s ETA    > docker-machine-driver-kvm2: 7.18 MiB / 48.57 MiB  14.77% 3.85 MiB p/s ETA    > docker-machine-driver-kvm2: 7.61 MiB / 48.57 MiB  15.67% 3.85 MiB p/s ETA    > docker-machine-driver-kvm2: 8.10 MiB / 48.57 MiB  16.67% 3.85 MiB p/s ETA    > docker-machine-driver-kvm2: 8.60 MiB / 48.57 MiB  17.70% 3.75 MiB p/s ETA    > docker-machine-driver-kvm2: 8.99 MiB / 48.57 MiB  18.51% 3.75 MiB p/s ETA    > docker-machine-driver-kvm2: 9.18 MiB / 48.57 MiB  18.89% 3.75 MiB p/s ETA    > docker-machine-driver-kvm2: 9.30 MiB / 48.57 MiB  19.15% 3.58 MiB p/s ETA    > docker-machine-driver-kvm2: 9.46 MiB / 48.57 MiB  19.47% 3.58 MiB p/s ETA    > docker-machine-driver-kvm2: 9.61 MiB / 48.57 MiB  19.79% 3.58 MiB p/s ETA    > docker-machine-driver-kvm2: 9.79 MiB / 48.57 MiB  20.15% 3.40 MiB p/s ETA    > docker-machine-driver-kvm2: 9.99 MiB / 48.57 MiB  20.56% 3.40 MiB p/s ETA    > docker-machine-driver-kvm2: 10.16 MiB / 48.57 MiB  20.92% 3.40 MiB p/s ET    > docker-machine-driver-kvm2: 10.36 MiB / 48.57 MiB  21.34% 3.25 MiB p/s ET    > docker-machine-driver-kvm2: 10.58 MiB / 48.57 MiB  21.79% 3.25 MiB p/s ET    > docker-machine-driver-kvm2: 10.77 MiB / 48.57 MiB  22.17% 3.25 MiB p/s ET    > docker-machine-driver-kvm2: 11.04 MiB / 48.57 MiB  22.72% 3.11 MiB p/s ET    > docker-machine-driver-kvm2: 11.32 MiB / 48.57 MiB  23.30% 3.11 MiB p/s ET    > docker-machine-driver-kvm2: 11.61 MiB / 48.57 MiB  23.91% 3.11 MiB p/s ET    > docker-machine-driver-kvm2: 11.88 MiB / 48.57 MiB  24.46% 3.00 MiB p/s ET    > docker-machine-driver-kvm2: 12.14 MiB / 48.57 MiB  25.00% 3.00 MiB p/s ET    > docker-machine-driver-kvm2: 12.41 MiB / 48.57 MiB  25.55% 3.00 MiB p/s ET    > docker-machine-driver-kvm2: 12.61 MiB / 48.57 MiB  25.97% 2.89 MiB p/s ET    > docker-machine-driver-kvm2: 12.91 MiB / 48.57 MiB  26.58% 2.89 MiB p/s ET    > docker-machine-driver-kvm2: 13.22 MiB / 48.57 MiB  27.22% 2.89 MiB p/s ET    > docker-machine-driver-kvm2: 13.24 MiB / 48.57 MiB  27.25% 2.77 MiB p/s ET    > docker-machine-driver-kvm2: 13.66 MiB / 48.57 MiB  28.12% 2.77 MiB p/s ET    > docker-machine-driver-kvm2: 14.02 MiB / 48.57 MiB  28.86% 2.77 MiB p/s ET    > docker-machine-driver-kvm2: 14.36 MiB / 48.57 MiB  29.57% 2.71 MiB p/s ET    > docker-machine-driver-kvm2: 14.79 MiB / 48.57 MiB  30.44% 2.71 MiB p/s ET    > docker-machine-driver-kvm2: 15.22 MiB / 48.57 MiB  31.34% 2.71 MiB p/s ET    > docker-machine-driver-kvm2: 15.66 MiB / 48.57 MiB  32.24% 2.67 MiB p/s ET    > docker-machine-driver-kvm2: 16.10 MiB / 48.57 MiB  33.14% 2.67 MiB p/s ET    > docker-machine-driver-kvm2: 16.33 MiB / 48.57 MiB  33.62% 2.67 MiB p/s ET    > docker-machine-driver-kvm2: 16.57 MiB / 48.57 MiB  34.11% 2.60 MiB p/s ET    > docker-machine-driver-kvm2: 16.85 MiB / 48.57 MiB  34.69% 2.60 MiB p/s ET    > docker-machine-driver-kvm2: 17.14 MiB / 48.57 MiB  35.30% 2.60 MiB p/s ET    > docker-machine-driver-kvm2: 17.38 MiB / 48.57 MiB  35.78% 2.52 MiB p/s ET    > docker-machine-driver-kvm2: 17.60 MiB / 48.57 MiB  36.23% 2.52 MiB p/s ET    > docker-machine-driver-kvm2: 17.82 MiB / 48.57 MiB  36.68% 2.52 MiB p/s ET    > docker-machine-driver-kvm2: 18.10 MiB / 48.57 MiB  37.26% 2.43 MiB p/s ET    > docker-machine-driver-kvm2: 18.39 MiB / 48.57 MiB  37.87% 2.43 MiB p/s ET    > docker-machine-driver-kvm2: 18.68 MiB / 48.57 MiB  38.45% 2.43 MiB p/s ET    > docker-machine-driver-kvm2: 19.02 MiB / 48.57 MiB  39.16% 2.38 MiB p/s ET    > docker-machine-driver-kvm2: 19.32 MiB / 48.57 MiB  39.77% 2.38 MiB p/s ET    > docker-machine-driver-kvm2: 19.60 MiB / 48.57 MiB  40.35% 2.38 MiB p/s ET    > docker-machine-driver-kvm2: 19.85 MiB / 48.57 MiB  40.86% 2.31 MiB p/s ET    > docker-machine-driver-kvm2: 20.13 MiB / 48.57 MiB  41.44% 2.31 MiB p/s ET    > docker-machine-driver-kvm2: 20.44 MiB / 48.57 MiB  42.08% 2.31 MiB p/s ET    > docker-machine-driver-kvm2: 20.68 MiB / 48.57 MiB  42.57% 2.25 MiB p/s ET    > docker-machine-driver-kvm2: 20.94 MiB / 48.57 MiB  43.11% 2.25 MiB p/s ET    > docker-machine-driver-kvm2: 21.22 MiB / 48.57 MiB  43.69% 2.25 MiB p/s ET    > docker-machine-driver-kvm2: 21.25 MiB / 48.57 MiB  43.76% 2.17 MiB p/s ET    > docker-machine-driver-kvm2: 21.58 MiB / 48.57 MiB  44.43% 2.17 MiB p/s ET    > docker-machine-driver-kvm2: 21.89 MiB / 48.57 MiB  45.08% 2.17 MiB p/s ET    > docker-machine-driver-kvm2: 22.14 MiB / 48.57 MiB  45.59% 2.12 MiB p/s ET    > docker-machine-driver-kvm2: 22.27 MiB / 48.57 MiB  45.85% 2.12 MiB p/s ET    > docker-machine-driver-kvm2: 22.47 MiB / 48.57 MiB  46.27% 2.12 MiB p/s ET    > docker-machine-driver-kvm2: 22.68 MiB / 48.57 MiB  46.68% 2.04 MiB p/s ET    > docker-machine-driver-kvm2: 22.89 MiB / 48.57 MiB  47.13% 2.04 MiB p/s ET    > docker-machine-driver-kvm2: 23.16 MiB / 48.57 MiB  47.68% 2.04 MiB p/s ET    > docker-machine-driver-kvm2: 23.39 MiB / 48.57 MiB  48.16% 1.99 MiB p/s ET    > docker-machine-driver-kvm2: 23.69 MiB / 48.57 MiB  48.78% 1.99 MiB p/s ET    > docker-machine-driver-kvm2: 23.96 MiB / 48.57 MiB  49.32% 1.99 MiB p/s ET    > docker-machine-driver-kvm2: 24.22 MiB / 48.57 MiB  49.87% 1.95 MiB p/s ET    > docker-machine-driver-kvm2: 24.54 MiB / 48.57 MiB  50.51% 1.95 MiB p/s ET    > docker-machine-driver-kvm2: 24.80 MiB / 48.57 MiB  51.06% 1.95 MiB p/s ET    > docker-machine-driver-kvm2: 25.11 MiB / 48.57 MiB  51.70% 1.92 MiB p/s ET    > docker-machine-driver-kvm2: 25.43 MiB / 48.57 MiB  52.35% 1.92 MiB p/s ET    > docker-machine-driver-kvm2: 25.79 MiB / 48.57 MiB  53.09% 1.92 MiB p/s ET    > docker-machine-driver-kvm2: 26.14 MiB / 48.57 MiB  53.82% 1.91 MiB p/s ET    > docker-machine-driver-kvm2: 26.50 MiB / 48.57 MiB  54.57% 1.91 MiB p/s ET    > docker-machine-driver-kvm2: 26.74 MiB / 48.57 MiB  55.05% 1.91 MiB p/s ET    > docker-machine-driver-kvm2: 26.93 MiB / 48.57 MiB  55.43% 1.87 MiB p/s ET    > docker-machine-driver-kvm2: 27.13 MiB / 48.57 MiB  55.85% 1.87 MiB p/s ET    > docker-machine-driver-kvm2: 27.33 MiB / 48.57 MiB  56.27% 1.87 MiB p/s ET    > docker-machine-driver-kvm2: 27.52 MiB / 48.57 MiB  56.66% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 27.79 MiB / 48.57 MiB  57.20% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 27.99 MiB / 48.57 MiB  57.62% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 28.19 MiB / 48.57 MiB  58.04% 1.77 MiB p/s ET    > docker-machine-driver-kvm2: 28.39 MiB / 48.57 MiB  58.46% 1.77 MiB p/s ET    > docker-machine-driver-kvm2: 28.63 MiB / 48.57 MiB  58.94% 1.77 MiB p/s ET    > docker-machine-driver-kvm2: 28.83 MiB / 48.57 MiB  59.36% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 29.04 MiB / 48.57 MiB  59.78% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 29.30 MiB / 48.57 MiB  60.32% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 29.54 MiB / 48.57 MiB  60.81% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 29.74 MiB / 48.57 MiB  61.22% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 29.91 MiB / 48.57 MiB  61.58% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 30.14 MiB / 48.57 MiB  62.06% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 30.39 MiB / 48.57 MiB  62.57% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 30.64 MiB / 48.57 MiB  63.09% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 30.94 MiB / 48.57 MiB  63.70% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 31.27 MiB / 48.57 MiB  64.38% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 31.57 MiB / 48.57 MiB  64.99% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 31.83 MiB / 48.57 MiB  65.53% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 32.00 MiB / 48.57 MiB  65.89% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 32.16 MiB / 48.57 MiB  66.21% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 32.36 MiB / 48.57 MiB  66.63% 1.57 MiB p/s ET    > docker-machine-driver-kvm2: 32.60 MiB / 48.57 MiB  67.11% 1.57 MiB p/s ET    > docker-machine-driver-kvm2: 32.82 MiB / 48.57 MiB  67.56% 1.57 MiB p/s ET    > docker-machine-driver-kvm2: 32.99 MiB / 48.57 MiB  67.91% 1.53 MiB p/s ET    > docker-machine-driver-kvm2: 33.18 MiB / 48.57 MiB  68.30% 1.53 MiB p/s ET    > docker-machine-driver-kvm2: 33.33 MiB / 48.57 MiB  68.62% 1.53 MiB p/s ET    > docker-machine-driver-kvm2: 33.49 MiB / 48.57 MiB  68.94% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 33.69 MiB / 48.57 MiB  69.36% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 33.93 MiB / 48.57 MiB  69.84% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 34.13 MiB / 48.57 MiB  70.26% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 34.35 MiB / 48.57 MiB  70.71% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 34.63 MiB / 48.57 MiB  71.29% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 34.89 MiB / 48.57 MiB  71.84% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 35.18 MiB / 48.57 MiB  72.42% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 35.50 MiB / 48.57 MiB  73.09% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 35.82 MiB / 48.57 MiB  73.74% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 36.16 MiB / 48.57 MiB  74.44% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 36.54 MiB / 48.57 MiB  75.22% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 36.91 MiB / 48.57 MiB  75.99% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 37.21 MiB / 48.57 MiB  76.60% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 37.49 MiB / 48.57 MiB  77.18% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 37.74 MiB / 48.57 MiB  77.69% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 38.02 MiB / 48.57 MiB  78.27% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 38.30 MiB / 48.57 MiB  78.85% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 38.60 MiB / 48.57 MiB  79.46% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 38.86 MiB / 48.57 MiB  80.01% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 39.11 MiB / 48.57 MiB  80.52% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 39.32 MiB / 48.57 MiB  80.94% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 39.46 MiB / 48.57 MiB  81.23% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 39.64 MiB / 48.57 MiB  81.62% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 39.85 MiB / 48.57 MiB  82.04% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 40.08 MiB / 48.57 MiB  82.52% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 40.27 MiB / 48.57 MiB  82.90% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 40.49 MiB / 48.57 MiB  83.36% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 40.66 MiB / 48.57 MiB  83.71% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 40.80 MiB / 48.57 MiB  84.00% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 41.00 MiB / 48.57 MiB  84.42% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 41.24 MiB / 48.57 MiB  84.90% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 41.36 MiB / 48.57 MiB  85.16% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 41.57 MiB / 48.57 MiB  85.57% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 41.79 MiB / 48.57 MiB  86.02% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 42.02 MiB / 48.57 MiB  86.51% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 42.24 MiB / 48.57 MiB  86.96% 1.32 MiB p/s ET    > docker-machine-driver-kvm2: 42.54 MiB / 48.57 MiB  87.57% 1.32 MiB p/s ET    > docker-machine-driver-kvm2: 42.85 MiB / 48.57 MiB  88.21% 1.32 MiB p/s ET    > docker-machine-driver-kvm2: 43.11 MiB / 48.57 MiB  88.76% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 43.44 MiB / 48.57 MiB  89.44% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 43.77 MiB / 48.57 MiB  90.11% 1.33 MiB p/s ET    > docker-machine-driver-kvm2: 44.08 MiB / 48.57 MiB  90.75% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 44.43 MiB / 48.57 MiB  91.46% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 44.71 MiB / 48.57 MiB  92.04% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 45.02 MiB / 48.57 MiB  92.68% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 45.25 MiB / 48.57 MiB  93.17% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 45.58 MiB / 48.57 MiB  93.84% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 45.93 MiB / 48.57 MiB  94.55% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 46.18 MiB / 48.57 MiB  95.06% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 46.54 MiB / 48.57 MiB  95.80% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 46.86 MiB / 48.57 MiB  96.48% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 47.18 MiB / 48.57 MiB  97.12% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 47.60 MiB / 48.57 MiB  97.99% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 48.02 MiB / 48.57 MiB  98.86% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 48.43 MiB / 48.57 MiB  99.70% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 48.57 MiB / 48.57 MiB  100.00% 1.43 MiB p/s 3    > docker-machine-driver-kvm2.sha256: 65 B / 65 B [-------] 100.00% ? p/s 0s    > docker-machine-driver-kvm2: 1.36 MiB / 48.57 MiB [>_______] 2.80% ? p/s ?    > docker-machine-driver-kvm2: 1.38 MiB / 48.57 MiB [>_______] 2.83% ? p/s ?    > docker-machine-driver-kvm2: 1.38 MiB / 48.57 MiB [>_______] 2.83% ? p/s ?    > docker-machine-driver-kvm2: 2.67 MiB / 48.57 MiB  5.50% 2.19 MiB p/s ETA     > docker-machine-driver-kvm2: 3.32 MiB / 48.57 MiB  6.83% 2.19 MiB p/s ETA     > docker-machine-driver-kvm2: 3.92 MiB / 48.57 MiB  8.07% 2.19 MiB p/s ETA     > docker-machine-driver-kvm2: 4.20 MiB / 48.57 MiB  8.65% 2.21 MiB p/s ETA     > docker-machine-driver-kvm2: 4.38 MiB / 48.57 MiB  9.02% 2.21 MiB p/s ETA     > docker-machine-driver-kvm2: 4.58 MiB / 48.57 MiB  9.43% 2.21 MiB p/s ETA     > docker-machine-driver-kvm2: 4.81 MiB / 48.57 MiB  9.91% 2.13 MiB p/s ETA     > docker-machine-driver-kvm2: 5.06 MiB / 48.57 MiB  10.42% 2.13 MiB p/s ETA    > docker-machine-driver-kvm2: 5.31 MiB / 48.57 MiB  10.94% 2.13 MiB p/s ETA    > docker-machine-driver-kvm2: 5.54 MiB / 48.57 MiB  11.41% 2.07 MiB p/s ETA    > docker-machine-driver-kvm2: 5.79 MiB / 48.57 MiB  11.93% 2.07 MiB p/s ETA    > docker-machine-driver-kvm2: 6.08 MiB / 48.57 MiB  12.51% 2.07 MiB p/s ETA    > docker-machine-driver-kvm2: 6.31 MiB / 48.57 MiB  12.99% 2.02 MiB p/s ETA    > docker-machine-driver-kvm2: 6.56 MiB / 48.57 MiB  13.50% 2.02 MiB p/s ETA    > docker-machine-driver-kvm2: 6.81 MiB / 48.57 MiB  14.01% 2.02 MiB p/s ETA    > docker-machine-driver-kvm2: 7.11 MiB / 48.57 MiB  14.63% 1.98 MiB p/s ETA    > docker-machine-driver-kvm2: 7.42 MiB / 48.57 MiB  15.28% 1.98 MiB p/s ETA    > docker-machine-driver-kvm2: 7.74 MiB / 48.57 MiB  15.93% 1.98 MiB p/s ETA    > docker-machine-driver-kvm2: 8.00 MiB / 48.57 MiB  16.47% 1.95 MiB p/s ETA    > docker-machine-driver-kvm2: 8.23 MiB / 48.57 MiB  16.95% 1.95 MiB p/s ETA    > docker-machine-driver-kvm2: 8.43 MiB / 48.57 MiB  17.36% 1.95 MiB p/s ETA    > docker-machine-driver-kvm2: 8.67 MiB / 48.57 MiB  17.84% 1.89 MiB p/s ETA    > docker-machine-driver-kvm2: 8.88 MiB / 48.57 MiB  18.28% 1.89 MiB p/s ETA    > docker-machine-driver-kvm2: 9.10 MiB / 48.57 MiB  18.73% 1.89 MiB p/s ETA    > docker-machine-driver-kvm2: 9.33 MiB / 48.57 MiB  19.21% 1.84 MiB p/s ETA    > docker-machine-driver-kvm2: 9.56 MiB / 48.57 MiB  19.69% 1.84 MiB p/s ETA    > docker-machine-driver-kvm2: 9.78 MiB / 48.57 MiB  20.13% 1.84 MiB p/s ETA    > docker-machine-driver-kvm2: 10.03 MiB / 48.57 MiB  20.64% 1.80 MiB p/s ET    > docker-machine-driver-kvm2: 10.28 MiB / 48.57 MiB  21.16% 1.80 MiB p/s ET    > docker-machine-driver-kvm2: 10.52 MiB / 48.57 MiB  21.67% 1.80 MiB p/s ET    > docker-machine-driver-kvm2: 10.74 MiB / 48.57 MiB  22.11% 1.76 MiB p/s ET    > docker-machine-driver-kvm2: 10.96 MiB / 48.57 MiB  22.56% 1.76 MiB p/s ET    > docker-machine-driver-kvm2: 11.22 MiB / 48.57 MiB  23.10% 1.76 MiB p/s ET    > docker-machine-driver-kvm2: 11.50 MiB / 48.57 MiB  23.68% 1.73 MiB p/s ET    > docker-machine-driver-kvm2: 11.79 MiB / 48.57 MiB  24.27% 1.73 MiB p/s ET    > docker-machine-driver-kvm2: 12.02 MiB / 48.57 MiB  24.74% 1.73 MiB p/s ET    > docker-machine-driver-kvm2: 12.20 MiB / 48.57 MiB  25.12% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 12.32 MiB / 48.57 MiB  25.36% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 12.43 MiB / 48.57 MiB  25.60% 1.69 MiB p/s ET    > docker-machine-driver-kvm2: 12.55 MiB / 48.57 MiB  25.84% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 12.68 MiB / 48.57 MiB  26.11% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 12.82 MiB / 48.57 MiB  26.38% 1.62 MiB p/s ET    > docker-machine-driver-kvm2: 13.00 MiB / 48.57 MiB  26.76% 1.56 MiB p/s ET    > docker-machine-driver-kvm2: 13.21 MiB / 48.57 MiB  27.20% 1.56 MiB p/s ET    > docker-machine-driver-kvm2: 13.46 MiB / 48.57 MiB  27.72% 1.56 MiB p/s ET    > docker-machine-driver-kvm2: 13.70 MiB / 48.57 MiB  28.20% 1.54 MiB p/s ET    > docker-machine-driver-kvm2: 13.91 MiB / 48.57 MiB  28.64% 1.54 MiB p/s ET    > docker-machine-driver-kvm2: 14.16 MiB / 48.57 MiB  29.15% 1.54 MiB p/s ET    > docker-machine-driver-kvm2: 14.44 MiB / 48.57 MiB  29.73% 1.52 MiB p/s ET    > docker-machine-driver-kvm2: 14.71 MiB / 48.57 MiB  30.28% 1.52 MiB p/s ET    > docker-machine-driver-kvm2: 14.94 MiB / 48.57 MiB  30.76% 1.52 MiB p/s ET    > docker-machine-driver-kvm2: 14.94 MiB / 48.57 MiB  30.76% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 15.37 MiB / 48.57 MiB  31.65% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 15.62 MiB / 48.57 MiB  32.16% 1.47 MiB p/s ET    > docker-machine-driver-kvm2: 15.90 MiB / 48.57 MiB  32.74% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 16.20 MiB / 48.57 MiB  33.36% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 16.47 MiB / 48.57 MiB  33.90% 1.48 MiB p/s ET    > docker-machine-driver-kvm2: 16.62 MiB / 48.57 MiB  34.21% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 16.75 MiB / 48.57 MiB  34.48% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 16.88 MiB / 48.57 MiB  34.76% 1.46 MiB p/s ET    > docker-machine-driver-kvm2: 17.07 MiB / 48.57 MiB  35.13% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 17.28 MiB / 48.57 MiB  35.58% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 17.48 MiB / 48.57 MiB  35.99% 1.42 MiB p/s ET    > docker-machine-driver-kvm2: 17.65 MiB / 48.57 MiB  36.33% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 17.85 MiB / 48.57 MiB  36.74% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 18.05 MiB / 48.57 MiB  37.15% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 18.26 MiB / 48.57 MiB  37.59% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 18.51 MiB / 48.57 MiB  38.11% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 18.76 MiB / 48.57 MiB  38.62% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 19.06 MiB / 48.57 MiB  39.24% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 19.37 MiB / 48.57 MiB  39.88% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 19.71 MiB / 48.57 MiB  40.57% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 20.04 MiB / 48.57 MiB  41.25% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 20.37 MiB / 48.57 MiB  41.94% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 20.72 MiB / 48.57 MiB  42.65% 1.38 MiB p/s ET    > docker-machine-driver-kvm2: 21.08 MiB / 48.57 MiB  43.40% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 21.35 MiB / 48.57 MiB  43.95% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 21.63 MiB / 48.57 MiB  44.53% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 21.91 MiB / 48.57 MiB  45.11% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 22.18 MiB / 48.57 MiB  45.66% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 22.49 MiB / 48.57 MiB  46.31% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 22.78 MiB / 48.57 MiB  46.89% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 22.94 MiB / 48.57 MiB  47.23% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 23.14 MiB / 48.57 MiB  47.64% 1.40 MiB p/s ET    > docker-machine-driver-kvm2: 23.31 MiB / 48.57 MiB  47.99% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 23.49 MiB / 48.57 MiB  48.36% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 23.71 MiB / 48.57 MiB  48.81% 1.37 MiB p/s ET    > docker-machine-driver-kvm2: 23.95 MiB / 48.57 MiB  49.32% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 24.22 MiB / 48.57 MiB  49.86% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 24.52 MiB / 48.57 MiB  50.48% 1.35 MiB p/s ET    > docker-machine-driver-kvm2: 24.85 MiB / 48.57 MiB  51.16% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 25.17 MiB / 48.57 MiB  51.81% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 25.55 MiB / 48.57 MiB  52.60% 1.36 MiB p/s ET    > docker-machine-driver-kvm2: 25.98 MiB / 48.57 MiB  53.49% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 26.38 MiB / 48.57 MiB  54.31% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 26.84 MiB / 48.57 MiB  55.27% 1.39 MiB p/s ET    > docker-machine-driver-kvm2: 27.31 MiB / 48.57 MiB  56.22% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 27.81 MiB / 48.57 MiB  57.25% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 28.22 MiB / 48.57 MiB  58.10% 1.45 MiB p/s ET    > docker-machine-driver-kvm2: 28.60 MiB / 48.57 MiB  58.89% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 28.92 MiB / 48.57 MiB  59.54% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 29.25 MiB / 48.57 MiB  60.22% 1.49 MiB p/s ET    > docker-machine-driver-kvm2: 29.62 MiB / 48.57 MiB  60.97% 1.51 MiB p/s ET    > docker-machine-driver-kvm2: 30.02 MiB / 48.57 MiB  61.79% 1.51 MiB p/s ET    > docker-machine-driver-kvm2: 30.45 MiB / 48.57 MiB  62.68% 1.51 MiB p/s ET    > docker-machine-driver-kvm2: 30.93 MiB / 48.57 MiB  63.67% 1.55 MiB p/s ET    > docker-machine-driver-kvm2: 31.43 MiB / 48.57 MiB  64.70% 1.55 MiB p/s ET    > docker-machine-driver-kvm2: 31.96 MiB / 48.57 MiB  65.79% 1.55 MiB p/s ET    > docker-machine-driver-kvm2: 32.46 MiB / 48.57 MiB  66.82% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 32.85 MiB / 48.57 MiB  67.64% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 33.29 MiB / 48.57 MiB  68.53% 1.61 MiB p/s ET    > docker-machine-driver-kvm2: 33.68 MiB / 48.57 MiB  69.35% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 34.05 MiB / 48.57 MiB  70.10% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 34.53 MiB / 48.57 MiB  71.09% 1.64 MiB p/s ET    > docker-machine-driver-kvm2: 34.98 MiB / 48.57 MiB  72.01% 1.68 MiB p/s ET    > docker-machine-driver-kvm2: 35.48 MiB / 48.57 MiB  73.04% 1.68 MiB p/s ET    > docker-machine-driver-kvm2: 35.94 MiB / 48.57 MiB  73.99% 1.68 MiB p/s ET    > docker-machine-driver-kvm2: 36.29 MiB / 48.57 MiB  74.71% 1.71 MiB p/s ET    > docker-machine-driver-kvm2: 36.69 MiB / 48.57 MiB  75.53% 1.71 MiB p/s ET    > docker-machine-driver-kvm2: 37.05 MiB / 48.57 MiB  76.28% 1.71 MiB p/s ET    > docker-machine-driver-kvm2: 37.37 MiB / 48.57 MiB  76.93% 1.71 MiB p/s ET--- FAIL: TestDockerFlags (62.32s)
    helpers.go:376: No need to wait for start slot, it is already 2020-01-10 12:44:35.195252587 +0000 UTC m=+695.840271336
    docker_test.go:42: (dbg) Run:  out/minikube-linux-amd64 start -p docker-flags-20200110T124435.195281233-4968 --cache-images=false --wait=false --docker-env=FOO=BAR --docker-env=BAZ=BAT --docker-opt=debug --docker-opt=icc=true --alsologtostderr -v=5 --vm-driver=kvm2 
    docker_test.go:42: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p docker-flags-20200110T124435.195281233-4968 --cache-images=false --wait=false --docker-env=FOO=BAR --docker-env=BAZ=BAT --docker-opt=debug --docker-opt=icc=true --alsologtostderr -v=5 --vm-driver=kvm2 : exit status 70 (56.589287404s)
        -- stdout --
        * [docker-flags-20200110T124435.195281233-4968] minikube v1.6.2 on Debian 9.11
          - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
          - MINIKUBE_BIN=out/minikube-linux-amd64
          - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
          - MINIKUBE_LOCATION=6150
        * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
        * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
        * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
          - opt debug
          - opt icc=true
          - env FOO=BAR
          - env BAZ=BAT
        * Pulling images ...
        * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:45:28.973800    2319 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * Launching Kubernetes ... 
        
        -- /stdout --
        ** stderr ** 
        I0110 12:44:35.235854    8239 notify.go:125] Checking for updates...
        I0110 12:44:35.369692    8239 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1624,"bootTime":1578658651,"procs":211,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
        I0110 12:44:35.370347    8239 start.go:266] virtualization: kvm host
        I0110 12:44:35.370762    8239 start.go:567] selectDriver: flag="kvm2", old=<nil>
        I0110 12:44:35.370788    8239 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:44:35.579578    8239 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:44:35.579669    8239 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
        I0110 12:44:35.678576    8239 global.go:68] docker priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:44:37.697705    8239 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:44:37.697795    8239 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:44:37.697820    8239 driver.go:128] requested: "kvm2"
        I0110 12:44:37.697840    8239 driver.go:132] choosing "kvm2" because it was requested
        I0110 12:44:37.697849    8239 driver.go:147] not recommending "docker" due to priority: 2
        I0110 12:44:37.697859    8239 driver.go:147] not recommending "none" due to priority: 2
        I0110 12:44:37.697875    8239 driver.go:165] Picked: kvm2
        I0110 12:44:37.697897    8239 driver.go:166] Alternatives: [virtualbox docker none]
        I0110 12:44:37.698024    8239 start.go:298] selected driver: kvm2
        I0110 12:44:37.698032    8239 start.go:597] validating driver "kvm2" against <nil>
        I0110 12:44:37.729848    8239 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:44:37.730015    8239 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:44:37.745325    8239 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
        I0110 12:44:37.745621    8239 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/docker-flags-20200110T124435.195281233-4968/config.json ...
        I0110 12:44:37.745759    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/docker-flags-20200110T124435.195281233-4968/config.json: {Name:mkdaad18e510c59d8ed36ae0a57d5f99003a621b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:44:37.746156    8239 cluster.go:96] Machine does not exist... provisioning new machine
        I0110 12:44:37.746177    8239 cluster.go:97] Provisioning machine with config: {Name:docker-flags-20200110T124435.195281233-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[FOO=BAR BAZ=BAT] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[debug icc=true] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:false EnableDefaultCNI:false} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
        I0110 12:44:37.746499    8239 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
        I0110 12:44:37.746591    8239 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:44:37.759797    8239 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:34101
        I0110 12:44:37.760325    8239 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:44:37.761173    8239 main.go:110] libmachine: Using API Version  1
        I0110 12:44:37.761200    8239 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:44:37.761606    8239 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:44:37.761812    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetMachineName
        I0110 12:44:37.762024    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:44:37.762218    8239 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
        I0110 12:44:37.762263    8239 main.go:110] libmachine: Decoding PEM data...
        I0110 12:44:37.762286    8239 main.go:110] libmachine: Parsing certificate...
        I0110 12:44:37.762380    8239 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
        I0110 12:44:37.762438    8239 main.go:110] libmachine: Decoding PEM data...
        I0110 12:44:37.762456    8239 main.go:110] libmachine: Parsing certificate...
        I0110 12:44:37.762514    8239 main.go:110] libmachine: Running pre-create checks...
        I0110 12:44:37.762529    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .PreCreateCheck
        I0110 12:44:37.762832    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetConfigRaw
        I0110 12:44:37.763268    8239 main.go:110] libmachine: Creating machine...
        I0110 12:44:37.763289    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .Create
        I0110 12:44:37.763468    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Creating KVM machine...
        I0110 12:44:37.766610    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968 ...
        I0110 12:44:37.766650    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
        I0110 12:44:37.766784    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | ERROR: logging before flag.Parse: I0110 12:44:37.766613    8421 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
        I0110 12:44:37.766868    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
        I0110 12:44:37.895077    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | ERROR: logging before flag.Parse: I0110 12:44:37.894902    8421 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968/id_rsa...
        I0110 12:44:38.032597    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | ERROR: logging before flag.Parse: I0110 12:44:38.032452    8421 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968/docker-flags-20200110T124435.195281233-4968.rawdisk...
        I0110 12:44:38.032676    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Writing magic tar header
        I0110 12:44:38.032717    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Writing SSH key tar header
        I0110 12:44:38.032752    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | ERROR: logging before flag.Parse: I0110 12:44:38.032615    8421 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968 ...
        I0110 12:44:38.032805    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968
        I0110 12:44:38.032845    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968 (perms=drwx------)
        I0110 12:44:38.032878    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
        I0110 12:44:38.032922    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
        I0110 12:44:38.032954    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
        I0110 12:44:38.032979    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
        I0110 12:44:38.033024    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
        I0110 12:44:38.033050    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
        I0110 12:44:38.033073    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
        I0110 12:44:38.033095    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home/jenkins
        I0110 12:44:38.033119    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
        I0110 12:44:38.033158    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
        I0110 12:44:38.033177    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Creating domain...
        I0110 12:44:38.033194    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Checking permissions on dir: /home
        I0110 12:44:38.033248    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Skipping /home - not owner
        I0110 12:44:38.712393    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Creating network...
        I0110 12:44:38.716167    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Ensuring networks are active...
        I0110 12:44:38.719120    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Ensuring network default is active
        I0110 12:44:38.720021    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Ensuring network minikube-net is active
        I0110 12:44:38.720657    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Getting domain xml...
        I0110 12:44:38.723514    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Creating domain...
        I0110 12:44:39.253535    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Waiting to get IP...
        I0110 12:44:39.260345    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 0/40
        I0110 12:44:42.267407    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 1/40
        I0110 12:44:45.275306    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 2/40
        I0110 12:44:48.282853    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 3/40
        I0110 12:44:51.290410    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 4/40
        I0110 12:44:54.296988    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 5/40
        I0110 12:44:57.304492    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 6/40
        I0110 12:45:00.312501    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 7/40
        I0110 12:45:03.319406    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 8/40
        I0110 12:45:06.329065    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 9/40
        I0110 12:45:09.337242    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 10/40
        I0110 12:45:12.344543    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Waiting for machine to come up 11/40
        I0110 12:45:15.351802    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Getting to WaitForSSH function...
        I0110 12:45:15.351833    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Found IP for machine: 192.168.39.44
        I0110 12:45:15.351853    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Waiting for SSH to be available...
        I0110 12:45:15.377321    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Using SSH client type: external
        I0110 12:45:15.377373    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968/id_rsa (-rw-------)
        I0110 12:45:15.377437    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.44 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/docker-flags-20200110T124435.195281233-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:45:15.377466    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | About to run SSH command:
        I0110 12:45:15.377515    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | exit 0
        I0110 12:45:15.531516    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | SSH cmd err, output: <nil>: 
        I0110 12:45:15.532203    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) KVM machine creation complete!
        I0110 12:45:15.532274    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetConfigRaw
        I0110 12:45:15.532995    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:15.533252    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:15.533497    8239 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
        I0110 12:45:15.533519    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetState
        I0110 12:45:15.537363    8239 main.go:110] libmachine: Detecting operating system of created instance...
        I0110 12:45:15.537384    8239 main.go:110] libmachine: Waiting for SSH to be available...
        I0110 12:45:15.537392    8239 main.go:110] libmachine: Getting to WaitForSSH function...
        I0110 12:45:15.537400    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:15.544002    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:15.544231    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.544415    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.544606    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:15.544854    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:15.545095    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:15.545116    8239 main.go:110] libmachine: About to run SSH command:
        exit 0
        I0110 12:45:15.677725    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:45:15.677755    8239 main.go:110] libmachine: Detecting the provisioner...
        I0110 12:45:15.677773    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:15.685157    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:15.685466    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.685704    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.685901    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:15.686135    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:15.686377    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:15.686398    8239 main.go:110] libmachine: About to run SSH command:
        cat /etc/os-release
        I0110 12:45:15.819056    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
        VERSION=2019.02.7
        ID=buildroot
        VERSION_ID=2019.02.7
        PRETTY_NAME="Buildroot 2019.02.7"
        
        I0110 12:45:15.819129    8239 main.go:110] libmachine: found compatible host: buildroot
        I0110 12:45:15.819149    8239 main.go:110] libmachine: Provisioning with buildroot...
        I0110 12:45:15.819166    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetMachineName
        I0110 12:45:15.819485    8239 main.go:110] libmachine: setting hostname "docker-flags-20200110T124435.195281233-4968"
        I0110 12:45:15.819507    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetMachineName
        I0110 12:45:15.819761    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:15.827273    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:15.827531    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.827747    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.827970    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:15.828187    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:15.828425    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:15.828449    8239 main.go:110] libmachine: About to run SSH command:
        sudo hostname docker-flags-20200110T124435.195281233-4968 && echo "docker-flags-20200110T124435.195281233-4968" | sudo tee /etc/hostname
        I0110 12:45:15.980759    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: docker-flags-20200110T124435.195281233-4968
        
        I0110 12:45:15.980794    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:15.988567    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:15.988815    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.988992    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:15.989182    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:15.989469    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:15.989647    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:15.989678    8239 main.go:110] libmachine: About to run SSH command:
        
        		if ! grep -xq '.*\sdocker-flags-20200110T124435.195281233-4968' /etc/hosts; then
        			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
        				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 docker-flags-20200110T124435.195281233-4968/g' /etc/hosts;
        			else 
        				echo '127.0.1.1 docker-flags-20200110T124435.195281233-4968' | sudo tee -a /etc/hosts; 
        			fi
        		fi
        I0110 12:45:16.126470    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:45:16.126560    8239 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
        I0110 12:45:16.126574    8239 main.go:110] libmachine: setting up certificates
        I0110 12:45:16.126590    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetMachineName
        I0110 12:45:16.126917    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetIP
        I0110 12:45:16.134636    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.pem
        I0110 12:45:16.134926    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cert.pem
        I0110 12:45:16.135084    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/key.pem
        I0110 12:45:16.135295    8239 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.docker-flags-20200110T124435.195281233-4968 san=[192.168.39.44 localhost]
        I0110 12:45:16.312722    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:16.320701    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:16.320933    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.321247    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:16.362984    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem -> /etc/docker/ca.pem
        I0110 12:45:16.411888    8239 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
        I0110 12:45:16.412423    8239 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
        I0110 12:45:16.413544    8239 ssh_runner.go:194] ca.pem: copied 1038 bytes
        I0110 12:45:16.432244    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem -> /etc/docker/server.pem
        I0110 12:45:16.437870    8239 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
        I0110 12:45:16.438204    8239 ssh_runner.go:175] Transferring 1159 bytes to /etc/docker/server.pem
        I0110 12:45:16.439021    8239 ssh_runner.go:194] server.pem: copied 1159 bytes
        I0110 12:45:16.454968    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem -> /etc/docker/server-key.pem
        I0110 12:45:16.460153    8239 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
        I0110 12:45:16.460673    8239 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
        I0110 12:45:16.461737    8239 ssh_runner.go:194] server-key.pem: copied 1675 bytes
        I0110 12:45:16.477193    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetMachineName
        I0110 12:45:16.477739    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:16.477943    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:16.484878    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:16.485120    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.485370    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.485569    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:16.485856    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:16.486021    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:16.486041    8239 main.go:110] libmachine: About to run SSH command:
        df --output=fstype / | tail -n 1
        I0110 12:45:16.618405    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
        
        I0110 12:45:16.618438    8239 main.go:110] libmachine: root file system type: tmpfs
        I0110 12:45:16.618749    8239 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
        I0110 12:45:16.618788    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:16.625881    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:16.626095    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.626337    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.626543    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:16.626796    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:16.627009    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:16.627164    8239 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        Environment="FOO=BAR"
        Environment="BAZ=BAT"
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 --debug --icc=true 
        ExecReload=/bin/kill -s HUP $MAINPID
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        " | sudo tee /lib/systemd/system/docker.service
        I0110 12:45:16.764829    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        Environment=FOO=BAR
        Environment=BAZ=BAT
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 --debug --icc=true 
        ExecReload=/bin/kill -s HUP 
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        
        I0110 12:45:16.764862    8239 main.go:110] libmachine: setting minikube options for container-runtime
        I0110 12:45:16.764946    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:16.772272    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:16.772507    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.772756    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.772956    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:16.773205    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:16.773446    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:16.773481    8239 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /etc/sysconfig && printf %s "
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        " | sudo tee /etc/sysconfig/crio.minikube
        I0110 12:45:16.913470    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        
        I0110 12:45:16.913512    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:16.921918    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:16.922107    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.922308    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:16.922525    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:16.922751    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:16.922955    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:16.922998    8239 main.go:110] libmachine: About to run SSH command:
        sudo systemctl daemon-reload
        I0110 12:45:17.187157    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:45:17.187198    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:17.194777    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:17.195069    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:17.195305    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:17.195508    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:17.195742    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:17.195912    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:17.195931    8239 main.go:110] libmachine: About to run SSH command:
        sudo systemctl -f restart crio
        I0110 12:45:24.755156    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:45:24.755226    8239 main.go:110] libmachine: Checking connection to Docker...
        I0110 12:45:24.755301    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetURL
        I0110 12:45:24.760660    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Using libvirt version 3000000
        I0110 12:45:24.768073    8239 main.go:110] libmachine: Docker is up and running!
        I0110 12:45:24.768109    8239 main.go:110] libmachine: Reticulating splines...
        I0110 12:45:24.768125    8239 main.go:110] libmachine: Waiting for SSH to be available...
        I0110 12:45:24.768146    8239 main.go:110] libmachine: Getting to WaitForSSH function...
        I0110 12:45:24.768164    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:24.774907    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:24.775164    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:24.775421    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:24.775645    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:24.775883    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:24.776051    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:24.776068    8239 main.go:110] libmachine: About to run SSH command:
        exit 0
        I0110 12:45:24.909742    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:45:24.909779    8239 main.go:110] libmachine: Detecting the provisioner...
        I0110 12:45:24.909797    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:24.917354    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:24.917591    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:24.917812    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:24.918005    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:24.918225    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:24.918428    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:24.918448    8239 main.go:110] libmachine: About to run SSH command:
        cat /etc/os-release
        I0110 12:45:25.051405    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
        VERSION=2019.02.7
        ID=buildroot
        VERSION_ID=2019.02.7
        PRETTY_NAME="Buildroot 2019.02.7"
        
        I0110 12:45:25.051478    8239 main.go:110] libmachine: found compatible host: buildroot
        I0110 12:45:25.051499    8239 cluster.go:418] Provisioned with Buildroot 2019.02.7
        I0110 12:45:25.051511    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:25.059158    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:25.059455    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:25.059661    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:25.059892    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:25.060104    8239 main.go:110] libmachine: Using SSH client type: native
        I0110 12:45:25.060285    8239 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.44 22 <nil> <nil>}
        I0110 12:45:25.060303    8239 main.go:110] libmachine: About to run SSH command:
        date +%s.%N
        I0110 12:45:25.192213    8239 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578660325.045915016
        
        I0110 12:45:25.192241    8239 cluster.go:197] guest clock: 1578660325.045915016
        I0110 12:45:25.192251    8239 cluster.go:210] Guest: 2020-01-10 12:45:25.045915016 +0000 UTC Remote: 2020-01-10 12:45:25.051502859 +0000 UTC m=+49.850731910 (delta=-5.587843ms)
        I0110 12:45:25.192286    8239 cluster.go:181] guest clock delta is within tolerance: -5.587843ms
        I0110 12:45:25.192318    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetConfigRaw
        I0110 12:45:25.193124    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:25.193378    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:25.193657    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:25.201994    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:25.202240    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:25.202480    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:25.243849    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetIP
        I0110 12:45:25.252072    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:25.252306    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:25.253193    8239 ssh_runner.go:102] Run: nslookup kubernetes.io
        I0110 12:45:25.303968    8239 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
        I0110 12:45:25.339301    8239 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/docker-flags-20200110T124435.195281233-4968/config.json ...
        I0110 12:45:25.339700    8239 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
        I0110 12:45:25.354910    8239 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:45:25.364948    8239 ssh_runner.go:102] Run: sudo systemctl stop crio
        I0110 12:45:25.498400    8239 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:45:25.509083    8239 ssh_runner.go:102] Run: sudo systemctl start docker
        I0110 12:45:26.692836    8239 ssh_runner.go:142] Completed: sudo systemctl start docker: (1.183712947s)
        I0110 12:45:26.692964    8239 ssh_runner.go:102] Run: docker version --format '{{.Server.Version}}'
        I0110 12:45:26.938548    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetURL
        I0110 12:45:26.943448    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) DBG | Using libvirt version 3000000
        I0110 12:45:26.952018    8239 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:26.952225    8239 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
        I0110 12:45:26.958743    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:26.959971    8239 main.go:110] libmachine: Found binary path at /home/jenkins/workspace/KVM_Linux_integration/out/docker-machine-driver-kvm2
        I0110 12:45:26.960129    8239 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:45:26.974634    8239 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:41279
        I0110 12:45:26.975213    8239 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:45:26.975781    8239 main.go:110] libmachine: Using API Version  1
        I0110 12:45:26.975806    8239 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:45:26.976196    8239 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:45:26.976574    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:26.976833    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .DriverName
        I0110 12:45:26.977082    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHHostname
        I0110 12:45:26.985600    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHPort
        I0110 12:45:26.985806    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHKeyPath
        I0110 12:45:26.986035    8239 main.go:110] libmachine: (docker-flags-20200110T124435.195281233-4968) Calling .GetSSHUsername
        I0110 12:45:27.030210    8239 kubeadm.go:390] kubelet [Unit]
        Wants=docker.socket
        
        [Service]
        ExecStart=
        ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=docker --fail-swap-on=false --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.39.44 --pod-manifest-path=/etc/kubernetes/manifests
        
        [Install]
         config:
        {KubernetesVersion:v1.17.0 NodeIP:192.168.39.44 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:false EnableDefaultCNI:false}
        I0110 12:45:27.030257    8239 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
        W0110 12:45:27.091642    8239 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
        stdout:
        
        stderr:
         command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
        I0110 12:45:27.092423    8239 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
        I0110 12:45:27.092450    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/v1.17.0/kubeadm -> /var/lib/minikube/binaries/v1.17.0/kubeadm
        I0110 12:45:27.092575    8239 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
        I0110 12:45:27.092593    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/v1.17.0/kubelet -> /var/lib/minikube/binaries/v1.17.0/kubelet
        I0110 12:45:27.099510    8239 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
        I0110 12:45:27.099923    8239 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
        I0110 12:45:27.112344    8239 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
        I0110 12:45:27.146765    8239 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
        I0110 12:45:27.565337    8239 ssh_runner.go:194] kubeadm: copied 39342080 bytes
        I0110 12:45:28.072979    8239 ssh_runner.go:194] kubelet: copied 111560216 bytes
        I0110 12:45:28.087364    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/files/etc/sync.test -> /etc/sync.test
        I0110 12:45:28.089751    8239 ssh_runner.go:175] Transferring 1151 bytes to /var/tmp/minikube/kubeadm.yaml
        I0110 12:45:28.090955    8239 ssh_runner.go:194] kubeadm.yaml: copied 1151 bytes
        I0110 12:45:28.110207    8239 ssh_runner.go:175] Transferring 560 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        I0110 12:45:28.111332    8239 ssh_runner.go:194] 10-kubeadm.conf: copied 560 bytes
        I0110 12:45:28.129484    8239 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
        I0110 12:45:28.130618    8239 ssh_runner.go:194] kubelet.service: copied 349 bytes
        I0110 12:45:28.154063    8239 ssh_runner.go:156] Checked if /etc/sync.test exists, but got error: Process exited with status 1
        I0110 12:45:28.154508    8239 ssh_runner.go:175] Transferring 40 bytes to /etc/sync.test
        I0110 12:45:28.155387    8239 ssh_runner.go:194] sync.test: copied 40 bytes
        I0110 12:45:28.173681    8239 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
        I0110 12:45:28.174643    8239 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
        I0110 12:45:28.193601    8239 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
        I0110 12:45:28.194738    8239 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
        I0110 12:45:28.212324    8239 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
        I0110 12:45:28.213250    8239 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
        I0110 12:45:28.231299    8239 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
        I0110 12:45:28.232169    8239 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
        I0110 12:45:28.249895    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
        I0110 12:45:28.402971    8239 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.44
        I0110 12:45:28.403016    8239 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.403217    8239 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
        I0110 12:45:28.406369    8239 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
        I0110 12:45:28.406406    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.406665    8239 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
        I0110 12:45:28.406690    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.406873    8239 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.44 10.96.0.1 127.0.0.1 10.0.0.1]
        I0110 12:45:28.409895    8239 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
        I0110 12:45:28.409921    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.410096    8239 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
        I0110 12:45:28.410127    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.410267    8239 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
        I0110 12:45:28.413275    8239 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
        I0110 12:45:28.413300    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.413491    8239 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
        I0110 12:45:28.413523    8239 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:45:28.413682    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.crt -> /var/lib/minikube/certs/ca.crt
        I0110 12:45:28.413727    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.key -> /var/lib/minikube/certs/ca.key
        I0110 12:45:28.413748    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt -> /var/lib/minikube/certs/apiserver.crt
        I0110 12:45:28.413764    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key -> /var/lib/minikube/certs/apiserver.key
        I0110 12:45:28.413788    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.crt -> /var/lib/minikube/certs/proxy-client-ca.crt
        I0110 12:45:28.413811    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client-ca.key -> /var/lib/minikube/certs/proxy-client-ca.key
        I0110 12:45:28.413833    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt -> /var/lib/minikube/certs/proxy-client.crt
        I0110 12:45:28.413868    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key -> /var/lib/minikube/certs/proxy-client.key
        I0110 12:45:28.414033    8239 vm_assets.go:89] NewFileAsset: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/ca.crt -> /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:45:28.422797    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
        I0110 12:45:28.423378    8239 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
        I0110 12:45:28.424744    8239 ssh_runner.go:194] ca.crt: copied 1066 bytes
        I0110 12:45:28.452513    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
        I0110 12:45:28.453044    8239 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
        I0110 12:45:28.454235    8239 ssh_runner.go:194] ca.key: copied 1675 bytes
        I0110 12:45:28.478376    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
        I0110 12:45:28.478829    8239 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
        I0110 12:45:28.479739    8239 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
        I0110 12:45:28.502460    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
        I0110 12:45:28.502969    8239 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
        I0110 12:45:28.504774    8239 ssh_runner.go:194] apiserver.key: copied 1679 bytes
        I0110 12:45:28.529272    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
        I0110 12:45:28.529681    8239 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
        I0110 12:45:28.530570    8239 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
        I0110 12:45:28.556465    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
        I0110 12:45:28.556983    8239 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
        I0110 12:45:28.558205    8239 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
        I0110 12:45:28.591620    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
        I0110 12:45:28.592123    8239 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
        I0110 12:45:28.593615    8239 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
        I0110 12:45:28.629898    8239 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
        I0110 12:45:28.632316    8239 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
        I0110 12:45:28.633342    8239 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
        I0110 12:45:28.662144    8239 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
        I0110 12:45:28.662735    8239 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:45:28.663646    8239 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
        I0110 12:45:28.698687    8239 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
        I0110 12:45:28.699566    8239 ssh_runner.go:194] kubeconfig: copied 428 bytes
        I0110 12:45:28.723824    8239 ssh_runner.go:102] Run: openssl version
        I0110 12:45:28.736651    8239 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
        I0110 12:45:28.752369    8239 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
        I0110 12:45:28.762726    8239 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:45:28.777346    8239 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
        I0110 12:45:28.786277    8239 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
        I0110 12:45:28.794282    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
        I0110 12:45:29.065047    8239 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
        I0110 12:45:29.077818    8239 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
        stdout:
        
        stderr:
        ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
        ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
        ls: cannot access '/var/lib/minikube/etcd': No such file or directory
        I0110 12:45:29.077853    8239 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.44 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:false EnableDefaultCNI:false}
        I0110 12:45:29.077917    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
        I0110 12:45:29.177407    8239 kubeadm.go:152] StartCluster complete in 99.521ms
        I0110 12:45:29.177527    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-apiserver --format="{{.ID}}"
        I0110 12:45:29.240936    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.240965    8239 logs.go:180] No container was found matching "kube-apiserver"
        I0110 12:45:29.241018    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_coredns --format="{{.ID}}"
        I0110 12:45:29.285706    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.285738    8239 logs.go:180] No container was found matching "coredns"
        I0110 12:45:29.285810    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-scheduler --format="{{.ID}}"
        I0110 12:45:29.331433    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.331468    8239 logs.go:180] No container was found matching "kube-scheduler"
        I0110 12:45:29.331552    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-proxy --format="{{.ID}}"
        I0110 12:45:29.376038    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.376087    8239 logs.go:180] No container was found matching "kube-proxy"
        I0110 12:45:29.376180    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-addon-manager --format="{{.ID}}"
        I0110 12:45:29.423604    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.423639    8239 logs.go:180] No container was found matching "kube-addon-manager"
        I0110 12:45:29.423705    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format="{{.ID}}"
        I0110 12:45:29.468264    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.468297    8239 logs.go:180] No container was found matching "kubernetes-dashboard"
        I0110 12:45:29.468359    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_storage-provisioner --format="{{.ID}}"
        I0110 12:45:29.511406    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.511432    8239 logs.go:180] No container was found matching "storage-provisioner"
        I0110 12:45:29.511507    8239 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format="{{.ID}}"
        I0110 12:45:29.564855    8239 logs.go:178] 0 containers: []
        W0110 12:45:29.564878    8239 logs.go:180] No container was found matching "kube-controller-manager"
        I0110 12:45:29.564891    8239 logs.go:92] Gathering logs for kubelet ...
        I0110 12:45:29.564902    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
        I0110 12:45:29.583049    8239 logs.go:92] Gathering logs for dmesg ...
        I0110 12:45:29.583084    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
        I0110 12:45:29.603074    8239 logs.go:92] Gathering logs for Docker ...
        I0110 12:45:29.603111    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
        I0110 12:45:29.651093    8239 logs.go:92] Gathering logs for container status ...
        I0110 12:45:29.651141    8239 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
        I0110 12:45:31.782631    8239 ssh_runner.go:142] Completed: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a": (2.131466885s)
        W0110 12:45:31.782868    8239 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:45:29.088802    2326 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        * 
        X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:45:29.088802    2326 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * 
        * minikube is exiting due to an error. If the above message is not useful, open an issue:
          - https://github.com/kubernetes/minikube/issues/new/choose
        
        ** /stderr **
    docker_test.go:44: [out/minikube-linux-amd64 start -p docker-flags-20200110T124435.195281233-4968 --cache-images=false --wait=false --docker-env=FOO=BAR --docker-env=BAZ=BAT --docker-opt=debug --docker-opt=icc=true --alsologtostderr -v=5 --vm-driver=kvm2 ] failed: exit status 70
    docker_test.go:47: (dbg) Run:  out/minikube-linux-amd64 -p docker-flags-20200110T124435.195281233-4968 ssh "systemctl show docker --property=Environment --no-pager"
    docker_test.go:47: (dbg) Done: out/minikube-linux-amd64 -p docker-flags-20200110T124435.195281233-4968 ssh "systemctl show docker --property=Environment --no-pager": (1.359489458s)
    docker_test.go:58: (dbg) Run:  out/minikube-linux-amd64 -p docker-flags-20200110T124435.195281233-4968 ssh "systemctl show docker --property=ExecStart --no-pager"
    docker_test.go:67: *** TestDockerFlags FAILED at 2020-01-10 12:45:33.738566202 +0000 UTC m=+754.383585056
    docker_test.go:67: >>> TestDockerFlags FAILED: start of post-mortem logs >>>
    docker_test.go:67: (dbg) Run:  kubectl --context docker-flags-20200110T124435.195281233-4968 get po -A --show-labels
    docker_test.go:67: (dbg) Non-zero exit: kubectl --context docker-flags-20200110T124435.195281233-4968 get po -A --show-labels: exit status 1 (147.691103ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.44:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    docker_test.go:67: kubectl --context docker-flags-20200110T124435.195281233-4968 get po -A --show-labels: exit status 1
    docker_test.go:67: (dbg) kubectl --context docker-flags-20200110T124435.195281233-4968 get po -A --show-labels:
    docker_test.go:67: (dbg) Run:  kubectl --context docker-flags-20200110T124435.195281233-4968 describe node
    docker_test.go:67: (dbg) Non-zero exit: kubectl --context docker-flags-20200110T124435.195281233-4968 describe node: exit status 1 (66.628237ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.44:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    docker_test.go:67: kubectl --context docker-flags-20200110T124435.195281233-4968 describe node: exit status 1
    docker_test.go:67: (dbg) Run:  out/minikube-linux-amd64 -p docker-flags-20200110T124435.195281233-4968 logs --problems
    docker_test.go:67: (dbg) Done: out/minikube-linux-amd64 -p docker-flags-20200110T124435.195281233-4968 logs --problems: (2.757496269s)
    docker_test.go:67: TestDockerFlags logs: 
    docker_test.go:67: <<< TestDockerFlags FAILED: end of post-mortem logs <<<
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p docker-flags-20200110T124435.195281233-4968
=== CONT  TestFunctional/parallel/AddonManager
    > docker-machine-driver-kvm2: 37.72 MiB / 48.57 MiB  77.65% 1.71 MiB p/s ET    > docker-machine-driver-kvm2: 38.08 MiB / 48.57 MiB  78.40% 1.71 MiB p/s ET    > docker-machine-driver-kvm2: 38.45 MiB / 48.57 MiB  79.16% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 38.83 MiB / 48.57 MiB  79.94% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 39.18 MiB / 48.57 MiB  80.66% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 39.53 MiB / 48.57 MiB  81.38% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 39.96 MiB / 48.57 MiB  82.27% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 40.31 MiB / 48.57 MiB  82.98% 1.72 MiB p/s ET    > docker-machine-driver-kvm2: 40.77 MiB / 48.57 MiB  83.94% 1.75 MiB p/s ET    > docker-machine-driver-kvm2: 41.29 MiB / 48.57 MiB  85.00% 1.75 MiB p/s ET    > docker-machine-driver-kvm2: 41.82 MiB / 48.57 MiB  86.09% 1.75 MiB p/s ET    > docker-machine-driver-kvm2: 42.38 MiB / 48.57 MiB  87.26% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 42.98 MiB / 48.57 MiB  88.49% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 43.46 MiB / 48.57 MiB  89.48% 1.81 MiB p/s ET    > docker-machine-driver-kvm2: 43.78 MiB / 48.57 MiB  90.13% 1.84 MiB p/s ET    > docker-machine-driver-kvm2: 44.13 MiB / 48.57 MiB  90.84% 1.84 MiB p/s ET    > docker-machine-driver-kvm2: 44.51 MiB / 48.57 MiB  91.63% 1.84 MiB p/s ET    > docker-machine-driver-kvm2: 44.94 MiB / 48.57 MiB  92.52% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 45.36 MiB / 48.57 MiB  93.37% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 45.74 MiB / 48.57 MiB  94.16% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 46.05 MiB / 48.57 MiB  94.81% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 46.38 MiB / 48.57 MiB  95.49% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 46.68 MiB / 48.57 MiB  96.11% 1.85 MiB p/s ET    > docker-machine-driver-kvm2: 47.00 MiB / 48.57 MiB  96.76% 1.83 MiB p/s ET    > docker-machine-driver-kvm2: 47.35 MiB / 48.57 MiB  97.47% 1.83 MiB p/s ET    > docker-machine-driver-kvm2: 47.71 MiB / 48.57 MiB  98.22% 1.83 MiB p/s ET    > docker-machine-driver-kvm2: 48.06 MiB / 48.57 MiB  98.94% 1.83 MiB p/s ET    > docker-machine-driver-kvm2: 48.39 MiB / 48.57 MiB  99.63% 1.83 MiB p/s ET    > docker-machine-driver-kvm2: 48.57 MiB / 48.57 MiB  100.00% 1.60 MiB p/s 3--- PASS: TestKVMDriverInstallOrUpdate (68.06s)
=== CONT  TestFunctional/parallel/ServiceCmd
--- FAIL: TestGvisorAddon (183.78s)
    helpers.go:373: Waiting for start slot at 2020-01-10 12:45:25.195248657 +0000 UTC m=+745.840267405 (sleeping 49.999841671s)  ...
    gvisor_addon_test.go:53: (dbg) Run:  out/minikube-linux-amd64 start -p gvisor-20200110T124525.195554881-4968 --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --vm-driver=kvm2 
    gvisor_addon_test.go:53: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p gvisor-20200110T124525.195554881-4968 --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --vm-driver=kvm2 : exit status 70 (2m5.169618565s)
        -- stdout --
        * [gvisor-20200110T124525.195554881-4968] minikube v1.6.2 on Debian 9.11
          - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
          - MINIKUBE_BIN=out/minikube-linux-amd64
          - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
          - MINIKUBE_LOCATION=6150
        * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
        * Downloading driver docker-machine-driver-kvm2:
        * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
        * Preparing Kubernetes v1.17.0 on containerd 1.2.10 ...
          - opt containerd=/var/run/containerd/containerd.sock
        * Pulling images ...
        * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:47:29.769476    2493 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * Launching Kubernetes ... 
        
        -- /stdout --
        ** stderr ** 
            > docker-machine-driver-kvm2.sha256: 65 B / 65 B [-------] 100.00% ? p/s 0s    > docker-machine-driver-kvm2: 1.58 MiB / 13.86 MiB [>______] 11.38% ? p/s ?    > docker-machine-driver-kvm2: 13.86 MiB / 13.86 MiB  100.00% 78.92 MiB p/s * 
        X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:47:29.877774    2500 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * 
        * minikube is exiting due to an error. If the above message is not useful, open an issue:
          - https://github.com/kubernetes/minikube/issues/new/choose
        
        ** /stderr **
    gvisor_addon_test.go:55: [out/minikube-linux-amd64 start -p gvisor-20200110T124525.195554881-4968 --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --vm-driver=kvm2 ] failed: exit status 70
    gvisor_addon_test.go:43: (dbg) Run:  kubectl --context gvisor-20200110T124525.195554881-4968 logs gvisor -n kube-system
    gvisor_addon_test.go:43: (dbg) Non-zero exit: kubectl --context gvisor-20200110T124525.195554881-4968 logs gvisor -n kube-system: exit status 1 (271.801949ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.224:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    gvisor_addon_test.go:45: failed to get gvisor post-mortem logs: exit status 1
    gvisor_addon_test.go:47: gvisor post-mortem: kubectl --context gvisor-20200110T124525.195554881-4968 logs gvisor -n kube-system:
        
        ** stderr ** 
        The connection to the server 192.168.39.224:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    gvisor_addon_test.go:49: *** TestGvisorAddon FAILED at 2020-01-10 12:47:30.637455995 +0000 UTC m=+871.282474835
    gvisor_addon_test.go:49: >>> TestGvisorAddon FAILED: start of post-mortem logs >>>
    gvisor_addon_test.go:49: (dbg) Run:  kubectl --context gvisor-20200110T124525.195554881-4968 get po -A --show-labels
    gvisor_addon_test.go:49: (dbg) Non-zero exit: kubectl --context gvisor-20200110T124525.195554881-4968 get po -A --show-labels: exit status 1 (109.513708ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.224:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    gvisor_addon_test.go:49: kubectl --context gvisor-20200110T124525.195554881-4968 get po -A --show-labels: exit status 1
    gvisor_addon_test.go:49: (dbg) kubectl --context gvisor-20200110T124525.195554881-4968 get po -A --show-labels:
    gvisor_addon_test.go:49: (dbg) Run:  kubectl --context gvisor-20200110T124525.195554881-4968 describe node
    gvisor_addon_test.go:49: (dbg) Non-zero exit: kubectl --context gvisor-20200110T124525.195554881-4968 describe node: exit status 1 (196.468164ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.224:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    gvisor_addon_test.go:49: kubectl --context gvisor-20200110T124525.195554881-4968 describe node: exit status 1
    gvisor_addon_test.go:49: (dbg) Run:  out/minikube-linux-amd64 -p gvisor-20200110T124525.195554881-4968 logs --problems
    gvisor_addon_test.go:49: (dbg) Done: out/minikube-linux-amd64 -p gvisor-20200110T124525.195554881-4968 logs --problems: (4.200914551s)
    gvisor_addon_test.go:49: TestGvisorAddon logs: 
    gvisor_addon_test.go:49: <<< TestGvisorAddon FAILED: end of post-mortem logs <<<
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p gvisor-20200110T124525.195554881-4968
    helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p gvisor-20200110T124525.195554881-4968: (3.831463271s)
=== CONT  TestFunctional/parallel/UpdateContextCmd
=== CONT  TestFunctional/parallel/FileSync
=== CONT  TestFunctional/parallel/MySQL
=== CONT  TestFunctional/parallel/SSHCmd
=== CONT  TestFunctional/parallel/TunnelCmd
=== CONT  TestFunctional/parallel/PersistentVolumeClaim
=== CONT  TestFunctional/parallel/AddonsCmd
=== CONT  TestFunctional/parallel/StatusCmd
=== CONT  TestFunctional/parallel/ProfileCmd
=== CONT  TestFunctional/parallel/MountCmd
=== CONT  TestFunctional/parallel/LogsCmd
=== CONT  TestFunctional/parallel/DashboardCmd
=== CONT  TestFunctional/parallel/DNS
=== CONT  TestFunctional/parallel/ConfigCmd
=== CONT  TestFunctional/parallel/ComponentHealth
--- FAIL: TestVersionUpgrade (475.60s)
    helpers.go:373: Waiting for start slot at 2020-01-10 12:46:15.195248657 +0000 UTC m=+795.840267405 (sleeping 1m39.999778691s)  ...
    version_upgrade_test.go:72: (dbg) Run:  /tmp/minikube-release.762602134.exe start -p vupgrade-20200110T124615.195477825-4968 --kubernetes-version=v1.11.10 --alsologtostderr -v=1 --vm-driver=kvm2 
    version_upgrade_test.go:72: (dbg) Done: /tmp/minikube-release.762602134.exe start -p vupgrade-20200110T124615.195477825-4968 --kubernetes-version=v1.11.10 --alsologtostderr -v=1 --vm-driver=kvm2 : (3m5.662331551s)
    version_upgrade_test.go:81: (dbg) Run:  /tmp/minikube-release.762602134.exe stop -p vupgrade-20200110T124615.195477825-4968
    version_upgrade_test.go:81: (dbg) Done: /tmp/minikube-release.762602134.exe stop -p vupgrade-20200110T124615.195477825-4968: (18.321600712s)
    version_upgrade_test.go:86: (dbg) Run:  /tmp/minikube-release.762602134.exe -p vupgrade-20200110T124615.195477825-4968 status --format={{.Host}}
    version_upgrade_test.go:86: (dbg) Non-zero exit: /tmp/minikube-release.762602134.exe -p vupgrade-20200110T124615.195477825-4968 status --format={{.Host}}: exit status 1 (104.907297ms)
        -- stdout --
        Stopped
        -- /stdout --
    version_upgrade_test.go:88: status error: exit status 1 (may be ok)
    helpers.go:373: Waiting for start slot at 2020-01-10 12:50:25.195248657 +0000 UTC m=+1045.840267405 (sleeping 45.476365917s)  ...
    version_upgrade_test.go:97: (dbg) Run:  out/minikube-linux-amd64 start -p vupgrade-20200110T124615.195477825-4968 --kubernetes-version=v1.17.0 --alsologtostderr -v=1 --vm-driver=kvm2 
    version_upgrade_test.go:97: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p vupgrade-20200110T124615.195477825-4968 --kubernetes-version=v1.17.0 --alsologtostderr -v=1 --vm-driver=kvm2 : exit status 70 (2m0.310609989s)
        -- stdout --
        * [vupgrade-20200110T124615.195477825-4968] minikube v1.6.2 on Debian 9.11
          - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
          - MINIKUBE_BIN=out/minikube-linux-amd64
          - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
          - MINIKUBE_LOCATION=6150
        * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
        * Starting existing kvm2 VM for "vupgrade-20200110T124615.195477825-4968" ...
        * Waiting for the host to be provisioned ...
        * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
        * Pulling images ...
        * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:52:21.040593    2643 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * Launching Kubernetes ... 
        
        -- /stdout --
        ** stderr ** 
        I0110 12:50:26.152667   11116 notify.go:125] Checking for updates...
        I0110 12:50:27.376623   11116 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1976,"bootTime":1578658651,"procs":238,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
        I0110 12:50:27.378238   11116 start.go:266] virtualization: kvm host
        I0110 12:50:27.379558   11116 start.go:567] selectDriver: flag="kvm2", old=&{vupgrade-20200110T124615.195477825-4968 false false https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso 2000 2 20000 kvm2 docker  [] [] [] [] 192.168.99.1/24  default qemu:///system false false <nil> [] false [] /nfsshares  false false true {v1.11.10 192.168.39.141 8443 minikube minikubeCA [] [] cluster.local docker    10.96.0.0/12  [] true false} virtio virtio map[] 0}
        I0110 12:50:27.379671   11116 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:50:28.490067   11116 global.go:68] docker priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:50:31.799711   11116 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:50:31.799827   11116 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:50:32.115554   11116 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:50:32.115679   11116 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
        I0110 12:50:32.115729   11116 driver.go:128] requested: "kvm2"
        I0110 12:50:32.115750   11116 driver.go:132] choosing "kvm2" because it was requested
        I0110 12:50:32.115769   11116 driver.go:147] not recommending "docker" due to priority: 2
        I0110 12:50:32.115785   11116 driver.go:147] not recommending "none" due to priority: 2
        I0110 12:50:32.115797   11116 driver.go:165] Picked: kvm2
        I0110 12:50:32.115811   11116 driver.go:166] Alternatives: [virtualbox docker none]
        I0110 12:50:32.115938   11116 start.go:298] selected driver: kvm2
        I0110 12:50:32.115948   11116 start.go:597] validating driver "kvm2" against &{Name:vupgrade-20200110T124615.195477825-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:<nil> DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.11.10 NodeIP:192.168.39.141 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
        I0110 12:50:32.189675   11116 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
        I0110 12:50:32.190909   11116 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
        I0110 12:50:32.191014   11116 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:50:32.234057   11116 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:39957
        I0110 12:50:32.238453   11116 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:50:32.239734   11116 main.go:110] libmachine: Using API Version  1
        I0110 12:50:32.239757   11116 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:50:32.240547   11116 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:50:32.240815   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:50:32.241163   11116 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
        I0110 12:50:32.278284   11116 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
        I0110 12:50:32.278440   11116 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/vupgrade-20200110T124615.195477825-4968/config.json ...
        I0110 12:50:32.278828   11116 cluster.go:101] Skipping create...Using existing machine configuration
        I0110 12:50:32.278893   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
        I0110 12:50:32.278906   11116 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "55.86Âµs"
        I0110 12:50:32.278922   11116 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
        I0110 12:50:32.278949   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
        I0110 12:50:32.278967   11116 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "29.691Âµs"
        I0110 12:50:32.278993   11116 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
        I0110 12:50:32.279021   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
        I0110 12:50:32.279028   11116 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "21.442Âµs"
        I0110 12:50:32.279036   11116 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
        I0110 12:50:32.279055   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
        I0110 12:50:32.279062   11116 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "17.483Âµs"
        I0110 12:50:32.279071   11116 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
        I0110 12:50:32.279090   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
        I0110 12:50:32.279096   11116 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "16.408Âµs"
        I0110 12:50:32.279103   11116 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
        I0110 12:50:32.279136   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
        I0110 12:50:32.279146   11116 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "34.982Âµs"
        I0110 12:50:32.279155   11116 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
        I0110 12:50:32.279178   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
        I0110 12:50:32.279183   11116 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "19.554Âµs"
        I0110 12:50:32.279191   11116 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
        I0110 12:50:32.279223   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
        I0110 12:50:32.279230   11116 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "30.444Âµs"
        I0110 12:50:32.279238   11116 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
        I0110 12:50:32.279258   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
        I0110 12:50:32.279266   11116 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "18.46Âµs"
        I0110 12:50:32.279275   11116 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
        I0110 12:50:32.279311   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
        I0110 12:50:32.279323   11116 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "38.209Âµs"
        I0110 12:50:32.279339   11116 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
        I0110 12:50:32.279374   11116 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
        I0110 12:50:32.279388   11116 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "37.738Âµs"
        I0110 12:50:32.279407   11116 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
        I0110 12:50:32.279420   11116 cache.go:70] Successfully saved all images to host disk.
        I0110 12:50:32.279516   11116 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
        I0110 12:50:32.279594   11116 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:50:32.332633   11116 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:36777
        I0110 12:50:32.333662   11116 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:50:32.334480   11116 main.go:110] libmachine: Using API Version  1
        I0110 12:50:32.334502   11116 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:50:32.339407   11116 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:50:32.339700   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetState
        I0110 12:50:32.346427   11116 cluster.go:113] Machine state:  Stopped
        I0110 12:50:32.346603   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .Start
        I0110 12:50:32.346813   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Creating network...
        I0110 12:50:32.352551   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Ensuring networks are active...
        I0110 12:50:32.356902   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Ensuring network default is active
        I0110 12:50:32.358126   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Ensuring network minikube-net is active
        I0110 12:50:32.359381   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Getting domain xml...
        I0110 12:50:32.364678   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Creating domain...
        I0110 12:50:37.282976   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Waiting to get IP...
        I0110 12:50:37.301351   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Getting to WaitForSSH function...
        I0110 12:50:37.301401   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Found IP for machine: 192.168.39.141
        I0110 12:50:37.301420   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Waiting for SSH to be available...
        I0110 12:50:37.314120   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH client type: external
        I0110 12:50:37.314177   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa (-rw-------)
        I0110 12:50:37.314247   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.141 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:50:37.314279   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | About to run SSH command:
        I0110 12:50:37.314308   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | exit 0
        I0110 12:50:54.470383   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | SSH cmd err, output: exit status 255: 
        I0110 12:50:54.470439   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Error getting ssh command 'exit 0' : ssh command error:
        I0110 12:50:54.470461   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | command : exit 0
        I0110 12:50:54.470485   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | err     : exit status 255
        I0110 12:50:54.470507   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | output  : 
        I0110 12:50:57.470616   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Getting to WaitForSSH function...
        I0110 12:50:57.482191   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH client type: external
        I0110 12:50:57.482246   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa (-rw-------)
        I0110 12:50:57.482304   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.141 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:50:57.482327   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | About to run SSH command:
        I0110 12:50:57.482347   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | exit 0
        I0110 12:51:04.678313   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | SSH cmd err, output: exit status 255: 
        I0110 12:51:04.678372   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Error getting ssh command 'exit 0' : ssh command error:
        I0110 12:51:04.678394   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | command : exit 0
        I0110 12:51:04.678414   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | err     : exit status 255
        I0110 12:51:04.678450   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | output  : 
        I0110 12:51:07.678699   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Getting to WaitForSSH function...
        I0110 12:51:07.690625   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH client type: external
        I0110 12:51:07.690680   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa (-rw-------)
        I0110 12:51:07.690745   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.141 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:51:07.690770   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | About to run SSH command:
        I0110 12:51:07.690797   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | exit 0
        I0110 12:51:14.886283   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | SSH cmd err, output: exit status 255: 
        I0110 12:51:14.886342   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Error getting ssh command 'exit 0' : ssh command error:
        I0110 12:51:14.886362   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | command : exit 0
        I0110 12:51:14.886381   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | err     : exit status 255
        I0110 12:51:14.886399   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | output  : 
        I0110 12:51:17.886527   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Getting to WaitForSSH function...
        I0110 12:51:17.900095   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH client type: external
        I0110 12:51:17.900172   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa (-rw-------)
        I0110 12:51:17.900255   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.141 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:51:17.900291   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | About to run SSH command:
        I0110 12:51:17.900319   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | exit 0
        I0110 12:51:24.239210   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | SSH cmd err, output: exit status 255: 
        I0110 12:51:24.239256   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Error getting ssh command 'exit 0' : ssh command error:
        I0110 12:51:24.239276   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | command : exit 0
        I0110 12:51:24.239298   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | err     : exit status 255
        I0110 12:51:24.239326   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | output  : 
        I0110 12:51:27.239431   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Getting to WaitForSSH function...
        I0110 12:51:27.345599   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH client type: external
        I0110 12:51:27.345649   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa (-rw-------)
        I0110 12:51:27.345711   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.141 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/vupgrade-20200110T124615.195477825-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
        I0110 12:51:27.345752   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | About to run SSH command:
        I0110 12:51:27.345774   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | exit 0
        I0110 12:51:27.557105   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | SSH cmd err, output: <nil>: 
        I0110 12:51:27.557698   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetConfigRaw
        I0110 12:51:27.558793   11116 cluster.go:131] engine options: &{ArbitraryFlags:[] DNS:[] GraphDir: Env:[] Ipv6:false InsecureRegistry:[10.96.0.0/12] Labels:[] LogLevel: StorageDriver: SelinuxEnabled:false TLSVerify:false RegistryMirror:[] InstallURL:https://get.docker.com}
        I0110 12:51:27.558871   11116 cluster.go:144] configureHost: &{plugin:0xc000210960 heartbeatDoneCh:0xc000412000 Client:0xc000331110}
        I0110 12:51:27.558907   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:27.559377   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:27.559622   11116 cluster.go:166] Configuring auth for driver kvm2 ...
        I0110 12:51:27.559662   11116 main.go:110] libmachine: Waiting for SSH to be available...
        I0110 12:51:27.559681   11116 main.go:110] libmachine: Getting to WaitForSSH function...
        I0110 12:51:27.559697   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:27.570816   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:27.571057   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.571347   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.571577   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:27.571913   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:27.572211   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:27.572242   11116 main.go:110] libmachine: About to run SSH command:
        exit 0
        I0110 12:51:27.737923   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:51:27.737965   11116 main.go:110] libmachine: Detecting the provisioner...
        I0110 12:51:27.737982   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:27.750082   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:27.750412   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.750643   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.750828   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:27.751069   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:27.751348   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:27.751368   11116 main.go:110] libmachine: About to run SSH command:
        cat /etc/os-release
        I0110 12:51:27.913560   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
        VERSION=2019.02.7
        ID=buildroot
        VERSION_ID=2019.02.7
        PRETTY_NAME="Buildroot 2019.02.7"
        
        I0110 12:51:27.913725   11116 main.go:110] libmachine: found compatible host: buildroot
        I0110 12:51:27.913758   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetMachineName
        I0110 12:51:27.914105   11116 main.go:110] libmachine: setting hostname "vupgrade-20200110T124615.195477825-4968"
        I0110 12:51:27.914125   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetMachineName
        I0110 12:51:27.914307   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:27.924776   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:27.925071   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.925372   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:27.925582   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:27.925830   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:27.926068   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:27.926100   11116 main.go:110] libmachine: About to run SSH command:
        sudo hostname vupgrade-20200110T124615.195477825-4968 && echo "vupgrade-20200110T124615.195477825-4968" | sudo tee /etc/hostname
        I0110 12:51:28.097965   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: vupgrade-20200110T124615.195477825-4968
        
        I0110 12:51:28.098041   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:28.108126   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:28.108486   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.108738   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.108980   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:28.109265   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:28.109560   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:28.109617   11116 main.go:110] libmachine: About to run SSH command:
        
        		if ! grep -xq '.*\svupgrade-20200110T124615.195477825-4968' /etc/hosts; then
        			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
        				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 vupgrade-20200110T124615.195477825-4968/g' /etc/hosts;
        			else 
        				echo '127.0.1.1 vupgrade-20200110T124615.195477825-4968' | sudo tee -a /etc/hosts; 
        			fi
        		fi
        I0110 12:51:28.250185   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:51:28.250324   11116 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
        I0110 12:51:28.250349   11116 main.go:110] libmachine: setting up certificates
        I0110 12:51:28.250401   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetMachineName
        I0110 12:51:28.250813   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetIP
        I0110 12:51:28.260892   11116 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.vupgrade-20200110T124615.195477825-4968 san=[192.168.39.141 localhost]
        I0110 12:51:28.467678   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:28.477857   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:28.478119   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.478485   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:28.578243   11116 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
        I0110 12:51:28.578825   11116 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
        I0110 12:51:28.579885   11116 ssh_runner.go:194] ca.pem: copied 1038 bytes
        I0110 12:51:28.626134   11116 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
        I0110 12:51:28.626882   11116 ssh_runner.go:175] Transferring 1155 bytes to /etc/docker/server.pem
        I0110 12:51:28.628107   11116 ssh_runner.go:194] server.pem: copied 1155 bytes
        I0110 12:51:28.654251   11116 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
        I0110 12:51:28.654832   11116 ssh_runner.go:175] Transferring 1679 bytes to /etc/docker/server-key.pem
        I0110 12:51:28.656007   11116 ssh_runner.go:194] server-key.pem: copied 1679 bytes
        I0110 12:51:28.676990   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetMachineName
        I0110 12:51:28.677607   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:28.677824   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:28.691102   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:28.691457   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.691739   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.692010   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:28.692251   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:28.692493   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:28.692518   11116 main.go:110] libmachine: About to run SSH command:
        df --output=fstype / | tail -n 1
        I0110 12:51:28.864398   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
        
        I0110 12:51:28.864440   11116 main.go:110] libmachine: root file system type: tmpfs
        I0110 12:51:28.864728   11116 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
        I0110 12:51:28.864769   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:28.875970   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:28.876202   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.876413   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:28.876606   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:28.876831   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:28.877079   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:28.877208   11116 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
        ExecReload=/bin/kill -s HUP $MAINPID
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        " | sudo tee /lib/systemd/system/docker.service
        I0110 12:51:29.041853   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
        Description=Docker Application Container Engine
        Documentation=https://docs.docker.com
        After=network.target  minikube-automount.service docker.socket
        Requires= minikube-automount.service docker.socket 
        
        [Service]
        Type=notify
        
        
        
        # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
        # The base configuration already specifies an 'ExecStart=...' command. The first directive
        # here is to clear out that command inherited from the base configuration. Without this,
        # the command from the base configuration and the command specified here are treated as
        # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
        # will catch this invalid input and refuse to start the service with an error like:
        #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
        
        # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
        # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
        ExecStart=
        ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
        ExecReload=/bin/kill -s HUP 
        
        # Having non-zero Limit*s causes performance problems due to accounting overhead
        # in the kernel. We recommend using cgroups to do container-local accounting.
        LimitNOFILE=infinity
        LimitNPROC=infinity
        LimitCORE=infinity
        
        # Uncomment TasksMax if your systemd version supports it.
        # Only systemd 226 and above support this version.
        TasksMax=infinity
        TimeoutStartSec=0
        
        # set delegate yes so that systemd does not reset the cgroups of docker containers
        Delegate=yes
        
        # kill only the docker process, not all processes in the cgroup
        KillMode=process
        
        [Install]
        WantedBy=multi-user.target
        
        I0110 12:51:29.041937   11116 main.go:110] libmachine: setting minikube options for container-runtime
        I0110 12:51:29.044240   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:29.056227   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:29.056539   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.056821   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.057047   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:29.057333   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:29.057581   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:29.057614   11116 main.go:110] libmachine: About to run SSH command:
        sudo mkdir -p /etc/sysconfig && printf %s "
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        " | sudo tee /etc/sysconfig/crio.minikube
        I0110 12:51:29.225640   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
        
        I0110 12:51:29.225674   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:29.236344   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:29.236586   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.236809   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.237002   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:29.237280   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:29.237489   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:29.237518   11116 main.go:110] libmachine: About to run SSH command:
        sudo systemctl daemon-reload
        I0110 12:51:29.680309   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:51:29.680352   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:29.691624   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:29.691879   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.692082   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:29.692292   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:29.692504   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:29.692723   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:29.692751   11116 main.go:110] libmachine: About to run SSH command:
        sudo systemctl -f restart crio
        I0110 12:51:37.211590   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 
        I0110 12:51:37.211637   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:37.246515   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:37.246852   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:37.247291   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:37.247573   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:37.247841   11116 main.go:110] libmachine: Using SSH client type: native
        I0110 12:51:37.248082   11116 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.141 22 <nil> <nil>}
        I0110 12:51:37.248099   11116 main.go:110] libmachine: About to run SSH command:
        date +%s.%N
        I0110 12:51:37.397485   11116 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578660697.184326850
        
        I0110 12:51:37.397512   11116 cluster.go:197] guest clock: 1578660697.184326850
        I0110 12:51:37.397522   11116 cluster.go:210] Guest: 2020-01-10 12:51:37.18432685 +0000 UTC Remote: 2020-01-10 12:51:37.211621528 +0000 UTC m=+72.012052239 (delta=-27.294678ms)
        I0110 12:51:37.397548   11116 cluster.go:181] guest clock delta is within tolerance: -27.294678ms
        I0110 12:51:37.397568   11116 cluster.go:146] configureHost completed within 9.838686839s
        I0110 12:51:37.397588   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:37.397941   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:37.398155   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:37.407965   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:37.408237   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:37.408502   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:37.449293   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetIP
        I0110 12:51:37.458881   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:37.459126   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:37.459961   11116 ssh_runner.go:102] Run: nslookup kubernetes.io
        I0110 12:51:37.509965   11116 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
        I0110 12:51:37.557424   11116 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/vupgrade-20200110T124615.195477825-4968/config.json ...
        I0110 12:51:37.589298   11116 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
        I0110 12:51:37.612618   11116 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:51:37.623304   11116 ssh_runner.go:102] Run: sudo systemctl stop crio
        I0110 12:51:37.752739   11116 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
        I0110 12:51:37.775350   11116 ssh_runner.go:102] Run: sudo systemctl start docker
        I0110 12:51:41.355231   11116 ssh_runner.go:142] Completed: sudo systemctl start docker: (3.579836253s)
        I0110 12:51:41.355338   11116 ssh_runner.go:102] Run: docker version --format '{{.Server.Version}}'
        I0110 12:51:41.630833   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetURL
        I0110 12:51:41.635595   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) DBG | Using libvirt version 3000000
        I0110 12:51:41.643317   11116 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:51:41.643483   11116 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
        I0110 12:51:41.648206   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:51:41.648797   11116 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
        I0110 12:51:41.648843   11116 main.go:110] libmachine: Launching plugin server for driver kvm2
        I0110 12:51:41.663630   11116 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:33317
        I0110 12:51:41.664574   11116 main.go:110] libmachine: () Calling .GetVersion
        I0110 12:51:41.666277   11116 main.go:110] libmachine: Using API Version  1
        I0110 12:51:41.666298   11116 main.go:110] libmachine: () Calling .SetConfigRaw
        I0110 12:51:41.666780   11116 main.go:110] libmachine: () Calling .GetMachineName
        I0110 12:51:41.667050   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:41.667276   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .DriverName
        I0110 12:51:41.667495   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHHostname
        I0110 12:51:41.675987   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHPort
        I0110 12:51:41.676264   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHKeyPath
        I0110 12:51:41.676487   11116 main.go:110] libmachine: (vupgrade-20200110T124615.195477825-4968) Calling .GetSSHUsername
        I0110 12:51:41.727155   11116 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
        I0110 12:51:41.730783   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-controller-manager:v1.17.0
        I0110 12:51:41.730816   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-addon-manager:v9.0.2
        I0110 12:51:41.730830   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/coredns:1.6.5
        I0110 12:51:41.730872   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/metrics-scraper:v1.0.2
        I0110 12:51:41.730887   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' gcr.io/k8s-minikube/storage-provisioner:v1.8.1
        I0110 12:51:41.730783   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-scheduler:v1.17.0
        I0110 12:51:41.730916   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/etcd:3.4.3-0
        I0110 12:51:41.731006   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-proxy:v1.17.0
        I0110 12:51:41.731007   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/pause:3.1
        I0110 12:51:41.731129   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-apiserver:v1.17.0
        I0110 12:51:41.731231   11116 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/dashboard:v2.0.0-beta8
        I0110 12:51:42.162554   11116 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: "k8s.gcr.io/etcd:3.4.3-0" does not exist at hash "sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f" in container runtime
        I0110 12:51:42.162634   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
        I0110 12:51:42.175391   11116 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: "k8s.gcr.io/coredns:1.6.5" does not exist at hash "sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61" in container runtime
        I0110 12:51:42.175426   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
        I0110 12:51:42.238296   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
        I0110 12:51:42.238357   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
        I0110 12:51:42.239788   11116 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
        I0110 12:51:42.239792   11116 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:51:42.312310   11116 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: "k8s.gcr.io/kube-proxy:v1.17.0" does not exist at hash "sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19" in container runtime
        I0110 12:51:42.312347   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
        I0110 12:51:42.411183   11116 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: "k8s.gcr.io/kube-apiserver:v1.17.0" does not exist at hash "sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2" in container runtime
        I0110 12:51:42.411224   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
        I0110 12:51:42.457327   11116 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: "k8s.gcr.io/kube-scheduler:v1.17.0" does not exist at hash "sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28" in container runtime
        I0110 12:51:42.457364   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
        I0110 12:51:42.460534   11116 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: "k8s.gcr.io/kube-controller-manager:v1.17.0" does not exist at hash "sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056" in container runtime
        I0110 12:51:42.460613   11116 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
        I0110 12:51:42.460836   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:51:42.478945   11116 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:51:42.489612   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:51:42.509924   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:51:42.513697   11116 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
        I0110 12:51:42.514810   11116 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:51:42.528798   11116 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:51:42.534243   11116 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:51:42.830981   11116 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
        I0110 12:51:42.864858   11116 docker.go:121] Loading image: /var/lib/minikube/images/coredns_1.6.5
        I0110 12:51:42.864958   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/coredns_1.6.5
        I0110 12:51:44.415611   11116 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
        I0110 12:51:44.543581   11116 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
        I0110 12:51:44.729997   11116 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
        I0110 12:51:44.756914   11116 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
        I0110 12:51:45.065271   11116 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
        I0110 12:51:48.087314   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/coredns_1.6.5: (5.222319963s)
        I0110 12:51:48.087354   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
        I0110 12:51:48.087381   11116 docker.go:121] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:51:48.087447   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0
        I0110 12:51:53.325888   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0: (5.238402486s)
        I0110 12:51:53.325928   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
        I0110 12:51:53.325944   11116 docker.go:121] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:51:53.325996   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0
        I0110 12:51:57.883275   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0: (4.557247848s)
        I0110 12:51:57.883313   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
        I0110 12:51:57.883364   11116 docker.go:121] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:51:57.883437   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0
        I0110 12:52:02.125705   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0: (4.242235391s)
        I0110 12:52:02.125743   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
        I0110 12:52:02.125762   11116 docker.go:121] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:52:02.125823   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0
        I0110 12:52:07.615613   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0: (5.489753735s)
        I0110 12:52:07.615652   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
        I0110 12:52:07.615676   11116 docker.go:121] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:52:07.615740   11116 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/etcd_3.4.3-0
        I0110 12:52:19.096020   11116 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/etcd_3.4.3-0: (11.480245202s)
        I0110 12:52:19.096082   11116 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
        I0110 12:52:19.096107   11116 cache_images.go:93] Successfully loaded all cached images
        I0110 12:52:19.096117   11116 cache_images.go:94] LoadImages end
        I0110 12:52:19.096363   11116 kubeadm.go:390] kubelet [Unit]
        Wants=docker.socket
        
        [Service]
        ExecStart=
        ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=docker --fail-swap-on=false --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --node-ip=192.168.39.141 --pod-manifest-path=/etc/kubernetes/manifests
        
        [Install]
         config:
        {KubernetesVersion:v1.17.0 NodeIP:192.168.39.141 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin: FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:false}
        I0110 12:52:19.096405   11116 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
        W0110 12:52:19.114074   11116 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
        stdout:
        
        stderr:
         command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
        I0110 12:52:19.132564   11116 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
        I0110 12:52:19.132575   11116 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
        I0110 12:52:19.141310   11116 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
        I0110 12:52:19.141852   11116 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
        I0110 12:52:19.143221   11116 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
        I0110 12:52:19.144280   11116 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
        I0110 12:52:19.566758   11116 ssh_runner.go:194] kubeadm: copied 39342080 bytes
        I0110 12:52:20.074614   11116 ssh_runner.go:194] kubelet: copied 111560216 bytes
        I0110 12:52:20.093950   11116 ssh_runner.go:175] Transferring 1152 bytes to /var/tmp/minikube/kubeadm.yaml
        I0110 12:52:20.095146   11116 ssh_runner.go:194] kubeadm.yaml: copied 1152 bytes
        I0110 12:52:20.112822   11116 ssh_runner.go:175] Transferring 561 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
        I0110 12:52:20.114069   11116 ssh_runner.go:194] 10-kubeadm.conf: copied 561 bytes
        I0110 12:52:20.132137   11116 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
        I0110 12:52:20.133289   11116 ssh_runner.go:194] kubelet.service: copied 349 bytes
        I0110 12:52:20.161076   11116 ssh_runner.go:156] Checked if /etc/sync.test exists, but got error: Process exited with status 1
        I0110 12:52:20.161738   11116 ssh_runner.go:175] Transferring 40 bytes to /etc/sync.test
        I0110 12:52:20.162836   11116 ssh_runner.go:194] sync.test: copied 40 bytes
        I0110 12:52:20.184443   11116 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
        I0110 12:52:20.185371   11116 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
        I0110 12:52:20.204653   11116 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
        I0110 12:52:20.205772   11116 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
        I0110 12:52:20.227766   11116 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
        I0110 12:52:20.228829   11116 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
        I0110 12:52:20.247032   11116 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
        I0110 12:52:20.248007   11116 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
        I0110 12:52:20.264637   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
        I0110 12:52:20.425181   11116 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.141
        I0110 12:52:20.425258   11116 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.425535   11116 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
        I0110 12:52:20.431077   11116 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
        I0110 12:52:20.431107   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.431416   11116 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
        I0110 12:52:20.431450   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.431650   11116 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.141 10.96.0.1 127.0.0.1 10.0.0.1]
        I0110 12:52:20.436675   11116 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
        I0110 12:52:20.436710   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.436919   11116 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
        I0110 12:52:20.436948   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.437152   11116 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
        I0110 12:52:20.442511   11116 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
        I0110 12:52:20.442537   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.442743   11116 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
        I0110 12:52:20.442768   11116 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
        I0110 12:52:20.458170   11116 ssh_runner.go:159] Skipping copying /var/lib/minikube/certs/ca.crt as it already exists
        I0110 12:52:20.467776   11116 ssh_runner.go:159] Skipping copying /var/lib/minikube/certs/ca.key as it already exists
        I0110 12:52:20.475426   11116 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: source file and destination file are different sizes
        I0110 12:52:20.476105   11116 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
        I0110 12:52:20.478253   11116 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
        I0110 12:52:20.512414   11116 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
        I0110 12:52:20.513309   11116 ssh_runner.go:194] apiserver.key: copied 1679 bytes
        I0110 12:52:20.545773   11116 ssh_runner.go:159] Skipping copying /var/lib/minikube/certs/proxy-client-ca.crt as it already exists
        I0110 12:52:20.552851   11116 ssh_runner.go:159] Skipping copying /var/lib/minikube/certs/proxy-client-ca.key as it already exists
        I0110 12:52:20.562541   11116 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
        I0110 12:52:20.563248   11116 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
        I0110 12:52:20.600369   11116 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
        I0110 12:52:20.601531   11116 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
        I0110 12:52:20.635548   11116 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
        I0110 12:52:20.636102   11116 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:52:20.637004   11116 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
        I0110 12:52:20.660197   11116 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
        I0110 12:52:20.661160   11116 ssh_runner.go:194] kubeconfig: copied 428 bytes
        I0110 12:52:20.683918   11116 ssh_runner.go:102] Run: openssl version
        I0110 12:52:20.694123   11116 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
        I0110 12:52:20.704979   11116 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
        I0110 12:52:20.717405   11116 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
        I0110 12:52:20.736190   11116 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
        I0110 12:52:20.745352   11116 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
        I0110 12:52:20.763567   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
        I0110 12:52:21.046234   11116 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
        I0110 12:52:21.057640   11116 kubeadm.go:254] restartCluster start
        I0110 12:52:21.057703   11116 ssh_runner.go:102] Run: sudo test -d /data/minikube
        I0110 12:52:21.100922   11116 kubeadm.go:129] /data/minikube skipping compat symlinks: sudo test -d /data/minikube: Process exited with status 1
        stdout:
        
        stderr:
        I0110 12:52:21.100961   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml"
        I0110 12:52:21.204159   11116 kubeadm.go:258] restartCluster took 146.495085ms
        I0110 12:52:21.204238   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-apiserver --format="{{.ID}}"
        I0110 12:52:21.290686   11116 logs.go:178] 1 containers: ["5f632fe525d7"]
        I0110 12:52:21.290782   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_coredns --format="{{.ID}}"
        I0110 12:52:21.339662   11116 logs.go:178] 0 containers: []
        W0110 12:52:21.339699   11116 logs.go:180] No container was found matching "coredns"
        I0110 12:52:21.339778   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-scheduler --format="{{.ID}}"
        I0110 12:52:21.391431   11116 logs.go:178] 1 containers: ["fca23ce23076"]
        I0110 12:52:21.391528   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-proxy --format="{{.ID}}"
        I0110 12:52:21.439985   11116 logs.go:178] 0 containers: []
        W0110 12:52:21.440015   11116 logs.go:180] No container was found matching "kube-proxy"
        I0110 12:52:21.440089   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-addon-manager --format="{{.ID}}"
        I0110 12:52:21.487585   11116 logs.go:178] 1 containers: ["909f7886fff2"]
        I0110 12:52:21.487691   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format="{{.ID}}"
        I0110 12:52:21.536985   11116 logs.go:178] 0 containers: []
        W0110 12:52:21.537022   11116 logs.go:180] No container was found matching "kubernetes-dashboard"
        I0110 12:52:21.537093   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_storage-provisioner --format="{{.ID}}"
        I0110 12:52:21.601021   11116 logs.go:178] 0 containers: []
        W0110 12:52:21.601061   11116 logs.go:180] No container was found matching "storage-provisioner"
        I0110 12:52:21.601142   11116 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format="{{.ID}}"
        I0110 12:52:21.727894   11116 logs.go:178] 1 containers: ["4500f90accaa"]
        I0110 12:52:21.727946   11116 logs.go:92] Gathering logs for kube-controller-manager ["4500f90accaa"] ...
        I0110 12:52:21.727964   11116 ssh_runner.go:102] Run: /bin/bash -c "docker logs --tail 400 "4500f90accaa""
        I0110 12:52:21.963953   11116 logs.go:92] Gathering logs for Docker ...
        I0110 12:52:21.963988   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
        I0110 12:52:21.985449   11116 logs.go:92] Gathering logs for container status ...
        I0110 12:52:21.985482   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
        I0110 12:52:24.150495   11116 ssh_runner.go:142] Completed: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a": (2.164985935s)
        I0110 12:52:24.152258   11116 logs.go:92] Gathering logs for kubelet ...
        I0110 12:52:24.152296   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
        I0110 12:52:24.180669   11116 logs.go:92] Gathering logs for dmesg ...
        I0110 12:52:24.180718   11116 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
        I0110 12:52:24.195692   11116 logs.go:92] Gathering logs for kube-apiserver ["5f632fe525d7"] ...
        I0110 12:52:24.195735   11116 ssh_runner.go:102] Run: /bin/bash -c "docker logs --tail 400 "5f632fe525d7""
        I0110 12:52:24.349566   11116 logs.go:92] Gathering logs for kube-scheduler ["fca23ce23076"] ...
        I0110 12:52:24.349614   11116 ssh_runner.go:102] Run: /bin/bash -c "docker logs --tail 400 "fca23ce23076""
        I0110 12:52:25.357341   11116 ssh_runner.go:142] Completed: /bin/bash -c "docker logs --tail 400 "fca23ce23076"": (1.007699461s)
        I0110 12:52:25.384820   11116 logs.go:92] Gathering logs for kube-addon-manager ["909f7886fff2"] ...
        I0110 12:52:25.384871   11116 ssh_runner.go:102] Run: /bin/bash -c "docker logs --tail 400 "909f7886fff2""
        W0110 12:52:25.503543   11116 exit.go:101] Error starting cluster: running cmd: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:52:21.198689    2655 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        * 
        X Error starting cluster: running cmd: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init phase certs all --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
        stdout:
        
        stderr:
        W0110 12:52:21.198689    2655 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
        To see the stack trace of this error execute with --v=5 or higher
        
        * 
        * minikube is exiting due to an error. If the above message is not useful, open an issue:
          - https://github.com/kubernetes/minikube/issues/new/choose
        
        ** /stderr **
    version_upgrade_test.go:99: [out/minikube-linux-amd64 start -p vupgrade-20200110T124615.195477825-4968 --kubernetes-version=v1.17.0 --alsologtostderr -v=1 --vm-driver=kvm2 ] failed: exit status 70
    version_upgrade_test.go:102: (dbg) Run:  kubectl --context vupgrade-20200110T124615.195477825-4968 version --output=json
    version_upgrade_test.go:102: (dbg) Non-zero exit: kubectl --context vupgrade-20200110T124615.195477825-4968 version --output=json: exit status 1 (122.122148ms)
        -- stdout --
        {
          "clientVersion": {
            "major": "1",
            "minor": "17",
            "gitVersion": "v1.17.0",
            "gitCommit": "70132b0f130acc0bed193d9ba59dd186f0e634cf",
            "gitTreeState": "clean",
            "buildDate": "2019-12-07T21:20:10Z",
            "goVersion": "go1.13.4",
            "compiler": "gc",
            "platform": "linux/amd64"
          }
        }
        
        -- /stdout --
        ** stderr ** 
        The connection to the server 192.168.39.141:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    version_upgrade_test.go:104: error running kubectl: exit status 1
    panic.go:563: *** TestVersionUpgrade FAILED at 2020-01-10 12:52:25.696350954 +0000 UTC m=+1166.341369812
    panic.go:563: >>> TestVersionUpgrade FAILED: start of post-mortem logs >>>
    panic.go:563: (dbg) Run:  kubectl --context vupgrade-20200110T124615.195477825-4968 get po -A --show-labels
    panic.go:563: (dbg) Non-zero exit: kubectl --context vupgrade-20200110T124615.195477825-4968 get po -A --show-labels: exit status 1 (232.573264ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.141:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    panic.go:563: kubectl --context vupgrade-20200110T124615.195477825-4968 get po -A --show-labels: exit status 1
    panic.go:563: (dbg) kubectl --context vupgrade-20200110T124615.195477825-4968 get po -A --show-labels:
    panic.go:563: (dbg) Run:  kubectl --context vupgrade-20200110T124615.195477825-4968 describe node
    panic.go:563: (dbg) Non-zero exit: kubectl --context vupgrade-20200110T124615.195477825-4968 describe node: exit status 1 (102.17809ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.141:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    panic.go:563: kubectl --context vupgrade-20200110T124615.195477825-4968 describe node: exit status 1
    panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p vupgrade-20200110T124615.195477825-4968 logs --problems
    panic.go:563: (dbg) Done: out/minikube-linux-amd64 -p vupgrade-20200110T124615.195477825-4968 logs --problems: (3.435431124s)
    panic.go:563: TestVersionUpgrade logs: * Problems detected in kube-addon-manager ["909f7886fff2"]:
          - error: error executing template "{{with index .secrets 0}}{{.name}}{{end}}": template: output:1:7: executing "output" at <index .secrets 0>: error calling index: index of untyped nil
    panic.go:563: <<< TestVersionUpgrade FAILED: end of post-mortem logs <<<
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p vupgrade-20200110T124615.195477825-4968
    helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p vupgrade-20200110T124615.195477825-4968: (1.329989953s)
--- FAIL: TestFunctional (794.14s)
    --- FAIL: TestFunctional/serial (117.57s)
        --- PASS: TestFunctional/serial/CopySyncFile (0.00s)
        --- FAIL: TestFunctional/serial/StartWithProxy (103.99s)
            functional_test.go:131: (dbg) Run:  out/minikube-linux-amd64 start -p functional-20200110T124237.619914461-4968 --wait=true --memory 2500MB --vm-driver=kvm2 
            functional_test.go:131: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p functional-20200110T124237.619914461-4968 --wait=true --memory 2500MB --vm-driver=kvm2 : exit status 70 (1m43.985945866s)
                -- stdout --
                * [functional-20200110T124237.619914461-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox none docker])
                * Creating kvm2 VM (CPUs=2, Memory=2500MB, Disk=20000MB) ...
                * Found network options:
                  - HTTP_PROXY=localhost:45093
                * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:44:18.902577    2858 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                ! Not passing HTTP_PROXY=localhost:45093 to docker env.
                ! You appear to be using a proxy, but your NO_PROXY environment does not include the minikube IP (192.168.39.207). Please see https://minikube.sigs.k8s.io/docs/reference/networking/proxy/ for more details
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:44:19.003717    2866 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            functional_test.go:133: [out/minikube-linux-amd64 start -p functional-20200110T124237.619914461-4968 --wait=true --memory 2500MB --vm-driver=kvm2 ] failed: exit status 70
        --- PASS: TestFunctional/serial/KubeContext (0.06s)
            functional_test.go:149: (dbg) Run:  kubectl config current-context
        --- FAIL: TestFunctional/serial/KubectlGetPods (0.65s)
            functional_test.go:160: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 get po -A
            functional_test.go:160: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 get po -A: exit status 1 (653.304009ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            functional_test.go:162: [kubectl --context functional-20200110T124237.619914461-4968 get po -A] failed: exit status 1
            functional_test.go:165: kubectl --context functional-20200110T124237.619914461-4968 get po -A: got unexpected stderr: The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
            functional_test.go:168: kubectl --context functional-20200110T124237.619914461-4968 get po -A = "", want *kube-system*
        --- FAIL: TestFunctional/serial/CacheCmd (12.87s)
            --- FAIL: TestFunctional/serial/CacheCmd/cache (12.87s)
                --- PASS: TestFunctional/serial/CacheCmd/cache/add (4.62s)
                    functional_test.go:320: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add busybox
                    functional_test.go:320: (dbg) Done: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add busybox: (1.435665581s)
                    functional_test.go:320: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add busybox:1.28.4-glibc
                    functional_test.go:320: (dbg) Done: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add busybox:1.28.4-glibc: (2.091446083s)
                    functional_test.go:320: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add k8s.gcr.io/pause:latest
                    functional_test.go:320: (dbg) Done: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache add k8s.gcr.io/pause:latest: (1.093226194s)
                --- PASS: TestFunctional/serial/CacheCmd/cache/delete_busybox:1.28.4-glibc (0.05s)
                    functional_test.go:327: (dbg) Run:  out/minikube-linux-amd64 cache delete busybox:1.28.4-glibc
                --- PASS: TestFunctional/serial/CacheCmd/cache/list (0.05s)
                    functional_test.go:334: (dbg) Run:  out/minikube-linux-amd64 cache list
                --- FAIL: TestFunctional/serial/CacheCmd/cache/verify_cache_inside_node (2.22s)
                    functional_test.go:347: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl images
                    functional_test.go:347: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl images: exit status 1 (2.218120692s)
                        -- stdout --
                        [31mFATA[0m[0002] failed to connect: failed to connect, make sure you are running as root and the runtime has been started: context deadline exceeded 
                        
                        -- /stdout --
                        ** stderr ** 
                        ssh: Process exited with status 1
                        
                        ** /stderr **
                    functional_test.go:349: failed to get images by "out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl images" ssh exit status 1
                    functional_test.go:352: expected '1.28.4-glibc' to be in the output: -- stdout --
                        [31mFATA[0m[0002] failed to connect: failed to connect, make sure you are running as root and the runtime has been started: context deadline exceeded 
                        
                        -- /stdout --
                        ** stderr ** 
                        ssh: Process exited with status 1
                        
                        ** /stderr **
                --- FAIL: TestFunctional/serial/CacheCmd/cache/cache_reload (5.93s)
                    functional_test.go:360: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo docker rmi busybox:latest
                    functional_test.go:365: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl inspecti busybox:latest
                    functional_test.go:365: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl inspecti busybox:latest: exit status 1 (2.201179059s)
                        -- stdout --
                        [31mFATA[0m[0002] failed to connect: failed to connect, make sure you are running as root and the runtime has been started: context deadline exceeded 
                        
                        -- /stdout --
                        ** stderr ** 
                        ssh: Process exited with status 1
                        
                        ** /stderr **
                    functional_test.go:370: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 cache reload
                    functional_test.go:375: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl inspecti busybox:latest
                    functional_test.go:375: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl inspecti busybox:latest: exit status 1 (2.197334653s)
                        -- stdout --
                        [31mFATA[0m[0002] failed to connect: failed to connect, make sure you are running as root and the runtime has been started: context deadline exceeded 
                        
                        -- /stdout --
                        ** stderr ** 
                        ssh: Process exited with status 1
                        
                        ** /stderr **
                    functional_test.go:377: expected to get no error for "out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh sudo crictl inspecti busybox:latest" but got exit status 1
    --- FAIL: TestFunctional/parallel (0.00s)
        --- PASS: TestFunctional/parallel/UpdateContextCmd (0.14s)
            functional_test.go:676: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 update-context --alsologtostderr -v=2
        --- PASS: TestFunctional/parallel/FileSync (0.32s)
            functional_test.go:659: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "cat /etc/sync.test"
        --- FAIL: TestFunctional/parallel/MySQL (0.41s)
            functional_test.go:623: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/mysql.yaml
            functional_test.go:623: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/mysql.yaml: exit status 1 (412.931155ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            functional_test.go:625: [kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/mysql.yaml] failed: exit status 1
        --- PASS: TestFunctional/parallel/SSHCmd (0.22s)
            functional_test.go:612: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "echo hello"
        --- FAIL: TestFunctional/parallel/TunnelCmd (0.63s)
            fn_tunnel_cmd.go:63: (dbg) daemon: [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 tunnel --alsologtostderr -v=1]
            fn_tunnel_cmd.go:70: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 apply -f testdata/testsvc.yaml
            fn_tunnel_cmd.go:70: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 apply -f testdata/testsvc.yaml: exit status 1 (142.791769ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            fn_tunnel_cmd.go:72: [kubectl --context functional-20200110T124237.619914461-4968 apply -f testdata/testsvc.yaml] failed: exit status 1
            panic.go:563: (dbg) stopping [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 tunnel --alsologtostderr -v=1] ...
            panic.go:563: (dbg) [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 tunnel --alsologtostderr -v=1] stdout:
            panic.go:563: (dbg) [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 tunnel --alsologtostderr -v=1] stderr:
                I0110 12:47:40.444334    9902 tunnel.go:56] Creating docker machine client...
                I0110 12:47:40.444370    9902 tunnel.go:61] Creating k8s client...
                I0110 12:47:40.488059    9902 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:47:40.488912    9902 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:47:40.508063    9902 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:35341
                I0110 12:47:40.508709    9902 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:47:40.509561    9902 main.go:110] libmachine: Using API Version  1
                I0110 12:47:40.509594    9902 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:47:40.510246    9902 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:47:40.510532    9902 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetState
                I0110 12:47:40.516043    9902 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetIP
                I0110 12:47:40.523857    9902 main.go:110] libmachine: Making call to close driver server
                I0110 12:47:40.523882    9902 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .Close
                I0110 12:47:40.524105    9902 main.go:110] libmachine: Successfully made call to close driver server
                I0110 12:47:40.524131    9902 main.go:110] libmachine: Making call to close connection to plugin binary
                I0110 12:47:40.524172    9902 tunnel_manager.go:71] Setting up tunnel...
                I0110 12:47:40.524194    9902 tunnel_manager.go:81] Started minikube tunnel.
        --- PASS: TestFunctional/parallel/AddonsCmd (1.26s)
            functional_test.go:553: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 addons list
            functional_test.go:567: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 addons list --format "{{.AddonName}}":"{{.AddonStatus}}"
            functional_test.go:581: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 addons list -f "{{.AddonName}}":"{{.AddonStatus}}"
            functional_test.go:595: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 addons list -o json
        --- FAIL: TestFunctional/parallel/StatusCmd (2.55s)
            functional_test.go:207: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status
            functional_test.go:207: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status: exit status 2 (541.694336ms)
                -- stdout --
                host: Running
                kubelet: Running
                apiserver: Stopped
                kubeconfig: Configured
                
                -- /stdout --
            functional_test.go:209: [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status] failed: exit status 2
            functional_test.go:213: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -f host:{{.Host}},kublet:{{.Kubelet}},apiserver:{{.APIServer}},kubeconfig:{{.Kubeconfig}}
            functional_test.go:213: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -f host:{{.Host}},kublet:{{.Kubelet}},apiserver:{{.APIServer}},kubeconfig:{{.Kubeconfig}}: exit status 2 (1.411210261s)
                -- stdout --
                host:Running,kublet:,apiserver:Stopped,kubeconfig:Configured
                -- /stdout --
            functional_test.go:215: [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -f host:{{.Host}},kublet:{{.Kubelet}},apiserver:{{.APIServer}},kubeconfig:{{.Kubeconfig}}] failed: exit status 2
            functional_test.go:219: [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -f host:{{.Host}},kublet:{{.Kubelet}},apiserver:{{.APIServer}},kubeconfig:{{.Kubeconfig}}] failed: exit status 2. Output for custom format did not match
            functional_test.go:223: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -o json
            functional_test.go:223: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -o json: exit status 2 (595.530617ms)
                -- stdout --
                {"Host":"Running","Kubelet":"","APIServer":"Stopped","Kubeconfig":"Configured"}
                -- /stdout --
            functional_test.go:225: [out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 status -o json] failed: exit status 2
        --- PASS: TestFunctional/parallel/ProfileCmd (0.52s)
            functional_test.go:432: (dbg) Run:  out/minikube-linux-amd64 profile list
            functional_test.go:452: (dbg) Run:  out/minikube-linux-amd64 profile list --output json
        --- FAIL: TestFunctional/parallel/MountCmd (3.82s)
            fn_mount_cmd.go:62: (dbg) daemon: [out/minikube-linux-amd64 mount -p functional-20200110T124237.619914461-4968 /tmp/mounttest710636285:/mount-9p --alsologtostderr -v=1]
            fn_mount_cmd.go:96: wrote "test-1578660640364034663" to /tmp/mounttest710636285/created-by-test
            fn_mount_cmd.go:96: wrote "test-1578660640364034663" to /tmp/mounttest710636285/created-by-test-removed-by-pod
            fn_mount_cmd.go:96: wrote "test-1578660640364034663" to /tmp/mounttest710636285/test-1578660640364034663
            fn_mount_cmd.go:104: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "findmnt -T /mount-9p | grep 9p"
            fn_mount_cmd.go:104: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "findmnt -T /mount-9p | grep 9p": exit status 1 (266.15693ms)
                
                ** stderr ** 
                ssh: Process exited with status 1
                
                ** /stderr **
            fn_mount_cmd.go:104: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "findmnt -T /mount-9p | grep 9p"
            fn_mount_cmd.go:118: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh -- ls -la /mount-9p
            fn_mount_cmd.go:122: guest mount directory contents
                total 2
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 created-by-test
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 created-by-test-removed-by-pod
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 test-1578660640364034663
            fn_mount_cmd.go:126: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh cat /mount-9p/test-1578660640364034663
            fn_mount_cmd.go:137: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox-mount-test.yaml
            fn_mount_cmd.go:137: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox-mount-test.yaml: exit status 1 (118.134463ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            fn_mount_cmd.go:139: [kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox-mount-test.yaml] failed: exit status 1
            fn_mount_cmd.go:69: TestFunctional/parallel/MountCmd failed, getting debug info...
            fn_mount_cmd.go:70: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "mount | grep 9p; ls -la /mount-9p; cat /mount-9p/pod-dates"
            fn_mount_cmd.go:70: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "mount | grep 9p; ls -la /mount-9p; cat /mount-9p/pod-dates": exit status 1 (407.644983ms)
                -- stdout --
                192.168.39.1 on /mount-9p type 9p (rw,relatime,sync,dirsync,dfltuid=1000,dfltgid=1000,access=any,msize=65536,trans=tcp,noextend,port=46435)
                192.168.39.1 on /mount-9p type 9p (rw,relatime,sync,dirsync,dfltuid=1000,dfltgid=1000,access=any,msize=65536,trans=tcp,noextend,port=46435)
                total 2
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 created-by-test
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 created-by-test-removed-by-pod
                -rw-r--r-- 1 docker docker 24 Jan 10 12:50 test-1578660640364034663
                cat: /mount-9p/pod-dates: No such file or directory
                
                -- /stdout --
                ** stderr ** 
                ssh: Process exited with status 1
                
                ** /stderr **
            fn_mount_cmd.go:72: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "mount | grep 9p; ls -la /mount-9p; cat /mount-9p/pod-dates": exit status 1
            fn_mount_cmd.go:79: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 ssh "sudo umount -f /mount-9p"
            fn_mount_cmd.go:83: (dbg) stopping [out/minikube-linux-amd64 mount -p functional-20200110T124237.619914461-4968 /tmp/mounttest710636285:/mount-9p --alsologtostderr -v=1] ...
            fn_mount_cmd.go:83: (dbg) [out/minikube-linux-amd64 mount -p functional-20200110T124237.619914461-4968 /tmp/mounttest710636285:/mount-9p --alsologtostderr -v=1] stdout:
                * Mounting host path /tmp/mounttest710636285 into VM as /mount-9p ...
                  - Mount type:   <no value>
                  - User ID:      docker
                  - Group ID:     docker
                  - Version:      9p2000.L
                  - Message Size: 262144
                  - Permissions:  755 (-rwxr-xr-x)
                  - Options:      map[]
                * Userspace file server: ufs starting
                * Successfully mounted /tmp/mounttest710636285 to /mount-9p
                
                * NOTE: This process must stay alive for the mount to be accessible ...
                * Unmounting /mount-9p ...
            fn_mount_cmd.go:83: (dbg) [out/minikube-linux-amd64 mount -p functional-20200110T124237.619914461-4968 /tmp/mounttest710636285:/mount-9p --alsologtostderr -v=1] stderr:
                I0110 12:50:40.479775   11876 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:40.479889   11876 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:40.499527   11876 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:38319
                I0110 12:50:40.501006   11876 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:40.501948   11876 main.go:110] libmachine: Using API Version  1
                I0110 12:50:40.501979   11876 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:40.509856   11876 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:40.510244   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .DriverName
                I0110 12:50:40.511385   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .DriverName
                I0110 12:50:40.511829   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .DriverName
                I0110 12:50:40.512074   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHHostname
                I0110 12:50:40.523047   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHPort
                I0110 12:50:40.523333   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHKeyPath
                I0110 12:50:40.523568   11876 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHUsername
                I0110 12:50:40.596272   11876 ssh_runner.go:102] Run: /bin/bash -c "[ "x$(findmnt -T /mount-9p | grep /mount-9p)" != "x" ] && sudo umount -f /mount-9p || echo "
                I0110 12:50:40.655146   11876 mount.go:145] unmount for /mount-9p ran successfully
                I0110 12:50:40.655229   11876 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -m 755 -p /mount-9p && sudo mount -t 9p -o dfltgid=$(grep ^docker: /etc/group | cut -d: -f3),dfltuid=$(id -u docker),msize=262144,port=46435,version=9p2000.L 192.168.39.1 /mount-9p"
                I0110 12:50:40.753183   11876 main.go:96] stdlog: ufs.go:141 connected
                I0110 12:50:40.763646   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tversion tag 65535 msize 65536 version '9P2000.L'
                I0110 12:50:40.763789   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rversion tag 65535 msize 65536 version '9P2000'
                I0110 12:50:40.767559   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tattach tag 0 fid 0 afid 4294967295 uname 'nobody' nuname 0 aname ''
                I0110 12:50:40.767671   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rattach tag 0 aqid (223e8 8f81b668 'd')
                I0110 12:50:40.773190   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tstat tag 0 fid 0
                I0110 12:50:40.773517   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:40.779494   11876 ssh_runner.go:102] Run: /bin/bash -c "sudo mount -t 9p -o dfltgid=$(grep ^docker: /etc/group | cut -d: -f3),dfltuid=$(id -u docker),msize=262144,port=46435,version=9p2000.L 192.168.39.1 /mount-9p"
                I0110 12:50:40.825491   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tstat tag 0 fid 0
                I0110 12:50:40.825786   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:40.827740   11876 main.go:96] stdlog: ufs.go:141 connected
                I0110 12:50:40.835231   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tversion tag 65535 msize 65536 version '9P2000.L'
                I0110 12:50:40.835325   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rversion tag 65535 msize 65536 version '9P2000'
                I0110 12:50:40.836094   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tattach tag 0 fid 0 afid 4294967295 uname 'nobody' nuname 0 aname ''
                I0110 12:50:40.836189   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rattach tag 0 aqid (223e8 8f81b668 'd')
                I0110 12:50:40.837486   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:40.837716   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:40.840293   11876 mount.go:72] mount successful: ""
                I0110 12:50:42.099023   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:42.099308   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:42.436936   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:42.437185   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:42.441002   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 1 
                I0110 12:50:42.441068   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 
                I0110 12:50:42.442348   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Topen tag 0 fid 1 mode 0
                I0110 12:50:42.442565   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Ropen tag 0 qid (223e8 8f81b668 'd') iounit 0
                I0110 12:50:42.443580   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:42.443762   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:42.444595   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 0 count 65512
                I0110 12:50:42.445002   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 258
                I0110 12:50:42.453364   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65254
                I0110 12:50:42.453439   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:42.454322   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65512
                I0110 12:50:42.454371   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:42.455338   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'created-by-test-removed-by-pod' 
                I0110 12:50:42.455406   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223ea 8f81b668 '') 
                I0110 12:50:42.456084   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.456765   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test-removed-by-pod' 'jenkins' 'balintp' '' q (223ea 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.457899   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.458063   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test-removed-by-pod' 'jenkins' 'balintp' '' q (223ea 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.458927   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:42.458984   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:42.459906   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'test-1578660640364034663' 
                I0110 12:50:42.459993   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223eb 8f81b668 '') 
                I0110 12:50:42.460569   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.460759   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.461901   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.462110   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.462805   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:42.462858   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:42.464341   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'created-by-test' 
                I0110 12:50:42.464424   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223e9 8f81b668 '') 
                I0110 12:50:42.465070   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.465251   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test' 'jenkins' 'balintp' '' q (223e9 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.465832   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:42.465978   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test' 'jenkins' 'balintp' '' q (223e9 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.466571   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:42.466619   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:42.467357   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65512
                I0110 12:50:42.467489   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:42.468349   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 1
                I0110 12:50:42.468423   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:42.765451   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 1 0:'test-1578660640364034663' 
                I0110 12:50:42.765612   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223eb 8f81b668 '') 
                I0110 12:50:42.766419   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 1
                I0110 12:50:42.766658   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.767506   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 1 newfid 2 
                I0110 12:50:42.767588   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 
                I0110 12:50:42.767987   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Topen tag 0 fid 2 mode 0
                I0110 12:50:42.768052   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Ropen tag 0 qid (223eb 8f81b668 '') iounit 0
                I0110 12:50:42.768466   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 1
                I0110 12:50:42.768677   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:42.769308   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 2 offset 0 count 65512
                I0110 12:50:42.769386   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 24
                I0110 12:50:42.769861   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 2 offset 24 count 65512
                I0110 12:50:42.769909   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:42.770666   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 2 offset 24 count 65512
                I0110 12:50:42.770717   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:42.771189   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:42.771244   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:42.771590   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 1
                I0110 12:50:42.771636   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.281107   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:43.281366   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:43.283006   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 1 
                I0110 12:50:43.283069   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 
                I0110 12:50:43.285606   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Topen tag 0 fid 1 mode 0
                I0110 12:50:43.285699   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Ropen tag 0 qid (223e8 8f81b668 'd') iounit 0
                I0110 12:50:43.286360   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 0
                I0110 12:50:43.286516   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:43.286836   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 0 count 65512
                I0110 12:50:43.287196   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 258
                I0110 12:50:43.287933   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65254
                I0110 12:50:43.287985   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:43.288527   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65512
                I0110 12:50:43.288575   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:43.291038   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'created-by-test-removed-by-pod' 
                I0110 12:50:43.291101   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223ea 8f81b668 '') 
                I0110 12:50:43.291676   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.291827   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test-removed-by-pod' 'jenkins' 'balintp' '' q (223ea 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.295434   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.295576   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test-removed-by-pod' 'jenkins' 'balintp' '' q (223ea 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.296001   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:43.296069   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.296473   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'test-1578660640364034663' 
                I0110 12:50:43.296533   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223eb 8f81b668 '') 
                I0110 12:50:43.297013   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.297185   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.298043   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.298206   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('test-1578660640364034663' 'jenkins' 'balintp' '' q (223eb 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.299076   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:43.299116   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.299520   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 2 0:'created-by-test' 
                I0110 12:50:43.299596   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rwalk tag 0 (223e9 8f81b668 '') 
                I0110 12:50:43.299856   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.300008   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test' 'jenkins' 'balintp' '' q (223e9 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.300364   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tstat tag 0 fid 2
                I0110 12:50:43.300492   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rstat tag 0 st ('created-by-test' 'jenkins' 'balintp' '' q (223e9 8f81b668 '') m 644 at 0 mt 1578660640 l 24 t 0 d 0 ext )
                I0110 12:50:43.301068   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 2
                I0110 12:50:43.301106   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.305376   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tread tag 0 fid 1 offset 258 count 65512
                I0110 12:50:43.305444   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rread tag 0 count 0
                I0110 12:50:43.306678   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 1
                I0110 12:50:43.306736   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.312826   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Twalk tag 0 fid 0 newfid 1 0:'pod-dates' 
                I0110 12:50:43.312937   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rerror tag 0 ename 'file not found' ecode 0
                I0110 12:50:43.719865   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38880 Tclunk tag 0 fid 0
                I0110 12:50:43.719923   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38880 Rclunk tag 0
                I0110 12:50:43.728743   11876 main.go:96] stdlog: ufs.go:147 disconnected
                I0110 12:50:44.060778   11876 ssh_runner.go:102] Run: /bin/bash -c "[ "x$(findmnt -T /mount-9p | grep /mount-9p)" != "x" ] && sudo umount -f /mount-9p || echo "
                I0110 12:50:44.076053   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tstat tag 0 fid 0
                I0110 12:50:44.076318   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rstat tag 0 st ('mounttest710636285' 'jenkins' 'balintp' '' q (223e8 8f81b668 'd') m d700 at 0 mt 1578660640 l 4096 t 0 d 0 ext )
                I0110 12:50:44.106673   11876 main.go:96] stdlog: srv_conn.go:133 >>> 192.168.39.207:38878 Tclunk tag 0 fid 0
                I0110 12:50:44.106765   11876 main.go:96] stdlog: srv_conn.go:190 <<< 192.168.39.207:38878 Rclunk tag 0
                I0110 12:50:44.128465   11876 main.go:96] stdlog: ufs.go:147 disconnected
                I0110 12:50:44.130095   11876 mount.go:145] unmount for /mount-9p ran successfully
                X Received terminated signal
        --- FAIL: TestFunctional/parallel/LogsCmd (3.16s)
            functional_test.go:419: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 logs
            functional_test.go:419: (dbg) Done: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 logs: (3.158469289s)
            functional_test.go:425: minikube logs missing expected word: "apiserver"
        --- FAIL: TestFunctional/parallel/PersistentVolumeClaim (240.01s)
            fn_pvc.go:40: (dbg) TestFunctional/parallel/PersistentVolumeClaim: waiting 4m0s for pods matching "integration-test=storage-provisioner" in namespace "kube-system" ...
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/PersistentVolumeClaim: WARNING: pod list for "kube-system" "integration-test=storage-provisioner" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=integration-test%3Dstorage-provisioner: dial tcp 192.168.39.207:8443: connect: connection refused
            fn_pvc.go:40: ***** TestFunctional/parallel/PersistentVolumeClaim: pod "integration-test=storage-provisioner" failed to start within 4m0s: timed out waiting for the condition ****
            helpers.go:313: TestFunctional/parallel/PersistentVolumeClaim: showing logs for failed pods as of 2020-01-10 12:51:40.70528727 +0000 UTC m=+1121.350306083
            fn_pvc.go:41: wait: integration-test=storage-provisioner within 4m0s: timed out waiting for the condition
        --- FAIL: TestFunctional/parallel/DNS (0.07s)
            functional_test.go:286: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox.yaml
            functional_test.go:286: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox.yaml: exit status 1 (68.236014ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            functional_test.go:288: [kubectl --context functional-20200110T124237.619914461-4968 replace --force -f testdata/busybox.yaml] failed: exit status 1
        --- PASS: TestFunctional/parallel/ConfigCmd (0.46s)
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config unset cpus
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config get cpus
            functional_test.go:401: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config get cpus: exit status 64 (69.994105ms)
                
                ** stderr ** 
                Error: specified key could not be found in config
                
                ** /stderr **
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config set cpus 2
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config get cpus
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config unset cpus
            functional_test.go:401: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config get cpus
            functional_test.go:401: (dbg) Non-zero exit: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 config get cpus: exit status 64 (72.437785ms)
                
                ** stderr ** 
                Error: specified key could not be found in config
                
                ** /stderr **
        --- FAIL: TestFunctional/parallel/ComponentHealth (0.13s)
            functional_test.go:182: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 get cs -o=json
            functional_test.go:182: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 get cs -o=json: exit status 1 (129.339902ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            functional_test.go:184: [kubectl --context functional-20200110T124237.619914461-4968 get cs -o=json] failed: exit status 1
        --- FAIL: TestFunctional/parallel/AddonManager (600.01s)
            functional_test.go:175: (dbg) TestFunctional/parallel/AddonManager: waiting 10m0s for pods matching "component=kube-addon-manager" in namespace "kube-system" ...
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/AddonManager: WARNING: pod list for "kube-system" "component=kube-addon-manager" returned: Get https://192.168.39.207:8443/api/v1/namespaces/kube-system/pods?labelSelector=component%3Dkube-addon-manager: dial tcp 192.168.39.207:8443: connect: connection refused
            functional_test.go:175: ***** TestFunctional/parallel/AddonManager: pod "component=kube-addon-manager" failed to start within 10m0s: timed out waiting for the condition ****
            helpers.go:313: TestFunctional/parallel/AddonManager: showing logs for failed pods as of 2020-01-10 12:55:37.523964899 +0000 UTC m=+1358.168983678
            functional_test.go:176: wait: component=kube-addon-manager within 10m0s: timed out waiting for the condition
        --- FAIL: TestFunctional/parallel/ServiceCmd (600.24s)
            functional_test.go:476: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node
            functional_test.go:476: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node: exit status 1 (138.45035ms)
                
                ** stderr ** 
                error: failed to discover supported resources: Get https://192.168.39.207:8443/apis/apps/v1?timeout=32s: dial tcp 192.168.39.207:8443: connect: connection refused
                
                ** /stderr **
            functional_test.go:478: [kubectl --context functional-20200110T124237.619914461-4968 create deployment hello-node --image=gcr.io/hello-minikube-zero-install/hello-node] failed: exit status 1 (may not be an error)
            functional_test.go:480: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 expose deployment hello-node --type=NodePort --port=8080
            functional_test.go:480: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 expose deployment hello-node --type=NodePort --port=8080: exit status 1 (90.861ms)
                
                ** stderr ** 
                error: Get https://192.168.39.207:8443/api?timeout=32s: dial tcp 192.168.39.207:8443: connect: connection refused
                See 'kubectl expose -h' for help and examples
                
                ** /stderr **
            functional_test.go:482: [kubectl --context functional-20200110T124237.619914461-4968 expose deployment hello-node --type=NodePort --port=8080] failed: exit status 1 (may not be an error)
            functional_test.go:485: (dbg) TestFunctional/parallel/ServiceCmd: waiting 10m0s for pods matching "app=hello-node" in namespace "default" ...
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            helpers.go:253: TestFunctional/parallel/ServiceCmd: WARNING: pod list for "default" "app=hello-node" returned: Get https://192.168.39.207:8443/api/v1/namespaces/default/pods?labelSelector=app%3Dhello-node: dial tcp 192.168.39.207:8443: connect: connection refused
            functional_test.go:485: ***** TestFunctional/parallel/ServiceCmd: pod "app=hello-node" failed to start within 10m0s: timed out waiting for the condition ****
            helpers.go:313: TestFunctional/parallel/ServiceCmd: showing logs for failed pods as of 2020-01-10 12:55:43.494597939 +0000 UTC m=+1364.139616754
            functional_test.go:486: wait: app=hello-node within 10m0s: timed out waiting for the condition
        --- FAIL: TestFunctional/parallel/DashboardCmd (300.35s)
            functional_test.go:249: (dbg) daemon: [out/minikube-linux-amd64 dashboard --url -p functional-20200110T124237.619914461-4968 --alsologtostderr -v=1]
            functional_test.go:263: failed to read url within 5m0.000217995s: timeout after 5m0s
                output: ""
            functional_test.go:254: (dbg) stopping [out/minikube-linux-amd64 dashboard --url -p functional-20200110T124237.619914461-4968 --alsologtostderr -v=1] ...
            functional_test.go:254: (dbg) [out/minikube-linux-amd64 dashboard --url -p functional-20200110T124237.619914461-4968 --alsologtostderr -v=1] stdout:
            functional_test.go:254: (dbg) [out/minikube-linux-amd64 dashboard --url -p functional-20200110T124237.619914461-4968 --alsologtostderr -v=1] stderr:
                I0110 12:50:47.392855   12132 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:47.393006   12132 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:47.414055   12132 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:45437
                I0110 12:50:47.414712   12132 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:47.415572   12132 main.go:110] libmachine: Using API Version  1
                I0110 12:50:47.415597   12132 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:47.416095   12132 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:47.416874   12132 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:47.416932   12132 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:47.433822   12132 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:36417
                I0110 12:50:47.434435   12132 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:47.435241   12132 main.go:110] libmachine: Using API Version  1
                I0110 12:50:47.435296   12132 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:47.435926   12132 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:47.436167   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetState
                * Enabling dashboard ...
                I0110 12:50:47.443417   12132 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:47.443515   12132 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:47.460060   12132 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:44895
                I0110 12:50:47.460789   12132 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:47.461726   12132 main.go:110] libmachine: Using API Version  1
                I0110 12:50:47.461761   12132 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:47.462482   12132 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:47.462829   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetState
                I0110 12:50:47.468705   12132 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:47.468758   12132 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:47.485364   12132 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:45737
                I0110 12:50:47.485937   12132 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:47.486805   12132 main.go:110] libmachine: Using API Version  1
                I0110 12:50:47.486847   12132 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:47.487441   12132 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:47.487713   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .DriverName
                I0110 12:50:47.487972   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .DriverName
                I0110 12:50:47.488215   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHHostname
                I0110 12:50:47.500672   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHPort
                I0110 12:50:47.500963   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHKeyPath
                I0110 12:50:47.501260   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .GetSSHUsername
                I0110 12:50:47.621395   12132 ssh_runner.go:175] Transferring 1001 bytes to /etc/kubernetes/addons/dashboard-clusterrole.yaml
                I0110 12:50:47.627228   12132 ssh_runner.go:194] dashboard-clusterrole.yaml: copied 1001 bytes
                I0110 12:50:47.652057   12132 ssh_runner.go:175] Transferring 1018 bytes to /etc/kubernetes/addons/dashboard-clusterrolebinding.yaml
                I0110 12:50:47.652851   12132 ssh_runner.go:194] dashboard-clusterrolebinding.yaml: copied 1018 bytes
                I0110 12:50:47.677877   12132 ssh_runner.go:175] Transferring 837 bytes to /etc/kubernetes/addons/dashboard-configmap.yaml
                I0110 12:50:47.679111   12132 ssh_runner.go:194] dashboard-configmap.yaml: copied 837 bytes
                I0110 12:50:47.712766   12132 ssh_runner.go:175] Transferring 4107 bytes to /etc/kubernetes/addons/dashboard-dp.yaml
                I0110 12:50:47.714621   12132 ssh_runner.go:194] dashboard-dp.yaml: copied 4107 bytes
                I0110 12:50:47.743325   12132 ssh_runner.go:175] Transferring 759 bytes to /etc/kubernetes/addons/dashboard-ns.yaml
                I0110 12:50:47.744921   12132 ssh_runner.go:194] dashboard-ns.yaml: copied 759 bytes
                I0110 12:50:47.789639   12132 ssh_runner.go:175] Transferring 1724 bytes to /etc/kubernetes/addons/dashboard-role.yaml
                I0110 12:50:47.791041   12132 ssh_runner.go:194] dashboard-role.yaml: copied 1724 bytes
                I0110 12:50:47.826391   12132 ssh_runner.go:175] Transferring 1046 bytes to /etc/kubernetes/addons/dashboard-rolebinding.yaml
                I0110 12:50:47.827698   12132 ssh_runner.go:194] dashboard-rolebinding.yaml: copied 1046 bytes
                I0110 12:50:47.851572   12132 ssh_runner.go:175] Transferring 837 bytes to /etc/kubernetes/addons/dashboard-sa.yaml
                I0110 12:50:47.852858   12132 ssh_runner.go:194] dashboard-sa.yaml: copied 837 bytes
                I0110 12:50:47.877888   12132 ssh_runner.go:175] Transferring 1401 bytes to /etc/kubernetes/addons/dashboard-secret.yaml
                I0110 12:50:47.879136   12132 ssh_runner.go:194] dashboard-secret.yaml: copied 1401 bytes
                I0110 12:50:47.903878   12132 ssh_runner.go:175] Transferring 1294 bytes to /etc/kubernetes/addons/dashboard-svc.yaml
                I0110 12:50:47.905192   12132 ssh_runner.go:194] dashboard-svc.yaml: copied 1294 bytes
                I0110 12:50:47.928060   12132 main.go:110] libmachine: Making call to close driver server
                I0110 12:50:47.928115   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .Close
                I0110 12:50:47.928467   12132 main.go:110] libmachine: Successfully made call to close driver server
                I0110 12:50:47.928495   12132 main.go:110] libmachine: Making call to close connection to plugin binary
                I0110 12:50:47.928523   12132 main.go:110] libmachine: Making call to close driver server
                I0110 12:50:47.928538   12132 main.go:110] libmachine: (functional-20200110T124237.619914461-4968) Calling .Close
                I0110 12:50:47.928828   12132 main.go:110] libmachine: Successfully made call to close driver server
                I0110 12:50:47.928884   12132 main.go:110] libmachine: Making call to close connection to plugin binary
                * Verifying dashboard health ...
                I0110 12:55:47.448472   12132 main.go:110] libmachine: Wrapper Docker Machine process exiting due to closed plugin server (connection is shut down)
                I0110 12:55:47.468111   12132 main.go:110] libmachine: Wrapper Docker Machine process exiting due to closed plugin server (read tcp 127.0.0.1:40060->127.0.0.1:36417: read: connection reset by peer)
    functional_test.go:116: *** TestFunctional FAILED at 2020-01-10 12:55:47.669575843 +0000 UTC m=+1368.314594655
    functional_test.go:116: >>> TestFunctional FAILED: start of post-mortem logs >>>
    functional_test.go:116: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 get po -A --show-labels
    functional_test.go:116: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 get po -A --show-labels: exit status 1 (63.386555ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    functional_test.go:116: kubectl --context functional-20200110T124237.619914461-4968 get po -A --show-labels: exit status 1
    functional_test.go:116: (dbg) kubectl --context functional-20200110T124237.619914461-4968 get po -A --show-labels:
    functional_test.go:116: (dbg) Run:  kubectl --context functional-20200110T124237.619914461-4968 describe node
    functional_test.go:116: (dbg) Non-zero exit: kubectl --context functional-20200110T124237.619914461-4968 describe node: exit status 1 (70.38848ms)
        
        ** stderr ** 
        The connection to the server 192.168.39.207:8443 was refused - did you specify the right host or port?
        
        ** /stderr **
    functional_test.go:116: kubectl --context functional-20200110T124237.619914461-4968 describe node: exit status 1
    functional_test.go:116: (dbg) Run:  out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 logs --problems
    functional_test.go:116: (dbg) Done: out/minikube-linux-amd64 -p functional-20200110T124237.619914461-4968 logs --problems: (2.884240503s)
    functional_test.go:116: TestFunctional logs: 
    functional_test.go:116: <<< TestFunctional FAILED: end of post-mortem logs <<<
    helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p functional-20200110T124237.619914461-4968
    helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p functional-20200110T124237.619914461-4968: (1.075749457s)
--- FAIL: TestStartStop (820.99s)
    --- FAIL: TestStartStop/group (0.00s)
        --- FAIL: TestStartStop/group/containerd (360.81s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:47:55.195248657 +0000 UTC m=+895.840267405 (sleeping 3m19.99940308s)  ...
            start_stop_delete_test.go:94: (dbg) Run:  out/minikube-linux-amd64 start -p containerd-20200110T124755.19551629-4968 --alsologtostderr -v=3 --wait=true --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --apiserver-port=8444 --vm-driver=kvm2  --kubernetes-version=v1.17.0
            start_stop_delete_test.go:94: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p containerd-20200110T124755.19551629-4968 --alsologtostderr -v=3 --wait=true --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --apiserver-port=8444 --vm-driver=kvm2  --kubernetes-version=v1.17.0: exit status 70 (2m37.674057836s)
                -- stdout --
                * [containerd-20200110T124755.19551629-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
                * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
                * Preparing Kubernetes v1.17.0 on containerd 1.2.10 ...
                  - opt containerd=/var/run/containerd/containerd.sock
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:50:31.885145    2602 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                I0110 12:47:55.279449   10017 notify.go:125] Checking for updates...
                I0110 12:47:58.407438   10017 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1827,"bootTime":1578658651,"procs":219,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
                I0110 12:47:58.408635   10017 start.go:266] virtualization: kvm host
                I0110 12:47:58.409055   10017 start.go:567] selectDriver: flag="kvm2", old=<nil>
                I0110 12:47:58.409096   10017 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:47:59.880700   10017 global.go:68] docker priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:02.147028   10017 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:02.147132   10017 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:03.129384   10017 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:03.129545   10017 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
                I0110 12:48:03.129592   10017 driver.go:128] requested: "kvm2"
                I0110 12:48:03.129605   10017 driver.go:132] choosing "kvm2" because it was requested
                I0110 12:48:03.129628   10017 driver.go:147] not recommending "docker" due to priority: 2
                I0110 12:48:03.129641   10017 driver.go:147] not recommending "none" due to priority: 2
                I0110 12:48:03.129655   10017 driver.go:165] Picked: kvm2
                I0110 12:48:03.129670   10017 driver.go:166] Alternatives: [virtualbox docker none]
                I0110 12:48:03.129798   10017 start.go:298] selected driver: kvm2
                I0110 12:48:03.129807   10017 start.go:597] validating driver "kvm2" against <nil>
                I0110 12:48:03.187347   10017 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:03.187513   10017 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:48:03.207946   10017 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
                I0110 12:48:03.208290   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
                I0110 12:48:03.208312   10017 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "66.803Âµs"
                I0110 12:48:03.208333   10017 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
                I0110 12:48:03.208295   10017 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/containerd-20200110T124755.19551629-4968/config.json ...
                I0110 12:48:03.208373   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
                I0110 12:48:03.208384   10017 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "34.166Âµs"
                I0110 12:48:03.208395   10017 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
                I0110 12:48:03.208417   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
                I0110 12:48:03.208423   10017 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "18.72Âµs"
                I0110 12:48:03.208443   10017 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
                I0110 12:48:03.208467   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
                I0110 12:48:03.208474   10017 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "20.131Âµs"
                I0110 12:48:03.208485   10017 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
                I0110 12:48:03.208466   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/containerd-20200110T124755.19551629-4968/config.json: {Name:mk77ab23437ab36a2a3a62a846ef5eb19726912d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:48:03.208496   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
                I0110 12:48:03.208508   10017 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "23.396Âµs"
                I0110 12:48:03.208516   10017 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
                I0110 12:48:03.208534   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
                I0110 12:48:03.208538   10017 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "12.644Âµs"
                I0110 12:48:03.208543   10017 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
                I0110 12:48:03.208556   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
                I0110 12:48:03.208560   10017 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "10.775Âµs"
                I0110 12:48:03.208565   10017 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
                I0110 12:48:03.208579   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
                I0110 12:48:03.208584   10017 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "13.026Âµs"
                I0110 12:48:03.208593   10017 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
                I0110 12:48:03.208609   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
                I0110 12:48:03.208613   10017 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "12.294Âµs"
                I0110 12:48:03.208619   10017 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
                I0110 12:48:03.208632   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
                I0110 12:48:03.208636   10017 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "10.937Âµs"
                I0110 12:48:03.208642   10017 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
                I0110 12:48:03.208340   10017 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
                I0110 12:48:03.208650   10017 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "341.072Âµs"
                I0110 12:48:03.208655   10017 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
                I0110 12:48:03.208661   10017 cache.go:70] Successfully saved all images to host disk.
                I0110 12:48:03.242119   10017 cluster.go:96] Machine does not exist... provisioning new machine
                I0110 12:48:03.242159   10017 cluster.go:97] Provisioning machine with config: {Name:containerd-20200110T124755.19551629-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:containerd HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[containerd=/var/run/containerd/containerd.sock] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8444 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
                I0110 12:48:03.242598   10017 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:48:03.242694   10017 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:48:03.258947   10017 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:34627
                I0110 12:48:03.259600   10017 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:48:03.260386   10017 main.go:110] libmachine: Using API Version  1
                I0110 12:48:03.260439   10017 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:48:03.260864   10017 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:48:03.261136   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetMachineName
                I0110 12:48:03.261375   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:03.261640   10017 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
                I0110 12:48:03.261697   10017 main.go:110] libmachine: Decoding PEM data...
                I0110 12:48:03.261720   10017 main.go:110] libmachine: Parsing certificate...
                I0110 12:48:03.261813   10017 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
                I0110 12:48:03.261842   10017 main.go:110] libmachine: Decoding PEM data...
                I0110 12:48:03.261859   10017 main.go:110] libmachine: Parsing certificate...
                I0110 12:48:03.261916   10017 main.go:110] libmachine: Running pre-create checks...
                I0110 12:48:03.261932   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .PreCreateCheck
                I0110 12:48:03.262386   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetConfigRaw
                I0110 12:48:03.262954   10017 main.go:110] libmachine: Creating machine...
                I0110 12:48:03.262976   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .Create
                I0110 12:48:03.263167   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Creating KVM machine...
                I0110 12:48:03.267155   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968 ...
                I0110 12:48:03.267202   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
                I0110 12:48:03.267326   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:03.267109   10182 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:48:03.267458   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
                I0110 12:48:03.399565   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:03.399387   10182 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968/id_rsa...
                I0110 12:48:03.726233   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:03.726086   10182 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968/containerd-20200110T124755.19551629-4968.rawdisk...
                I0110 12:48:03.726267   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Writing magic tar header
                I0110 12:48:03.726284   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Writing SSH key tar header
                I0110 12:48:03.726357   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:03.726256   10182 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968 ...
                I0110 12:48:03.726469   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968
                I0110 12:48:03.726515   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968 (perms=drwx------)
                I0110 12:48:03.726548   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
                I0110 12:48:03.726592   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:48:03.726622   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
                I0110 12:48:03.726644   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
                I0110 12:48:03.726673   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
                I0110 12:48:03.726696   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home/jenkins
                I0110 12:48:03.726724   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
                I0110 12:48:03.726743   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Checking permissions on dir: /home
                I0110 12:48:03.726765   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Skipping /home - not owner
                I0110 12:48:03.726806   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
                I0110 12:48:03.726837   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
                I0110 12:48:03.726863   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
                I0110 12:48:03.726875   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Creating domain...
                I0110 12:48:03.760643   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Creating network...
                I0110 12:48:03.764982   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Ensuring networks are active...
                I0110 12:48:03.768501   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Ensuring network default is active
                I0110 12:48:03.769466   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Ensuring network minikube-net is active
                I0110 12:48:03.770053   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Getting domain xml...
                I0110 12:48:03.773534   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Creating domain...
                I0110 12:48:08.269302   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Waiting to get IP...
                I0110 12:48:08.280295   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 0/40
                I0110 12:48:11.288762   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 1/40
                I0110 12:48:14.297448   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 2/40
                I0110 12:48:17.308770   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 3/40
                I0110 12:48:20.316692   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 4/40
                I0110 12:48:23.326816   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 5/40
                I0110 12:48:26.335375   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 6/40
                I0110 12:48:29.345147   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 7/40
                I0110 12:48:32.356615   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 8/40
                I0110 12:48:35.366187   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 9/40
                I0110 12:48:38.379188   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 10/40
                I0110 12:48:41.391266   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 11/40
                I0110 12:48:44.401354   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 12/40
                I0110 12:48:47.429631   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Waiting for machine to come up 13/40
                I0110 12:48:50.620007   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Getting to WaitForSSH function...
                I0110 12:48:50.620063   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Found IP for machine: 192.168.39.71
                I0110 12:48:50.620119   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Waiting for SSH to be available...
                I0110 12:48:50.630777   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Using SSH client type: external
                I0110 12:48:50.630835   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968/id_rsa (-rw-------)
                I0110 12:48:50.630909   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.71 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/containerd-20200110T124755.19551629-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
                I0110 12:48:50.630947   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | About to run SSH command:
                I0110 12:48:50.630980   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | exit 0
                I0110 12:48:50.804846   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | SSH cmd err, output: <nil>: 
                I0110 12:48:50.805842   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) KVM machine creation complete!
                I0110 12:48:50.806006   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetConfigRaw
                I0110 12:48:50.806888   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:50.807152   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:50.807423   10017 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
                I0110 12:48:50.807448   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetState
                I0110 12:48:50.813393   10017 main.go:110] libmachine: Detecting operating system of created instance...
                I0110 12:48:50.813422   10017 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:48:50.813434   10017 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:48:50.813456   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:50.824116   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:50.824351   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:50.824594   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:50.824845   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:50.825119   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:50.825414   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:50.825439   10017 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:48:50.994245   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:48:50.994286   10017 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:48:50.994304   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:51.006133   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:51.006399   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.006644   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.006857   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:51.007072   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:51.007310   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:51.007334   10017 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:48:51.161776   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:48:51.161963   10017 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:48:51.161991   10017 main.go:110] libmachine: Provisioning with buildroot...
                I0110 12:48:51.162010   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetMachineName
                I0110 12:48:51.162376   10017 main.go:110] libmachine: setting hostname "containerd-20200110T124755.19551629-4968"
                I0110 12:48:51.162402   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetMachineName
                I0110 12:48:51.162834   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:51.176217   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:51.176562   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.176847   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.177104   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:51.177381   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:51.177649   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:51.177687   10017 main.go:110] libmachine: About to run SSH command:
                sudo hostname containerd-20200110T124755.19551629-4968 && echo "containerd-20200110T124755.19551629-4968" | sudo tee /etc/hostname
                I0110 12:48:51.347282   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: containerd-20200110T124755.19551629-4968
                
                I0110 12:48:51.347331   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:51.357088   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:51.357364   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.357587   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:51.357819   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:51.358074   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:51.358303   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:51.358342   10017 main.go:110] libmachine: About to run SSH command:
                
                		if ! grep -xq '.*\scontainerd-20200110T124755.19551629-4968' /etc/hosts; then
                			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
                				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 containerd-20200110T124755.19551629-4968/g' /etc/hosts;
                			else 
                				echo '127.0.1.1 containerd-20200110T124755.19551629-4968' | sudo tee -a /etc/hosts; 
                			fi
                		fi
                I0110 12:48:51.502875   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:48:51.503015   10017 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
                I0110 12:48:51.503036   10017 main.go:110] libmachine: setting up certificates
                I0110 12:48:51.503067   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetMachineName
                I0110 12:48:51.503454   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetIP
                I0110 12:48:51.927359   10017 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.containerd-20200110T124755.19551629-4968 san=[192.168.39.71 localhost]
                I0110 12:48:52.171107   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:52.180400   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:52.180663   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.180889   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:52.275027   10017 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
                I0110 12:48:52.275605   10017 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
                I0110 12:48:52.276592   10017 ssh_runner.go:194] ca.pem: copied 1038 bytes
                I0110 12:48:52.298613   10017 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
                I0110 12:48:52.299006   10017 ssh_runner.go:175] Transferring 1155 bytes to /etc/docker/server.pem
                I0110 12:48:52.300171   10017 ssh_runner.go:194] server.pem: copied 1155 bytes
                I0110 12:48:52.324281   10017 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
                I0110 12:48:52.324713   10017 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
                I0110 12:48:52.325974   10017 ssh_runner.go:194] server-key.pem: copied 1675 bytes
                I0110 12:48:52.344507   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetMachineName
                I0110 12:48:52.345062   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:52.345343   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:52.353895   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:52.354151   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.354351   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.354519   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:52.354711   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:52.354878   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:52.354897   10017 main.go:110] libmachine: About to run SSH command:
                df --output=fstype / | tail -n 1
                I0110 12:48:52.493472   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
                
                I0110 12:48:52.493509   10017 main.go:110] libmachine: root file system type: tmpfs
                I0110 12:48:52.493900   10017 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
                I0110 12:48:52.493938   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:52.504290   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:52.504551   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.504773   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.504995   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:52.505435   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:52.505717   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:52.505867   10017 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 --containerd=/var/run/containerd/containerd.sock 
                ExecReload=/bin/kill -s HUP $MAINPID
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                " | sudo tee /lib/systemd/system/docker.service
                I0110 12:48:52.656929   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 --containerd=/var/run/containerd/containerd.sock 
                ExecReload=/bin/kill -s HUP 
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                
                I0110 12:48:52.657248   10017 main.go:110] libmachine: setting minikube options for container-runtime
                I0110 12:48:52.657400   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:52.667495   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:52.667733   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.667940   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.668165   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:52.668408   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:52.668615   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:52.668645   10017 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /etc/sysconfig && printf %s "
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                " | sudo tee /etc/sysconfig/crio.minikube
                I0110 12:48:52.826882   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                
                I0110 12:48:52.826916   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:52.836633   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:52.836852   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.837069   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:52.837290   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:52.837605   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:52.837849   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:52.837882   10017 main.go:110] libmachine: About to run SSH command:
                sudo systemctl daemon-reload
                I0110 12:48:53.170416   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:48:53.170457   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:53.180469   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:53.180737   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:53.180987   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:53.181244   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:53.181603   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:53.181905   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:53.181936   10017 main.go:110] libmachine: About to run SSH command:
                sudo systemctl -f restart crio
                I0110 12:48:59.395713   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:48:59.395768   10017 main.go:110] libmachine: Checking connection to Docker...
                I0110 12:48:59.395789   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetURL
                I0110 12:48:59.401706   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Using libvirt version 3000000
                I0110 12:48:59.412171   10017 main.go:110] libmachine: Docker is up and running!
                I0110 12:48:59.412202   10017 main.go:110] libmachine: Reticulating splines...
                I0110 12:48:59.412213   10017 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:48:59.412228   10017 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:48:59.412252   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:59.423314   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:59.423626   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.423871   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.424121   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:59.424419   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:59.424639   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:59.424679   10017 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:48:59.593757   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:48:59.593801   10017 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:48:59.593887   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:59.605802   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:59.606046   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.606279   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.606481   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:59.606739   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:59.606965   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:59.606993   10017 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:48:59.775767   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:48:59.775851   10017 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:48:59.775901   10017 cluster.go:418] Provisioned with Buildroot 2019.02.7
                I0110 12:48:59.775929   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:59.787718   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:59.788063   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.788318   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.788552   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:48:59.788818   10017 main.go:110] libmachine: Using SSH client type: native
                I0110 12:48:59.789085   10017 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.71 22 <nil> <nil>}
                I0110 12:48:59.789125   10017 main.go:110] libmachine: About to run SSH command:
                date +%s.%N
                I0110 12:48:59.957752   10017 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578660539.826244544
                
                I0110 12:48:59.957786   10017 cluster.go:197] guest clock: 1578660539.826244544
                I0110 12:48:59.957799   10017 cluster.go:210] Guest: 2020-01-10 12:48:59.826244544 +0000 UTC Remote: 2020-01-10 12:48:59.775914788 +0000 UTC m=+64.577136417 (delta=50.329756ms)
                I0110 12:48:59.957836   10017 cluster.go:181] guest clock delta is within tolerance: 50.329756ms
                I0110 12:48:59.957875   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetConfigRaw
                I0110 12:48:59.958822   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:59.959081   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:48:59.959396   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:48:59.971303   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:48:59.971561   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:48:59.971794   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:49:00.036806   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetIP
                I0110 12:49:00.049026   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:49:00.049392   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:49:00.050372   10017 ssh_runner.go:102] Run: nslookup kubernetes.io
                I0110 12:49:00.110250   10017 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
                I0110 12:49:00.196843   10017 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/containerd-20200110T124755.19551629-4968/config.json ...
                I0110 12:49:00.197281   10017 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:49:00.215998   10017 ssh_runner.go:102] Run: sudo systemctl stop crio
                I0110 12:49:00.362859   10017 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:49:00.383963   10017 ssh_runner.go:102] Run: systemctl is-active --quiet service docker
                I0110 12:49:00.400289   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc && printf %s "runtime-endpoint: unix:///run/containerd/containerd.sock
                image-endpoint: unix:///run/containerd/containerd.sock
                " | sudo tee /etc/crictl.yaml"
                I0110 12:49:00.437258   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo mkdir -p /etc/containerd && printf %s "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" | base64 -d | sudo tee /etc/containerd/config.toml"
                I0110 12:49:00.466128   10017 ssh_runner.go:102] Run: sudo modprobe br_netfilter
                I0110 12:49:00.506067   10017 ssh_runner.go:102] Run: sudo sh -c "echo 1 > /proc/sys/net/ipv4/ip_forward"
                I0110 12:49:00.521464   10017 ssh_runner.go:102] Run: sudo systemctl restart containerd
                I0110 12:49:00.569700   10017 ssh_runner.go:102] Run: containerd --version
                I0110 12:49:01.431010   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetURL
                I0110 12:49:01.437089   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) DBG | Using libvirt version 3000000
                I0110 12:49:01.448170   10017 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:49:01.801630   10017 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                I0110 12:49:01.808122   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:49:01.858153   10017 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:49:01.858270   10017 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:49:02.163250   10017 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:32795
                I0110 12:49:02.163995   10017 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:49:02.164810   10017 main.go:110] libmachine: Using API Version  1
                I0110 12:49:02.164857   10017 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:49:02.165422   10017 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:49:02.165748   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:49:02.166005   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .DriverName
                I0110 12:49:02.166213   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHHostname
                I0110 12:49:02.176978   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHPort
                I0110 12:49:02.177286   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHKeyPath
                I0110 12:49:02.177535   10017 main.go:110] libmachine: (containerd-20200110T124755.19551629-4968) Calling .GetSSHUsername
                I0110 12:49:02.239631   10017 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
                I0110 12:49:02.243387   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/pause:3.1 | grep sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e"
                I0110 12:49:02.243403   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep gcr.io/k8s-minikube/storage-provisioner:v1.8.1 | grep sha256:4689081edb103a9e8174bf23a255bfbe0b2d9ed82edc907abab6989d1c60f02c"
                I0110 12:49:02.243388   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep kubernetesui/metrics-scraper:v1.0.2 | grep sha256:3b08661dc379d9f80155be9d658f71578988640357ebae1aab287d6954c723d1"
                I0110 12:49:02.243498   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep kubernetesui/dashboard:v2.0.0-beta8 | grep sha256:eb51a359752560a66f314602e87155b75f428fb838bf951079ff1f9621958c0c"
                I0110 12:49:02.243691   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-addon-manager:v9.0.2 | grep sha256:bd12a212f9dcbafe64323774c6b937dec3099d65f39a8d29896cf0d1d0c906cf"
                I0110 12:49:02.257541   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-proxy:v1.17.0 | grep sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19"
                I0110 12:49:02.273253   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-apiserver:v1.17.0 | grep sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2"
                I0110 12:49:02.288150   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/etcd:3.4.3-0 | grep sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f"
                I0110 12:49:02.288851   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-scheduler:v1.17.0 | grep sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28"
                I0110 12:49:02.290524   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-controller-manager:v1.17.0 | grep sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056"
                I0110 12:49:02.334023   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/coredns:1.6.5 | grep sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61"
                I0110 12:49:04.259118   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/pause:3.1 | grep sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e": (2.015685239s)
                I0110 12:49:04.259189   10017 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: "k8s.gcr.io/pause:3.1" does not exist at hash "sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e" in container runtime
                I0110 12:49:04.259215   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
                I0110 12:49:04.259119   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-controller-manager:v1.17.0 | grep sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056": (1.968556605s)
                I0110 12:49:04.259318   10017 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: "k8s.gcr.io/kube-controller-manager:v1.17.0" does not exist at hash "sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056" in container runtime
                I0110 12:49:04.259345   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
                I0110 12:49:04.263836   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep kubernetesui/metrics-scraper:v1.0.2 | grep sha256:3b08661dc379d9f80155be9d658f71578988640357ebae1aab287d6954c723d1": (2.020346867s)
                I0110 12:49:04.263882   10017 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: "kubernetesui/metrics-scraper:v1.0.2" does not exist at hash "sha256:3b08661dc379d9f80155be9d658f71578988640357ebae1aab287d6954c723d1" in container runtime
                I0110 12:49:04.263900   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
                I0110 12:49:04.287015   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
                I0110 12:49:04.287051   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep gcr.io/k8s-minikube/storage-provisioner:v1.8.1 | grep sha256:4689081edb103a9e8174bf23a255bfbe0b2d9ed82edc907abab6989d1c60f02c": (2.043620275s)
                I0110 12:49:04.287075   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-apiserver:v1.17.0 | grep sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2": (2.013771848s)
                I0110 12:49:04.287112   10017 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: "k8s.gcr.io/kube-apiserver:v1.17.0" does not exist at hash "sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2" in container runtime
                I0110 12:49:04.287133   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
                I0110 12:49:04.287113   10017 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" does not exist at hash "sha256:4689081edb103a9e8174bf23a255bfbe0b2d9ed82edc907abab6989d1c60f02c" in container runtime
                I0110 12:49:04.287227   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
                I0110 12:49:04.288926   10017 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
                I0110 12:49:04.292314   10017 ssh_runner.go:194] pause_3.1: copied 356864 bytes
                I0110 12:49:04.293950   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-addon-manager:v9.0.2 | grep sha256:bd12a212f9dcbafe64323774c6b937dec3099d65f39a8d29896cf0d1d0c906cf": (2.050229723s)
                I0110 12:49:04.293992   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-proxy:v1.17.0 | grep sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19": (2.036388537s)
                I0110 12:49:04.294029   10017 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: "k8s.gcr.io/kube-proxy:v1.17.0" does not exist at hash "sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19" in container runtime
                I0110 12:49:04.294071   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
                I0110 12:49:04.293995   10017 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: "k8s.gcr.io/kube-addon-manager:v9.0.2" does not exist at hash "sha256:bd12a212f9dcbafe64323774c6b937dec3099d65f39a8d29896cf0d1d0c906cf" in container runtime
                I0110 12:49:04.294201   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
                I0110 12:49:04.293958   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/kube-scheduler:v1.17.0 | grep sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28": (2.00503295s)
                I0110 12:49:04.294341   10017 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: "k8s.gcr.io/kube-scheduler:v1.17.0" does not exist at hash "sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28" in container runtime
                I0110 12:49:04.294363   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
                I0110 12:49:04.298839   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
                I0110 12:49:04.311974   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:49:04.312965   10017 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:49:04.313035   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep kubernetesui/dashboard:v2.0.0-beta8 | grep sha256:eb51a359752560a66f314602e87155b75f428fb838bf951079ff1f9621958c0c": (2.069505649s)
                I0110 12:49:04.313076   10017 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: "kubernetesui/dashboard:v2.0.0-beta8" does not exist at hash "sha256:eb51a359752560a66f314602e87155b75f428fb838bf951079ff1f9621958c0c" in container runtime
                I0110 12:49:04.313106   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
                I0110 12:49:04.313160   10017 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:49:04.323149   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
                I0110 12:49:04.357198   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:49:04.357686   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/coredns:1.6.5 | grep sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61": (2.023609625s)
                I0110 12:49:04.357739   10017 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: "k8s.gcr.io/coredns:1.6.5" does not exist at hash "sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61" in container runtime
                I0110 12:49:04.357760   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
                I0110 12:49:04.360589   10017 ssh_runner.go:142] Completed: /bin/bash -c "sudo ctr -n=k8s.io images check | grep k8s.gcr.io/etcd:3.4.3-0 | grep sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f": (2.072396216s)
                I0110 12:49:04.360647   10017 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: "k8s.gcr.io/etcd:3.4.3-0" does not exist at hash "sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f" in container runtime
                I0110 12:49:04.360675   10017 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
                I0110 12:49:04.362661   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:49:04.390486   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:49:04.390518   10017 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:49:04.390587   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
                I0110 12:49:04.390644   10017 containerd.go:235] Loading image: /var/lib/minikube/images/pause_3.1
                I0110 12:49:04.390699   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/pause_3.1
                I0110 12:49:04.390746   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
                I0110 12:49:04.391009   10017 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:49:04.419118   10017 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:49:04.421122   10017 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:49:04.421187   10017 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:49:04.422093   10017 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:49:04.459284   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
                I0110 12:49:04.516815   10017 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
                I0110 12:49:04.557890   10017 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
                I0110 12:49:04.581163   10017 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:49:06.320925   10017 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
                I0110 12:49:06.670290   10017 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
                I0110 12:49:06.921838   10017 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
                I0110 12:49:07.477759   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/pause_3.1: (3.087012181s)
                I0110 12:49:07.477810   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
                I0110 12:49:07.477831   10017 containerd.go:235] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:49:07.477897   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:49:08.564742   10017 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
                I0110 12:49:09.196495   10017 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
                I0110 12:49:09.196920   10017 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
                I0110 12:49:09.717331   10017 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
                I0110 12:49:09.883086   10017 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
                I0110 12:49:09.889274   10017 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
                I0110 12:49:10.409379   10017 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
                I0110 12:49:16.864147   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/metrics-scraper_v1.0.2: (9.386203071s)
                I0110 12:49:16.864185   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
                I0110 12:49:16.864204   10017 containerd.go:235] Loading image: /var/lib/minikube/images/coredns_1.6.5
                I0110 12:49:16.864271   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/coredns_1.6.5
                I0110 12:49:20.302362   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/coredns_1.6.5: (3.43805137s)
                I0110 12:49:20.302404   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
                I0110 12:49:20.302418   10017 containerd.go:235] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:49:20.302475   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:49:23.479731   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/storage-provisioner_v1.8.1: (3.177194189s)
                I0110 12:49:23.479778   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
                I0110 12:49:23.479795   10017 containerd.go:235] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:49:23.479873   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:49:30.445653   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-addon-manager_v9.0.2: (6.965750777s)
                I0110 12:49:30.445702   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
                I0110 12:49:30.445732   10017 containerd.go:235] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:49:30.445821   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:49:34.203365   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/dashboard_v2.0.0-beta8: (3.757503085s)
                I0110 12:49:34.203425   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
                I0110 12:49:34.203440   10017 containerd.go:235] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:49:34.203513   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:49:41.205754   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-scheduler_v1.17.0: (7.002197537s)
                I0110 12:49:41.205786   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
                I0110 12:49:41.205800   10017 containerd.go:235] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:49:41.205896   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:49:48.750778   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-controller-manager_v1.17.0: (7.544826606s)
                I0110 12:49:48.750822   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
                I0110 12:49:48.750842   10017 containerd.go:235] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:49:48.750911   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:49:58.921264   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-proxy_v1.17.0: (10.170322007s)
                I0110 12:49:58.921309   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
                I0110 12:49:58.921323   10017 containerd.go:235] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:49:58.921382   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:50:08.233424   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/kube-apiserver_v1.17.0: (9.312013317s)
                I0110 12:50:08.233470   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
                I0110 12:50:08.233484   10017 containerd.go:235] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:50:08.233576   10017 ssh_runner.go:102] Run: sudo ctr -n=k8s.io images import /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:50:28.344418   10017 ssh_runner.go:142] Completed: sudo ctr -n=k8s.io images import /var/lib/minikube/images/etcd_3.4.3-0: (20.110806455s)
                I0110 12:50:28.344469   10017 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
                I0110 12:50:28.344489   10017 cache_images.go:93] Successfully loaded all cached images
                I0110 12:50:28.344499   10017 cache_images.go:94] LoadImages end
                I0110 12:50:28.345624   10017 kubeadm.go:390] kubelet [Unit]
                Wants=containerd.service
                
                [Service]
                ExecStart=
                ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=remote --container-runtime-endpoint=unix:///run/containerd/containerd.sock --fail-swap-on=false --hostname-override=minikube --image-service-endpoint=unix:///run/containerd/containerd.sock --kubeconfig=/etc/kubernetes/kubelet.conf --network-plugin=cni --node-ip=192.168.39.71 --pod-manifest-path=/etc/kubernetes/manifests --runtime-request-timeout=15m
                
                [Install]
                 config:
                {KubernetesVersion:v1.17.0 NodeIP:192.168.39.71 NodePort:8444 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:50:28.345701   10017 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
                W0110 12:50:28.375674   10017 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
                stdout:
                
                stderr:
                 command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
                I0110 12:50:28.402012   10017 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
                I0110 12:50:28.402032   10017 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
                I0110 12:50:28.449359   10017 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
                I0110 12:50:28.449359   10017 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
                I0110 12:50:28.450151   10017 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
                I0110 12:50:28.450286   10017 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
                I0110 12:50:29.214077   10017 ssh_runner.go:194] kubeadm: copied 39342080 bytes
                I0110 12:50:29.966958   10017 ssh_runner.go:194] kubelet: copied 111560216 bytes
                I0110 12:50:29.997372   10017 ssh_runner.go:175] Transferring 1158 bytes to /var/tmp/minikube/kubeadm.yaml
                I0110 12:50:30.001476   10017 ssh_runner.go:194] kubeadm.yaml: copied 1158 bytes
                I0110 12:50:30.055801   10017 ssh_runner.go:175] Transferring 748 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                I0110 12:50:30.058139   10017 ssh_runner.go:194] 10-kubeadm.conf: copied 748 bytes
                I0110 12:50:30.094834   10017 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
                I0110 12:50:30.106932   10017 ssh_runner.go:194] kubelet.service: copied 349 bytes
                I0110 12:50:30.147089   10017 ssh_runner.go:175] Transferring 341 bytes to /etc/cni/net.d/k8s.conf
                I0110 12:50:30.149203   10017 ssh_runner.go:194] k8s.conf: copied 341 bytes
                I0110 12:50:30.194587   10017 ssh_runner.go:156] Checked if /etc/sync.test exists, but got error: Process exited with status 1
                I0110 12:50:30.195651   10017 ssh_runner.go:175] Transferring 40 bytes to /etc/sync.test
                I0110 12:50:30.196949   10017 ssh_runner.go:194] sync.test: copied 40 bytes
                I0110 12:50:30.231620   10017 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
                I0110 12:50:30.232886   10017 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
                I0110 12:50:30.266058   10017 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
                I0110 12:50:30.267909   10017 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
                I0110 12:50:30.300566   10017 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
                I0110 12:50:30.302623   10017 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
                I0110 12:50:30.326834   10017 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
                I0110 12:50:30.328159   10017 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
                I0110 12:50:30.358751   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
                I0110 12:50:30.638556   10017 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.71
                I0110 12:50:30.638611   10017 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.638851   10017 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
                I0110 12:50:30.643820   10017 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
                I0110 12:50:30.643907   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.644357   10017 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
                I0110 12:50:30.644403   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.644665   10017 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.71 10.96.0.1 127.0.0.1 10.0.0.1]
                I0110 12:50:30.649369   10017 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
                I0110 12:50:30.649421   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.649750   10017 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
                I0110 12:50:30.649780   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.650000   10017 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
                I0110 12:50:30.654984   10017 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
                I0110 12:50:30.655104   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.655513   10017 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
                I0110 12:50:30.655591   10017 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:30.719257   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
                I0110 12:50:30.722149   10017 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
                I0110 12:50:30.724117   10017 ssh_runner.go:194] ca.crt: copied 1066 bytes
                I0110 12:50:30.801641   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
                I0110 12:50:30.802538   10017 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
                I0110 12:50:30.803816   10017 ssh_runner.go:194] ca.key: copied 1675 bytes
                I0110 12:50:30.856221   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
                I0110 12:50:30.857074   10017 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
                I0110 12:50:30.858480   10017 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
                I0110 12:50:30.900909   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
                I0110 12:50:30.914735   10017 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
                I0110 12:50:30.919017   10017 ssh_runner.go:194] apiserver.key: copied 1679 bytes
                I0110 12:50:30.989625   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
                I0110 12:50:30.990634   10017 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
                I0110 12:50:30.992231   10017 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
                I0110 12:50:31.057098   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
                I0110 12:50:31.064896   10017 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
                I0110 12:50:31.066234   10017 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
                I0110 12:50:31.122799   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
                I0110 12:50:31.123833   10017 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
                I0110 12:50:31.125260   10017 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
                I0110 12:50:31.182223   10017 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
                I0110 12:50:31.183156   10017 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
                I0110 12:50:31.184311   10017 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
                I0110 12:50:31.234149   10017 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
                I0110 12:50:31.235092   10017 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:50:31.236248   10017 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
                I0110 12:50:31.274111   10017 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
                I0110 12:50:31.275644   10017 ssh_runner.go:194] kubeconfig: copied 428 bytes
                I0110 12:50:31.307966   10017 ssh_runner.go:102] Run: openssl version
                I0110 12:50:31.324152   10017 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
                I0110 12:50:31.337787   10017 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
                I0110 12:50:31.352506   10017 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:50:31.385636   10017 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
                I0110 12:50:31.416258   10017 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
                I0110 12:50:31.431398   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
                I0110 12:50:31.893234   10017 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
                I0110 12:50:31.917534   10017 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
                stdout:
                
                stderr:
                ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
                ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
                ls: cannot access '/var/lib/minikube/etcd': No such file or directory
                I0110 12:50:31.917576   10017 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.71 NodePort:8444 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:containerd CRISocket: NetworkPlugin:cni FeatureGates: ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[] ShouldLoadCachedImages:true EnableDefaultCNI:true}
                I0110 12:50:31.917674   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
                I0110 12:50:32.092540   10017 kubeadm.go:152] StartCluster complete in 174.950864ms
                I0110 12:50:32.092644   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-apiserver --state=Running --quiet
                I0110 12:50:32.301468   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.301515   10017 logs.go:180] No container was found matching "kube-apiserver"
                I0110 12:50:32.301635   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=coredns --state=Running --quiet
                I0110 12:50:32.362864   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.362892   10017 logs.go:180] No container was found matching "coredns"
                I0110 12:50:32.362958   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-scheduler --state=Running --quiet
                I0110 12:50:32.410715   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.410754   10017 logs.go:180] No container was found matching "kube-scheduler"
                I0110 12:50:32.410843   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-proxy --state=Running --quiet
                I0110 12:50:32.449457   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.449503   10017 logs.go:180] No container was found matching "kube-proxy"
                I0110 12:50:32.449604   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-addon-manager --state=Running --quiet
                I0110 12:50:32.505818   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.505858   10017 logs.go:180] No container was found matching "kube-addon-manager"
                I0110 12:50:32.505934   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kubernetes-dashboard --state=Running --quiet
                I0110 12:50:32.539992   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.540028   10017 logs.go:180] No container was found matching "kubernetes-dashboard"
                I0110 12:50:32.540109   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=storage-provisioner --state=Running --quiet
                I0110 12:50:32.589287   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.589319   10017 logs.go:180] No container was found matching "storage-provisioner"
                I0110 12:50:32.589393   10017 ssh_runner.go:102] Run: sudo crictl ps -a --name=kube-controller-manager --state=Running --quiet
                I0110 12:50:32.627023   10017 logs.go:178] 0 containers: []
                W0110 12:50:32.627062   10017 logs.go:180] No container was found matching "kube-controller-manager"
                I0110 12:50:32.627080   10017 logs.go:92] Gathering logs for kubelet ...
                I0110 12:50:32.627096   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
                I0110 12:50:32.753342   10017 logs.go:92] Gathering logs for dmesg ...
                I0110 12:50:32.753383   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
                I0110 12:50:32.787154   10017 logs.go:92] Gathering logs for containerd ...
                I0110 12:50:32.787196   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u containerd -n 400"
                I0110 12:50:32.824810   10017 logs.go:92] Gathering logs for container status ...
                I0110 12:50:32.824875   10017 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
                W0110 12:50:32.866856   10017 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:50:32.089270    2609 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:50:32.089270    2609 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            start_stop_delete_test.go:97: [out/minikube-linux-amd64 start -p containerd-20200110T124755.19551629-4968 --alsologtostderr -v=3 --wait=true --container-runtime=containerd --docker-opt containerd=/var/run/containerd/containerd.sock --apiserver-port=8444 --vm-driver=kvm2  --kubernetes-version=v1.17.0] failed: exit status 70
            panic.go:563: *** TestStartStop/group/containerd FAILED at 2020-01-10 12:50:32.870838604 +0000 UTC m=+1053.515857468
            panic.go:563: >>> TestStartStop/group/containerd FAILED: start of post-mortem logs >>>
            panic.go:563: (dbg) Run:  kubectl --context containerd-20200110T124755.19551629-4968 get po -A --show-labels
            panic.go:563: (dbg) Non-zero exit: kubectl --context containerd-20200110T124755.19551629-4968 get po -A --show-labels: exit status 1 (364.837536ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.71:8444 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context containerd-20200110T124755.19551629-4968 get po -A --show-labels: exit status 1
            panic.go:563: (dbg) kubectl --context containerd-20200110T124755.19551629-4968 get po -A --show-labels:
            panic.go:563: (dbg) Run:  kubectl --context containerd-20200110T124755.19551629-4968 describe node
            panic.go:563: (dbg) Non-zero exit: kubectl --context containerd-20200110T124755.19551629-4968 describe node: exit status 1 (131.02748ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.71:8444 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context containerd-20200110T124755.19551629-4968 describe node: exit status 1
            panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p containerd-20200110T124755.19551629-4968 logs --problems
            panic.go:563: (dbg) Done: out/minikube-linux-amd64 -p containerd-20200110T124755.19551629-4968 logs --problems: (1.507502308s)
            panic.go:563: TestStartStop/group/containerd logs: 
            panic.go:563: <<< TestStartStop/group/containerd FAILED: end of post-mortem logs <<<
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p containerd-20200110T124755.19551629-4968
            helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p containerd-20200110T124755.19551629-4968: (1.132757165s)
        --- FAIL: TestStartStop/group/newest-cni (426.41s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:48:45.195248657 +0000 UTC m=+945.840267405 (sleeping 4m9.999392735s)  ...
            start_stop_delete_test.go:94: (dbg) Run:  out/minikube-linux-amd64 start -p newest-cni-20200110T124845.195538591-4968 --alsologtostderr -v=3 --wait=true --feature-gates ServerSideApply=true --network-plugin=cni --extra-config=kubelet.network-plugin=cni --extra-config=kubeadm.pod-network-cidr=192.168.111.111/16 --vm-driver=kvm2  --kubernetes-version=v1.17.0
            start_stop_delete_test.go:94: (dbg) Non-zero exit: out/minikube-linux-amd64 start -p newest-cni-20200110T124845.195538591-4968 --alsologtostderr -v=3 --wait=true --feature-gates ServerSideApply=true --network-plugin=cni --extra-config=kubelet.network-plugin=cni --extra-config=kubeadm.pod-network-cidr=192.168.111.111/16 --vm-driver=kvm2  --kubernetes-version=v1.17.0: exit status 70 (2m48.470463903s)
                -- stdout --
                * [newest-cni-20200110T124845.195538591-4968] minikube v1.6.2 on Debian 9.11
                  - KUBECONFIG=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                  - MINIKUBE_BIN=out/minikube-linux-amd64
                  - MINIKUBE_HOME=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                  - MINIKUBE_LOCATION=6150
                * Selecting 'kvm2' driver from user configuration (alternates: [virtualbox docker none])
                * Creating kvm2 VM (CPUs=2, Memory=2000MB, Disk=20000MB) ...
                * Preparing Kubernetes v1.17.0 on Docker '19.03.5' ...
                  - kubelet.network-plugin=cni
                  - kubeadm.pod-network-cidr=192.168.111.111/16
                * Pulling images ...
                * Unable to pull images, which may be OK: running cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:51:30.908965    2858 strict.go:54] error unmarshaling configuration schema.GroupVersionKind{Group:"kubeadm.k8s.io", Version:"v1beta2", Kind:"ClusterConfiguration"}: error converting YAML to JSON: yaml: unmarshal errors:
                  line 16: key "controllerManager" already set in map
                W0110 12:51:30.915844    2858 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * Launching Kubernetes ... 
                
                -- /stdout --
                ** stderr ** 
                I0110 12:48:46.113563   10292 notify.go:125] Checking for updates...
                I0110 12:48:48.781328   10292 start.go:256] hostinfo: {"hostname":"kvm-integration-slave","uptime":1877,"bootTime":1578658651,"procs":227,"os":"linux","platform":"debian","platformFamily":"debian","platformVersion":"9.11","kernelVersion":"4.9.0-11-amd64","virtualizationSystem":"kvm","virtualizationRole":"host","hostid":"ae41e7f6-8b8e-4d40-b77d-1ebb5a2d5fdb"}
                I0110 12:48:48.782359   10292 start.go:266] virtualization: kvm host
                I0110 12:48:48.782693   10292 start.go:567] selectDriver: flag="kvm2", old=<nil>
                I0110 12:48:48.782723   10292 global.go:60] Querying for installed drivers using PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:48:48.782800   10292 global.go:68] vmware priority: 5, state: {Installed:false Healthy:false Error:exec: "docker-machine-driver-vmware": executable file not found in $PATH Fix:Install docker-machine-driver-vmware Doc:https://minikube.sigs.k8s.io/docs/reference/drivers/vmware/}
                I0110 12:48:49.011832   10292 global.go:68] docker priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:51.391350   10292 global.go:68] kvm2 priority: 6, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:51.391440   10292 global.go:68] none priority: 2, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:53.838293   10292 global.go:68] virtualbox priority: 4, state: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:53.838358   10292 driver.go:128] requested: "kvm2"
                I0110 12:48:53.838373   10292 driver.go:132] choosing "kvm2" because it was requested
                I0110 12:48:53.838382   10292 driver.go:147] not recommending "docker" due to priority: 2
                I0110 12:48:53.838395   10292 driver.go:147] not recommending "none" due to priority: 2
                I0110 12:48:53.838407   10292 driver.go:165] Picked: kvm2
                I0110 12:48:53.838432   10292 driver.go:166] Alternatives: [virtualbox docker none]
                I0110 12:48:53.838573   10292 start.go:298] selected driver: kvm2
                I0110 12:48:53.838584   10292 start.go:597] validating driver "kvm2" against <nil>
                I0110 12:48:53.881754   10292 start.go:603] status for kvm2: {Installed:true Healthy:true Error:<nil> Fix: Doc:}
                I0110 12:48:53.881908   10292 install.go:102] Validating docker-machine-driver-kvm2, PATH=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin:/home/jenkins/workspace/KVM_Linux_integration/out/:/usr/local/bin:/usr/bin:/bin:/usr/local/games:/usr/games:/usr/local/go/bin:/home/jenkins/go/bin:/usr/local/bin/:/usr/local/go/bin/:/home/jenkins/go/bin
                I0110 12:48:53.903598   10292 downloader.go:60] Not caching ISO, using https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso
                I0110 12:48:53.903924   10292 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/newest-cni-20200110T124845.195538591-4968/config.json ...
                I0110 12:48:53.904088   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/newest-cni-20200110T124845.195538591-4968/config.json: {Name:mk7562f7701ed6db64697f43677a4f642870ac03 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:48:53.904358   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 exists
                I0110 12:48:53.904374   10292 cache.go:78] cache image "kubernetesui/metrics-scraper:v1.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 to local destination -> "31.501Âµs"
                I0110 12:48:53.904395   10292 cache.go:63] save to tar file kubernetesui/metrics-scraper:v1.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 succeeded
                I0110 12:48:53.904364   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 exists
                I0110 12:48:53.904407   10292 cache.go:78] cache image "k8s.gcr.io/kube-proxy:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 to local destination -> "78.077Âµs"
                I0110 12:48:53.904402   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 exists
                I0110 12:48:53.904429   10292 cache.go:78] cache image "k8s.gcr.io/kube-scheduler:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 to local destination -> "79.272Âµs"
                I0110 12:48:53.904442   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 exists
                I0110 12:48:53.904444   10292 cache.go:63] save to tar file k8s.gcr.io/kube-scheduler:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 succeeded
                I0110 12:48:53.904417   10292 cache.go:63] save to tar file k8s.gcr.io/kube-proxy:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 succeeded
                I0110 12:48:53.904417   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 exists
                I0110 12:48:53.904463   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 exists
                I0110 12:48:53.904469   10292 cache.go:78] cache image "k8s.gcr.io/etcd:3.4.3-0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 to local destination -> "73.922Âµs"
                I0110 12:48:53.904480   10292 cache.go:63] save to tar file k8s.gcr.io/etcd:3.4.3-0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 succeeded
                I0110 12:48:53.904483   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 exists
                I0110 12:48:53.904492   10292 cache.go:78] cache image "k8s.gcr.io/kube-apiserver:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 to local destination -> "23.94Âµs"
                I0110 12:48:53.904505   10292 cache.go:63] save to tar file k8s.gcr.io/kube-apiserver:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 succeeded
                I0110 12:48:53.904471   10292 cache.go:78] cache image "k8s.gcr.io/kube-addon-manager:v9.0.2" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 to local destination -> "20.331Âµs"
                I0110 12:48:53.904520   10292 cache.go:63] save to tar file k8s.gcr.io/kube-addon-manager:v9.0.2 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 succeeded
                I0110 12:48:53.904453   10292 cache.go:78] cache image "k8s.gcr.io/kube-controller-manager:v1.17.0" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 to local destination -> "27.151Âµs"
                I0110 12:48:53.904527   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 exists
                I0110 12:48:53.904543   10292 cache.go:78] cache image "k8s.gcr.io/coredns:1.6.5" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 to local destination -> "47.89Âµs"
                I0110 12:48:53.904553   10292 cache.go:63] save to tar file k8s.gcr.io/coredns:1.6.5 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 succeeded
                I0110 12:48:53.904441   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 exists
                I0110 12:48:53.904567   10292 cache.go:78] cache image "k8s.gcr.io/pause:3.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 to local destination -> "139.13Âµs"
                I0110 12:48:53.904576   10292 cache.go:63] save to tar file k8s.gcr.io/pause:3.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 succeeded
                I0110 12:48:53.904532   10292 cache.go:63] save to tar file k8s.gcr.io/kube-controller-manager:v1.17.0 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 succeeded
                I0110 12:48:53.904533   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 exists
                I0110 12:48:53.904590   10292 cache.go:78] cache image "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 to local destination -> "74.082Âµs"
                I0110 12:48:53.904605   10292 cache.go:63] save to tar file gcr.io/k8s-minikube/storage-provisioner:v1.8.1 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 succeeded
                I0110 12:48:53.904578   10292 cache.go:82] /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 exists
                I0110 12:48:53.904617   10292 cache.go:78] cache image "kubernetesui/dashboard:v2.0.0-beta8" -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 to local destination -> "77.682Âµs"
                I0110 12:48:53.904626   10292 cache.go:63] save to tar file kubernetesui/dashboard:v2.0.0-beta8 -> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 succeeded
                I0110 12:48:53.904639   10292 cache.go:70] Successfully saved all images to host disk.
                I0110 12:48:53.929152   10292 cluster.go:96] Machine does not exist... provisioning new machine
                I0110 12:48:53.929193   10292 cluster.go:97] Provisioning machine with config: {Name:newest-cni-20200110T124845.195538591-4968 KeepContext:false EmbedCerts:false MinikubeISO:https://storage.googleapis.com/minikube/iso/minikube-v1.6.0.iso Memory:2000 CPUs:2 DiskSize:20000 VMDriver:kvm2 ContainerRuntime:docker HyperkitVpnKitSock: HyperkitVSockPorts:[] DockerEnv:[] InsecureRegistry:[] RegistryMirror:[] HostOnlyCIDR:192.168.99.1/24 HypervVirtualSwitch: KVMNetwork:default KVMQemuURI:qemu:///system KVMGPU:false KVMHidden:false Downloader:{} DockerOpt:[] DisableDriverMounts:false NFSShare:[] NFSSharesRoot:/nfsshares UUID: NoVTXCheck:false DNSProxy:false HostDNSResolver:true KubernetesConfig:{KubernetesVersion:v1.17.0 NodeIP: NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates:ServerSideApply=true ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[{Component:kubelet Key:network-plugin Value:cni} {Component:kubeadm Key:pod-network-cidr Value:192.168.111.111/16}] ShouldLoadCachedImages:true EnableDefaultCNI:false} HostOnlyNicType:virtio NatNicType:virtio Addons:map[] NodeBindPort:0}
                I0110 12:48:53.929630   10292 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:48:53.929723   10292 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:48:53.949761   10292 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:46749
                I0110 12:48:53.950472   10292 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:48:53.951385   10292 main.go:110] libmachine: Using API Version  1
                I0110 12:48:53.951424   10292 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:48:53.953339   10292 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:48:53.953631   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetMachineName
                I0110 12:48:53.957327   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:48:53.957732   10292 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem
                I0110 12:48:53.957800   10292 main.go:110] libmachine: Decoding PEM data...
                I0110 12:48:53.957831   10292 main.go:110] libmachine: Parsing certificate...
                I0110 12:48:53.957977   10292 main.go:110] libmachine: Reading certificate data from /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem
                I0110 12:48:53.958020   10292 main.go:110] libmachine: Decoding PEM data...
                I0110 12:48:53.958055   10292 main.go:110] libmachine: Parsing certificate...
                I0110 12:48:53.958154   10292 main.go:110] libmachine: Running pre-create checks...
                I0110 12:48:53.958177   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .PreCreateCheck
                I0110 12:48:53.958718   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetConfigRaw
                I0110 12:48:53.959438   10292 main.go:110] libmachine: Creating machine...
                I0110 12:48:53.959462   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .Create
                I0110 12:48:53.959668   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Creating KVM machine...
                I0110 12:48:53.965438   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting up store path in /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968 ...
                I0110 12:48:53.965482   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Building disk image from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso
                I0110 12:48:53.965644   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:53.965367   10517 common.go:99] Making disk image using store path: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:48:53.973365   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Downloading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/boot2docker.iso from file:///home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/iso/minikube-v1.6.0.iso...
                I0110 12:48:54.159395   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:54.159223   10517 common.go:106] Creating ssh key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968/id_rsa...
                I0110 12:48:54.330944   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:54.330776   10517 common.go:112] Creating raw disk image: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968/newest-cni-20200110T124845.195538591-4968.rawdisk...
                I0110 12:48:54.330994   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Writing magic tar header
                I0110 12:48:54.331018   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Writing SSH key tar header
                I0110 12:48:54.331046   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | ERROR: logging before flag.Parse: I0110 12:48:54.330963   10517 common.go:126] Fixing permissions on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968 ...
                I0110 12:48:54.331217   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968
                I0110 12:48:54.331269   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines
                I0110 12:48:54.331320   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968 (perms=drwx------)
                I0110 12:48:54.331365   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines (perms=drwxr-xr-x)
                I0110 12:48:54.331401   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube (perms=drwxr-xr-x)
                I0110 12:48:54.331431   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube
                I0110 12:48:54.331461   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25
                I0110 12:48:54.331482   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins/minikube-integration
                I0110 12:48:54.331501   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home/jenkins
                I0110 12:48:54.331514   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Checking permissions on dir: /home
                I0110 12:48:54.331534   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Skipping /home - not owner
                I0110 12:48:54.331557   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 (perms=drwxr-xr-x)
                I0110 12:48:54.331573   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins/minikube-integration (perms=drwxr-xr-x)
                I0110 12:48:54.331592   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Setting executable bit set on /home/jenkins (perms=drwxr-xr-x)
                I0110 12:48:54.331606   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Creating domain...
                I0110 12:48:54.363209   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Creating network...
                I0110 12:48:54.368644   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Ensuring networks are active...
                I0110 12:48:54.373076   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Ensuring network default is active
                I0110 12:48:54.374278   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Ensuring network minikube-net is active
                I0110 12:48:54.375213   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Getting domain xml...
                I0110 12:48:54.380355   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Creating domain...
                I0110 12:48:56.964472   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Waiting to get IP...
                I0110 12:48:56.975787   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 0/40
                I0110 12:48:59.987016   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 1/40
                I0110 12:49:02.999711   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 2/40
                I0110 12:49:06.012862   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 3/40
                I0110 12:49:09.026116   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 4/40
                I0110 12:49:12.035437   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 5/40
                I0110 12:49:15.047749   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 6/40
                I0110 12:49:18.058767   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 7/40
                I0110 12:49:21.122052   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 8/40
                I0110 12:49:24.133050   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 9/40
                I0110 12:49:27.142066   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 10/40
                I0110 12:49:30.153681   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 11/40
                I0110 12:49:33.168290   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 12/40
                I0110 12:49:36.195033   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 13/40
                I0110 12:49:39.206066   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 14/40
                I0110 12:49:42.218168   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 15/40
                I0110 12:49:45.229047   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 16/40
                I0110 12:49:48.241391   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Waiting for machine to come up 17/40
                I0110 12:49:51.257904   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Found IP for machine: 192.168.39.38
                I0110 12:49:51.257938   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Waiting for SSH to be available...
                I0110 12:49:51.257969   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Getting to WaitForSSH function...
                I0110 12:49:51.272845   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Using SSH client type: external
                I0110 12:49:51.272888   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Using SSH private key: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968/id_rsa (-rw-------)
                I0110 12:49:51.272953   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | &{[-F /dev/null -o ConnectionAttempts=3 -o ConnectTimeout=10 -o ControlMaster=no -o ControlPath=none -o LogLevel=quiet -o PasswordAuthentication=no -o ServerAliveInterval=60 -o StrictHostKeyChecking=no -o UserKnownHostsFile=/dev/null docker@192.168.39.38 -o IdentitiesOnly=yes -i /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/newest-cni-20200110T124845.195538591-4968/id_rsa -p 22] /usr/bin/ssh <nil>}
                I0110 12:49:51.272979   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | About to run SSH command:
                I0110 12:49:51.273000   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | exit 0
                I0110 12:49:51.514411   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | SSH cmd err, output: <nil>: 
                I0110 12:49:51.515660   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) KVM machine creation complete!
                I0110 12:49:51.515736   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetConfigRaw
                I0110 12:49:51.516701   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:49:51.517015   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:49:51.517369   10292 main.go:110] libmachine: Waiting for machine to be running, this may take a few minutes...
                I0110 12:49:51.517412   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetState
                I0110 12:49:51.530512   10292 main.go:110] libmachine: Detecting operating system of created instance...
                I0110 12:49:51.530547   10292 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:49:51.530561   10292 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:49:51.530577   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:51.544417   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:51.546154   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:51.546565   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:51.546793   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:51.547040   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:51.547329   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:51.547351   10292 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:49:51.910295   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:49:51.910337   10292 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:49:51.910356   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:51.923648   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:51.923941   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:51.924204   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:51.924443   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:51.924726   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:51.924956   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:51.924983   10292 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:49:52.087888   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:49:52.088028   10292 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:49:52.088070   10292 main.go:110] libmachine: Provisioning with buildroot...
                I0110 12:49:52.088135   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetMachineName
                I0110 12:49:52.088461   10292 main.go:110] libmachine: setting hostname "newest-cni-20200110T124845.195538591-4968"
                I0110 12:49:52.088487   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetMachineName
                I0110 12:49:52.088711   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:52.099050   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:52.099289   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:52.099481   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:52.099682   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:52.099900   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:52.100245   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:52.100279   10292 main.go:110] libmachine: About to run SSH command:
                sudo hostname newest-cni-20200110T124845.195538591-4968 && echo "newest-cni-20200110T124845.195538591-4968" | sudo tee /etc/hostname
                I0110 12:49:52.316900   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: newest-cni-20200110T124845.195538591-4968
                
                I0110 12:49:52.316947   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:52.328356   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:52.328611   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:52.328841   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:52.329063   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:52.329320   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:52.329563   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:52.329602   10292 main.go:110] libmachine: About to run SSH command:
                
                		if ! grep -xq '.*\snewest-cni-20200110T124845.195538591-4968' /etc/hosts; then
                			if grep -xq '127.0.1.1\s.*' /etc/hosts; then
                				sudo sed -i 's/^127.0.1.1\s.*/127.0.1.1 newest-cni-20200110T124845.195538591-4968/g' /etc/hosts;
                			else 
                				echo '127.0.1.1 newest-cni-20200110T124845.195538591-4968' | sudo tee -a /etc/hosts; 
                			fi
                		fi
                I0110 12:49:52.520569   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:49:52.520700   10292 main.go:110] libmachine: set auth options {CertDir:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube CaCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem CaPrivateKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem CaCertRemotePath:/etc/docker/ca.pem ServerCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ServerKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server-key.pem ClientKeyPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/key.pem ServerCertRemotePath:/etc/docker/server.pem ServerKeyRemotePath:/etc/docker/server-key.pem ClientCertPath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/cert.pem ServerCertSANs:[] StorePath:/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube}
                I0110 12:49:52.520715   10292 main.go:110] libmachine: setting up certificates
                I0110 12:49:52.520736   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetMachineName
                I0110 12:49:52.521061   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetIP
                I0110 12:49:52.580922   10292 main.go:110] libmachine: generating server cert: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/machines/server.pem ca-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca.pem private-key=/home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/certs/ca-key.pem org=jenkins.newest-cni-20200110T124845.195538591-4968 san=[192.168.39.38 localhost]
                I0110 12:49:52.846068   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:52.862717   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:52.862911   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:52.863047   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:53.036002   10292 ssh_runner.go:156] Checked if /etc/docker/server.pem exists, but got error: Process exited with status 1
                I0110 12:49:53.037375   10292 ssh_runner.go:175] Transferring 1159 bytes to /etc/docker/server.pem
                I0110 12:49:53.042432   10292 ssh_runner.go:194] server.pem: copied 1159 bytes
                I0110 12:49:53.121540   10292 ssh_runner.go:156] Checked if /etc/docker/server-key.pem exists, but got error: Process exited with status 1
                I0110 12:49:53.122417   10292 ssh_runner.go:175] Transferring 1675 bytes to /etc/docker/server-key.pem
                I0110 12:49:53.125740   10292 ssh_runner.go:194] server-key.pem: copied 1675 bytes
                I0110 12:49:53.180635   10292 ssh_runner.go:156] Checked if /etc/docker/ca.pem exists, but got error: Process exited with status 1
                I0110 12:49:53.181330   10292 ssh_runner.go:175] Transferring 1038 bytes to /etc/docker/ca.pem
                I0110 12:49:53.182876   10292 ssh_runner.go:194] ca.pem: copied 1038 bytes
                I0110 12:49:53.218081   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetMachineName
                I0110 12:49:53.218650   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:49:53.218851   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:53.244357   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:53.244676   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.244951   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.245206   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:53.245545   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:53.245775   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:53.245794   10292 main.go:110] libmachine: About to run SSH command:
                df --output=fstype / | tail -n 1
                I0110 12:49:53.491902   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: tmpfs
                
                I0110 12:49:53.491938   10292 main.go:110] libmachine: root file system type: tmpfs
                I0110 12:49:53.492190   10292 main.go:110] libmachine: Setting Docker configuration on the remote daemon...
                I0110 12:49:53.492219   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:53.512294   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:53.513518   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.517471   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.517772   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:53.518468   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:53.518945   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:53.519121   10292 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /lib/systemd/system && printf %s "[Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP $MAINPID
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                " | sudo tee /lib/systemd/system/docker.service
                I0110 12:49:53.837273   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: [Unit]
                Description=Docker Application Container Engine
                Documentation=https://docs.docker.com
                After=network.target  minikube-automount.service docker.socket
                Requires= minikube-automount.service docker.socket 
                
                [Service]
                Type=notify
                
                
                
                # This file is a systemd drop-in unit that inherits from the base dockerd configuration.
                # The base configuration already specifies an 'ExecStart=...' command. The first directive
                # here is to clear out that command inherited from the base configuration. Without this,
                # the command from the base configuration and the command specified here are treated as
                # a sequence of commands, which is not the desired behavior, nor is it valid -- systemd
                # will catch this invalid input and refuse to start the service with an error like:
                #  Service has more than one ExecStart= setting, which is only allowed for Type=oneshot services.
                
                # NOTE: default-ulimit=nofile is set to an arbitrary number for consistency with other
                # container runtimes. If left unlimited, it may result in OOM issues with MySQL.
                ExecStart=
                ExecStart=/usr/bin/dockerd -H tcp://0.0.0.0:2376 -H unix:///var/run/docker.sock --default-ulimit=nofile=1048576:1048576 --tlsverify --tlscacert /etc/docker/ca.pem --tlscert /etc/docker/server.pem --tlskey /etc/docker/server-key.pem --label provider=kvm2 --insecure-registry 10.96.0.0/12 
                ExecReload=/bin/kill -s HUP 
                
                # Having non-zero Limit*s causes performance problems due to accounting overhead
                # in the kernel. We recommend using cgroups to do container-local accounting.
                LimitNOFILE=infinity
                LimitNPROC=infinity
                LimitCORE=infinity
                
                # Uncomment TasksMax if your systemd version supports it.
                # Only systemd 226 and above support this version.
                TasksMax=infinity
                TimeoutStartSec=0
                
                # set delegate yes so that systemd does not reset the cgroups of docker containers
                Delegate=yes
                
                # kill only the docker process, not all processes in the cgroup
                KillMode=process
                
                [Install]
                WantedBy=multi-user.target
                
                I0110 12:49:53.837327   10292 main.go:110] libmachine: setting minikube options for container-runtime
                I0110 12:49:53.837480   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:53.858004   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:53.858364   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.858628   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:53.858907   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:53.859251   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:53.859527   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:53.859569   10292 main.go:110] libmachine: About to run SSH command:
                sudo mkdir -p /etc/sysconfig && printf %s "
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                " | sudo tee /etc/sysconfig/crio.minikube
                I0110 12:49:54.226465   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                CRIO_MINIKUBE_OPTIONS='--insecure-registry 10.96.0.0/12 '
                
                I0110 12:49:54.226501   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:54.249553   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:54.249896   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:54.250100   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:54.250300   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:54.250754   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:54.251197   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:54.251224   10292 main.go:110] libmachine: About to run SSH command:
                sudo systemctl daemon-reload
                I0110 12:49:54.778963   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:49:54.779002   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:49:54.791285   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:49:54.791566   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:54.791830   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:49:54.792050   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:49:54.792384   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:49:54.792654   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:49:54.792680   10292 main.go:110] libmachine: About to run SSH command:
                sudo systemctl -f restart crio
                I0110 12:50:02.297542   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:50:02.297578   10292 main.go:110] libmachine: Checking connection to Docker...
                I0110 12:50:02.297597   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetURL
                I0110 12:50:02.309964   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Using libvirt version 3000000
                I0110 12:50:02.326067   10292 main.go:110] libmachine: Docker is up and running!
                I0110 12:50:02.326100   10292 main.go:110] libmachine: Reticulating splines...
                I0110 12:50:02.326131   10292 main.go:110] libmachine: Waiting for SSH to be available...
                I0110 12:50:02.326148   10292 main.go:110] libmachine: Getting to WaitForSSH function...
                I0110 12:50:02.326166   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:50:02.347518   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:50:02.347822   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.348089   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.348312   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:50:02.348565   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:50:02.348893   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:50:02.348921   10292 main.go:110] libmachine: About to run SSH command:
                exit 0
                I0110 12:50:02.605974   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 
                I0110 12:50:02.606006   10292 main.go:110] libmachine: Detecting the provisioner...
                I0110 12:50:02.606024   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:50:02.625397   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:50:02.625693   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.625953   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.626146   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:50:02.626409   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:50:02.626656   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:50:02.626696   10292 main.go:110] libmachine: About to run SSH command:
                cat /etc/os-release
                I0110 12:50:02.809956   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: NAME=Buildroot
                VERSION=2019.02.7
                ID=buildroot
                VERSION_ID=2019.02.7
                PRETTY_NAME="Buildroot 2019.02.7"
                
                I0110 12:50:02.810033   10292 main.go:110] libmachine: found compatible host: buildroot
                I0110 12:50:02.810046   10292 cluster.go:418] Provisioned with Buildroot 2019.02.7
                I0110 12:50:02.810072   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:50:02.823174   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:50:02.823412   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.823650   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:02.823849   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:50:02.824160   10292 main.go:110] libmachine: Using SSH client type: native
                I0110 12:50:02.824417   10292 main.go:110] libmachine: &{{{<nil> 0 [] [] []} docker [0x7b6460] 0x7b6430 <nil>  [] 0s} 192.168.39.38 22 <nil> <nil>}
                I0110 12:50:02.824442   10292 main.go:110] libmachine: About to run SSH command:
                date +%s.%N
                I0110 12:50:02.977922   10292 main.go:110] libmachine: SSH cmd err, output: <nil>: 1578660602.706473102
                
                I0110 12:50:02.977953   10292 cluster.go:197] guest clock: 1578660602.706473102
                I0110 12:50:02.977969   10292 cluster.go:210] Guest: 2020-01-10 12:50:02.706473102 +0000 UTC Remote: 2020-01-10 12:50:02.810050434 +0000 UTC m=+77.610647364 (delta=-103.577332ms)
                I0110 12:50:02.978002   10292 cluster.go:181] guest clock delta is within tolerance: -103.577332ms
                I0110 12:50:02.978037   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetConfigRaw
                I0110 12:50:02.979115   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:02.979338   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:02.979552   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:50:03.005698   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:50:03.006021   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:03.006264   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:50:03.065351   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetIP
                I0110 12:50:03.077223   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:03.077469   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:03.078263   10292 ssh_runner.go:102] Run: nslookup kubernetes.io
                I0110 12:50:03.131103   10292 ssh_runner.go:102] Run: curl -sS https://k8s.gcr.io/
                I0110 12:50:03.161780   10292 profile.go:89] Saving config to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/profiles/newest-cni-20200110T124845.195538591-4968/config.json ...
                I0110 12:50:03.162137   10292 ssh_runner.go:102] Run: systemctl is-active --quiet service containerd
                I0110 12:50:03.177620   10292 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:50:03.189253   10292 ssh_runner.go:102] Run: sudo systemctl stop crio
                I0110 12:50:03.336326   10292 ssh_runner.go:102] Run: systemctl is-active --quiet service crio
                I0110 12:50:03.358092   10292 ssh_runner.go:102] Run: sudo systemctl start docker
                I0110 12:50:06.489477   10292 ssh_runner.go:142] Completed: sudo systemctl start docker: (3.131336556s)
                I0110 12:50:06.489564   10292 ssh_runner.go:102] Run: docker version --format '{{.Server.Version}}'
                I0110 12:50:07.210172   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetURL
                I0110 12:50:07.216029   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) DBG | Using libvirt version 3000000
                I0110 12:50:07.227320   10292 settings.go:123] acquiring lock: {Name:mk1d872a787294bed5ed9e2e7affd8eca10d910a Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:07.227468   10292 settings.go:131] Updating kubeconfig:  /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig
                I0110 12:50:07.238798   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/kubeconfig: {Name:mk5b24163af42247397a344b523163e1e0399b1b Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:50:07.239784   10292 main.go:110] libmachine: Found binary path at /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/bin/docker-machine-driver-kvm2
                I0110 12:50:07.239957   10292 main.go:110] libmachine: Launching plugin server for driver kvm2
                I0110 12:50:08.054413   10292 main.go:110] libmachine: Plugin server listening at address 127.0.0.1:33107
                I0110 12:50:08.055359   10292 main.go:110] libmachine: () Calling .GetVersion
                I0110 12:50:08.056181   10292 main.go:110] libmachine: Using API Version  1
                I0110 12:50:08.056206   10292 main.go:110] libmachine: () Calling .SetConfigRaw
                I0110 12:50:08.056755   10292 main.go:110] libmachine: () Calling .GetMachineName
                I0110 12:50:08.061542   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:08.061809   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .DriverName
                I0110 12:50:08.062053   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHHostname
                I0110 12:50:08.074598   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHPort
                I0110 12:50:08.074864   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHKeyPath
                I0110 12:50:08.075086   10292 main.go:110] libmachine: (newest-cni-20200110T124845.195538591-4968) Calling .GetSSHUsername
                I0110 12:50:08.133696   10292 cache_images.go:65] LoadImages start: [k8s.gcr.io/kube-proxy:v1.17.0 k8s.gcr.io/kube-scheduler:v1.17.0 k8s.gcr.io/kube-controller-manager:v1.17.0 k8s.gcr.io/kube-apiserver:v1.17.0 k8s.gcr.io/coredns:1.6.5 k8s.gcr.io/etcd:3.4.3-0 k8s.gcr.io/pause:3.1 k8s.gcr.io/kube-addon-manager:v9.0.2 gcr.io/k8s-minikube/storage-provisioner:v1.8.1 kubernetesui/dashboard:v2.0.0-beta8 kubernetesui/metrics-scraper:v1.0.2]
                I0110 12:50:08.210020   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/dashboard:v2.0.0-beta8
                I0110 12:50:08.252578   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/etcd:3.4.3-0
                I0110 12:50:08.262903   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/pause:3.1
                I0110 12:50:08.279806   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' gcr.io/k8s-minikube/storage-provisioner:v1.8.1
                I0110 12:50:08.285677   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-scheduler:v1.17.0
                I0110 12:50:08.289507   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-controller-manager:v1.17.0
                I0110 12:50:08.291324   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-apiserver:v1.17.0
                I0110 12:50:08.309630   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-addon-manager:v9.0.2
                I0110 12:50:08.316602   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/coredns:1.6.5
                I0110 12:50:08.348928   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-proxy:v1.17.0
                I0110 12:50:08.380226   10292 ssh_runner.go:102] Run: docker inspect --format='{{.Id}}' kubernetesui/metrics-scraper:v1.0.2
                I0110 12:50:08.969459   10292 cache_images.go:86] "kubernetesui/dashboard:v2.0.0-beta8" needs transfer: "kubernetesui/dashboard:v2.0.0-beta8" does not exist at hash "sha256:eb51a359752560a66f314602e87155b75f428fb838bf951079ff1f9621958c0c" in container runtime
                I0110 12:50:08.969508   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8
                I0110 12:50:09.165409   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/dashboard_v2.0.0-beta8 exists, but got error: Process exited with status 1
                I0110 12:50:09.169342   10292 ssh_runner.go:175] Transferring 41433088 bytes to /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:50:10.138908   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/etcd:3.4.3-0: (1.88627428s)
                I0110 12:50:10.138970   10292 cache_images.go:86] "k8s.gcr.io/etcd:3.4.3-0" needs transfer: "k8s.gcr.io/etcd:3.4.3-0" does not exist at hash "sha256:303ce5db0e90dab1c5728ec70d21091201a23cdf8aeca70ab54943bbaaf0833f" in container runtime
                I0110 12:50:10.139011   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0
                I0110 12:50:10.139218   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/pause:3.1: (1.876286646s)
                I0110 12:50:10.139268   10292 cache_images.go:86] "k8s.gcr.io/pause:3.1" needs transfer: "k8s.gcr.io/pause:3.1" does not exist at hash "sha256:da86e6ba6ca197bf6bc5e9d900febd906b133eaa4750e6bed647b0fbe50ed43e" in container runtime
                I0110 12:50:10.139286   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1
                I0110 12:50:10.152107   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-apiserver:v1.17.0: (1.860748092s)
                I0110 12:50:10.152128   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-controller-manager:v1.17.0: (1.862594857s)
                I0110 12:50:10.152167   10292 cache_images.go:86] "k8s.gcr.io/kube-apiserver:v1.17.0" needs transfer: "k8s.gcr.io/kube-apiserver:v1.17.0" does not exist at hash "sha256:0cae8d5cc64c7d8fbdf73ee2be36c77fdabd9e0c7d30da0c12aedf402730bbb2" in container runtime
                I0110 12:50:10.152185   10292 cache_images.go:86] "k8s.gcr.io/kube-controller-manager:v1.17.0" needs transfer: "k8s.gcr.io/kube-controller-manager:v1.17.0" does not exist at hash "sha256:5eb3b7486872441e0943f6e14e9dd5cc1c70bc3047efacbc43d1aa9b7d5b3056" in container runtime
                I0110 12:50:10.152193   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0
                I0110 12:50:10.152201   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0
                I0110 12:50:10.152937   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-scheduler:v1.17.0: (1.867230506s)
                I0110 12:50:10.152975   10292 cache_images.go:86] "k8s.gcr.io/kube-scheduler:v1.17.0" needs transfer: "k8s.gcr.io/kube-scheduler:v1.17.0" does not exist at hash "sha256:78c190f736b115876724580513fdf37fa4c3984559dc9e90372b11c21b9cad28" in container runtime
                I0110 12:50:10.152993   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0
                I0110 12:50:10.216457   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-addon-manager:v9.0.2: (1.906778714s)
                I0110 12:50:10.216530   10292 cache_images.go:86] "k8s.gcr.io/kube-addon-manager:v9.0.2" needs transfer: "k8s.gcr.io/kube-addon-manager:v9.0.2" does not exist at hash "sha256:bd12a212f9dcbafe64323774c6b937dec3099d65f39a8d29896cf0d1d0c906cf" in container runtime
                I0110 12:50:10.216555   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2
                I0110 12:50:10.238905   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' gcr.io/k8s-minikube/storage-provisioner:v1.8.1: (1.959036907s)
                I0110 12:50:10.238976   10292 cache_images.go:86] "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" needs transfer: "gcr.io/k8s-minikube/storage-provisioner:v1.8.1" does not exist at hash "sha256:4689081edb103a9e8174bf23a255bfbe0b2d9ed82edc907abab6989d1c60f02c" in container runtime
                I0110 12:50:10.239000   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1
                I0110 12:50:10.294322   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/coredns:1.6.5: (1.977680028s)
                I0110 12:50:10.294384   10292 cache_images.go:86] "k8s.gcr.io/coredns:1.6.5" needs transfer: "k8s.gcr.io/coredns:1.6.5" does not exist at hash "sha256:70f311871ae12c14bd0e02028f249f933f925e4370744e4e35f706da773a8f61" in container runtime
                I0110 12:50:10.294405   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5
                I0110 12:50:10.294644   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/pause_3.1 exists, but got error: Process exited with status 1
                I0110 12:50:10.294697   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/etcd_3.4.3-0 exists, but got error: Process exited with status 1
                I0110 12:50:10.315357   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-controller-manager_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:50:10.315462   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' k8s.gcr.io/kube-proxy:v1.17.0: (1.966491344s)
                I0110 12:50:10.315498   10292 cache_images.go:86] "k8s.gcr.io/kube-proxy:v1.17.0" needs transfer: "k8s.gcr.io/kube-proxy:v1.17.0" does not exist at hash "sha256:7d54289267dc5a115f940e8b1ea5c20483a5da5ae5bb3ad80107409ed1400f19" in container runtime
                I0110 12:50:10.315523   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0
                I0110 12:50:10.315631   10292 ssh_runner.go:142] Completed: docker inspect --format='{{.Id}}' kubernetesui/metrics-scraper:v1.0.2: (1.935372552s)
                I0110 12:50:10.315654   10292 cache_images.go:86] "kubernetesui/metrics-scraper:v1.0.2" needs transfer: "kubernetesui/metrics-scraper:v1.0.2" does not exist at hash "sha256:3b08661dc379d9f80155be9d658f71578988640357ebae1aab287d6954c723d1" in container runtime
                I0110 12:50:10.315666   10292 cache_images.go:172] Loading image from cache: /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2
                I0110 12:50:10.317581   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-apiserver_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:50:10.317653   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-scheduler_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:50:10.328979   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-addon-manager_v9.0.2 exists, but got error: Process exited with status 1
                I0110 12:50:10.336111   10292 ssh_runner.go:175] Transferring 37993472 bytes to /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:50:10.336314   10292 ssh_runner.go:175] Transferring 356864 bytes to /var/lib/minikube/images/pause_3.1
                I0110 12:50:10.336383   10292 ssh_runner.go:175] Transferring 114172928 bytes to /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:50:10.336449   10292 ssh_runner.go:175] Transferring 56059392 bytes to /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:50:10.336587   10292 ssh_runner.go:175] Transferring 58209280 bytes to /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:50:10.347502   10292 ssh_runner.go:175] Transferring 34298880 bytes to /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:50:10.391433   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/storage-provisioner_v1.8.1 exists, but got error: Process exited with status 1
                I0110 12:50:10.398977   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/kube-proxy_v1.17.0 exists, but got error: Process exited with status 1
                I0110 12:50:10.404502   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/coredns_1.6.5 exists, but got error: Process exited with status 1
                I0110 12:50:10.449977   10292 ssh_runner.go:156] Checked if /var/lib/minikube/images/metrics-scraper_v1.0.2 exists, but got error: Process exited with status 1
                I0110 12:50:10.456188   10292 ssh_runner.go:175] Transferring 24434688 bytes to /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:50:10.456706   10292 ssh_runner.go:194] pause_3.1: copied 356864 bytes
                I0110 12:50:10.471459   10292 ssh_runner.go:175] Transferring 15187456 bytes to /var/lib/minikube/images/coredns_1.6.5
                I0110 12:50:10.471590   10292 ssh_runner.go:175] Transferring 53322240 bytes to /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:50:10.472853   10292 ssh_runner.go:175] Transferring 17549824 bytes to /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:50:10.511132   10292 docker.go:121] Loading image: /var/lib/minikube/images/pause_3.1
                I0110 12:50:10.511218   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/pause_3.1
                I0110 12:50:12.352179   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/pause_3.1: (1.840922349s)
                I0110 12:50:12.352225   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/pause_3.1 from cache
                I0110 12:50:13.533742   10292 ssh_runner.go:194] coredns_1.6.5: copied 15187456 bytes
                I0110 12:50:13.710864   10292 docker.go:121] Loading image: /var/lib/minikube/images/coredns_1.6.5
                I0110 12:50:13.710967   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/coredns_1.6.5
                I0110 12:50:13.833134   10292 ssh_runner.go:194] metrics-scraper_v1.0.2: copied 17549824 bytes
                I0110 12:50:14.500617   10292 ssh_runner.go:194] storage-provisioner_v1.8.1: copied 24434688 bytes
                I0110 12:50:15.328076   10292 ssh_runner.go:194] dashboard_v2.0.0-beta8: copied 41433088 bytes
                I0110 12:50:15.594762   10292 ssh_runner.go:194] kube-addon-manager_v9.0.2: copied 34298880 bytes
                I0110 12:50:15.594855   10292 ssh_runner.go:194] kube-scheduler_v1.17.0: copied 37993472 bytes
                I0110 12:50:16.467375   10292 ssh_runner.go:194] kube-apiserver_v1.17.0: copied 58209280 bytes
                I0110 12:50:16.475479   10292 ssh_runner.go:194] kube-proxy_v1.17.0: copied 53322240 bytes
                I0110 12:50:16.585102   10292 ssh_runner.go:194] kube-controller-manager_v1.17.0: copied 56059392 bytes
                I0110 12:50:17.206387   10292 ssh_runner.go:194] etcd_3.4.3-0: copied 114172928 bytes
                I0110 12:50:21.933037   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/coredns_1.6.5: (8.222032631s)
                I0110 12:50:21.933076   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/coredns_1.6.5 from cache
                I0110 12:50:21.933111   10292 docker.go:121] Loading image: /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:50:21.933200   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2
                I0110 12:50:27.411214   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/metrics-scraper_v1.0.2: (5.477953776s)
                I0110 12:50:27.411255   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/metrics-scraper_v1.0.2 from cache
                I0110 12:50:27.411273   10292 docker.go:121] Loading image: /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:50:27.411332   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1
                I0110 12:50:33.228735   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/storage-provisioner_v1.8.1: (5.817363163s)
                I0110 12:50:33.228778   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/gcr.io/k8s-minikube/storage-provisioner_v1.8.1 from cache
                I0110 12:50:33.228800   10292 docker.go:121] Loading image: /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:50:33.228875   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8
                I0110 12:50:40.029280   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/dashboard_v2.0.0-beta8: (6.80036735s)
                I0110 12:50:40.029318   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/kubernetesui/dashboard_v2.0.0-beta8 from cache
                I0110 12:50:40.029350   10292 docker.go:121] Loading image: /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:50:40.029404   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0
                I0110 12:50:46.903244   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-scheduler_v1.17.0: (6.873811704s)
                I0110 12:50:46.903279   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-scheduler_v1.17.0 from cache
                I0110 12:50:46.903294   10292 docker.go:121] Loading image: /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:50:46.903357   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2
                I0110 12:50:54.516539   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-addon-manager_v9.0.2: (7.613148757s)
                I0110 12:50:54.516589   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-addon-manager_v9.0.2 from cache
                I0110 12:50:54.516608   10292 docker.go:121] Loading image: /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:50:54.516681   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0
                I0110 12:51:05.164957   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-proxy_v1.17.0: (10.648234862s)
                I0110 12:51:05.165004   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-proxy_v1.17.0 from cache
                I0110 12:51:05.165030   10292 docker.go:121] Loading image: /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:51:05.165121   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0
                I0110 12:51:11.225277   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-apiserver_v1.17.0: (6.060116355s)
                I0110 12:51:11.225332   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-apiserver_v1.17.0 from cache
                I0110 12:51:11.225347   10292 docker.go:121] Loading image: /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:51:11.225403   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0
                I0110 12:51:18.739282   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/kube-controller-manager_v1.17.0: (7.513843795s)
                I0110 12:51:18.739327   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/kube-controller-manager_v1.17.0 from cache
                I0110 12:51:18.739354   10292 docker.go:121] Loading image: /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:51:18.739430   10292 ssh_runner.go:102] Run: docker load -i /var/lib/minikube/images/etcd_3.4.3-0
                I0110 12:51:28.500633   10292 ssh_runner.go:142] Completed: docker load -i /var/lib/minikube/images/etcd_3.4.3-0: (9.761109869s)
                I0110 12:51:28.500681   10292 cache_images.go:194] Transferred and loaded /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/cache/images/k8s.gcr.io/etcd_3.4.3-0 from cache
                I0110 12:51:28.500703   10292 cache_images.go:93] Successfully loaded all cached images
                I0110 12:51:28.500717   10292 cache_images.go:94] LoadImages end
                I0110 12:51:28.500980   10292 kubeadm.go:390] kubelet [Unit]
                Wants=docker.socket
                
                [Service]
                ExecStart=
                ExecStart=/var/lib/minikube/binaries/v1.17.0/kubelet --authorization-mode=Webhook --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --cgroup-driver=cgroupfs --client-ca-file=/var/lib/minikube/certs/ca.crt --cluster-dns=10.96.0.10 --cluster-domain=cluster.local --config=/var/lib/kubelet/config.yaml --container-runtime=docker --fail-swap-on=false --feature-gates=ServerSideApply=true --hostname-override=minikube --kubeconfig=/etc/kubernetes/kubelet.conf --network-plugin=cni --node-ip=192.168.39.38 --pod-manifest-path=/etc/kubernetes/manifests
                
                [Install]
                 config:
                {KubernetesVersion:v1.17.0 NodeIP:192.168.39.38 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates:ServerSideApply=true ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[{Component:kubelet Key:network-plugin Value:cni} {Component:kubeadm Key:pod-network-cidr Value:192.168.111.111/16}] ShouldLoadCachedImages:true EnableDefaultCNI:false}
                I0110 12:51:28.501030   10292 ssh_runner.go:102] Run: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet"
                W0110 12:51:28.521444   10292 kubeadm.go:395] unable to stop kubelet: /bin/bash -c "pgrep kubelet && sudo systemctl stop kubelet": Process exited with status 1
                stdout:
                
                stderr:
                 command: "/bin/bash -c \"pgrep kubelet && sudo systemctl stop kubelet\"" output: ""
                I0110 12:51:28.539456   10292 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubeadm
                I0110 12:51:28.539466   10292 cache_binaries.go:74] Not caching binary, using https://storage.googleapis.com/kubernetes-release/release/v1.17.0/bin/linux/amd64/kubelet
                I0110 12:51:28.587444   10292 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubeadm exists, but got error: Process exited with status 1
                I0110 12:51:28.588099   10292 ssh_runner.go:175] Transferring 39342080 bytes to /var/lib/minikube/binaries/v1.17.0/kubeadm
                I0110 12:51:28.588118   10292 ssh_runner.go:156] Checked if /var/lib/minikube/binaries/v1.17.0/kubelet exists, but got error: Process exited with status 1
                I0110 12:51:28.589673   10292 ssh_runner.go:175] Transferring 111560216 bytes to /var/lib/minikube/binaries/v1.17.0/kubelet
                I0110 12:51:29.225286   10292 ssh_runner.go:194] kubeadm: copied 39342080 bytes
                I0110 12:51:29.784447   10292 ssh_runner.go:194] kubelet: copied 111560216 bytes
                I0110 12:51:29.803652   10292 ssh_runner.go:175] Transferring 1333 bytes to /var/tmp/minikube/kubeadm.yaml
                I0110 12:51:29.805141   10292 ssh_runner.go:194] kubeadm.yaml: copied 1333 bytes
                I0110 12:51:29.826641   10292 ssh_runner.go:175] Transferring 618 bytes to /etc/systemd/system/kubelet.service.d/10-kubeadm.conf
                I0110 12:51:29.827856   10292 ssh_runner.go:194] 10-kubeadm.conf: copied 618 bytes
                I0110 12:51:29.846249   10292 ssh_runner.go:175] Transferring 349 bytes to /lib/systemd/system/kubelet.service
                I0110 12:51:29.847203   10292 ssh_runner.go:194] kubelet.service: copied 349 bytes
                I0110 12:51:29.873582   10292 ssh_runner.go:156] Checked if /etc/sync.test exists, but got error: Process exited with status 1
                I0110 12:51:29.874107   10292 ssh_runner.go:175] Transferring 40 bytes to /etc/sync.test
                I0110 12:51:29.875065   10292 ssh_runner.go:194] sync.test: copied 40 bytes
                I0110 12:51:29.893803   10292 ssh_runner.go:175] Transferring 271 bytes to /etc/kubernetes/addons/storageclass.yaml
                I0110 12:51:29.895139   10292 ssh_runner.go:194] storageclass.yaml: copied 271 bytes
                I0110 12:51:29.919419   10292 ssh_runner.go:175] Transferring 1709 bytes to /etc/kubernetes/addons/storage-provisioner.yaml
                I0110 12:51:29.920675   10292 ssh_runner.go:194] storage-provisioner.yaml: copied 1709 bytes
                I0110 12:51:29.942106   10292 ssh_runner.go:175] Transferring 6353 bytes to /etc/kubernetes/addons/istio-operator.yaml
                I0110 12:51:29.943360   10292 ssh_runner.go:194] istio-operator.yaml: copied 6353 bytes
                I0110 12:51:29.964032   10292 ssh_runner.go:175] Transferring 1631 bytes to /etc/kubernetes/manifests/addon-manager.yaml.tmpl
                I0110 12:51:29.965163   10292 ssh_runner.go:194] addon-manager.yaml.tmpl: copied 1631 bytes
                I0110 12:51:29.985314   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo systemctl daemon-reload && sudo systemctl start kubelet"
                I0110 12:51:30.170504   10292 certs.go:66] Setting up /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube for IP: 192.168.39.38
                I0110 12:51:30.170552   10292 certs.go:75] acquiring lock: {Name:mk6262a3a4626ef840bf74a96a44970cb9c4d619 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.170800   10292 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt with IP's: []
                I0110 12:51:30.175796   10292 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt ...
                I0110 12:51:30.175825   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.crt: {Name:mka829eb362d1b2205a7f12a2f3788ff1c5ee17c Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.176085   10292 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key ...
                I0110 12:51:30.176105   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/client.key: {Name:mk89a479085124febebe3d46d8cdb5738867e06e Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.176258   10292 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt with IP's: [192.168.39.38 10.96.0.1 127.0.0.1 10.0.0.1]
                I0110 12:51:30.179419   10292 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt ...
                I0110 12:51:30.179455   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.crt: {Name:mk71952ab2b690b9f05a0da8ded32940faf38276 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.179660   10292 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key ...
                I0110 12:51:30.179683   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/apiserver.key: {Name:mk2aca34ed793d6b97cc016bcff12840308bad1d Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.179878   10292 crypto.go:69] Generating cert /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt with IP's: []
                I0110 12:51:30.182929   10292 crypto.go:157] Writing cert to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt ...
                I0110 12:51:30.182967   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.crt: {Name:mk5d4780057ebc79335e99975966d6e61c6d6c60 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.183143   10292 crypto.go:165] Writing key to /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key ...
                I0110 12:51:30.183164   10292 lock.go:35] WriteFile acquiring /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/.minikube/proxy-client.key: {Name:mk70c31cfb4bb77f4ee650567c6f36a6d2aa0d31 Clock:{} Delay:500ms Timeout:1m0s Cancel:<nil>}
                I0110 12:51:30.208858   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.crt exists, but got error: Process exited with status 1
                I0110 12:51:30.209911   10292 ssh_runner.go:175] Transferring 1066 bytes to /var/lib/minikube/certs/ca.crt
                I0110 12:51:30.212792   10292 ssh_runner.go:194] ca.crt: copied 1066 bytes
                I0110 12:51:30.263694   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/ca.key exists, but got error: Process exited with status 1
                I0110 12:51:30.264416   10292 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/ca.key
                I0110 12:51:30.265383   10292 ssh_runner.go:194] ca.key: copied 1675 bytes
                I0110 12:51:30.295202   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.crt exists, but got error: Process exited with status 1
                I0110 12:51:30.295852   10292 ssh_runner.go:175] Transferring 1306 bytes to /var/lib/minikube/certs/apiserver.crt
                I0110 12:51:30.297290   10292 ssh_runner.go:194] apiserver.crt: copied 1306 bytes
                I0110 12:51:30.337038   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/apiserver.key exists, but got error: Process exited with status 1
                I0110 12:51:30.337873   10292 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/apiserver.key
                I0110 12:51:30.339336   10292 ssh_runner.go:194] apiserver.key: copied 1679 bytes
                I0110 12:51:30.401267   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.crt exists, but got error: Process exited with status 1
                I0110 12:51:30.401976   10292 ssh_runner.go:175] Transferring 1074 bytes to /var/lib/minikube/certs/proxy-client-ca.crt
                I0110 12:51:30.403726   10292 ssh_runner.go:194] proxy-client-ca.crt: copied 1074 bytes
                I0110 12:51:30.450020   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client-ca.key exists, but got error: Process exited with status 1
                I0110 12:51:30.450519   10292 ssh_runner.go:175] Transferring 1679 bytes to /var/lib/minikube/certs/proxy-client-ca.key
                I0110 12:51:30.451334   10292 ssh_runner.go:194] proxy-client-ca.key: copied 1679 bytes
                I0110 12:51:30.485069   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.crt exists, but got error: Process exited with status 1
                I0110 12:51:30.490306   10292 ssh_runner.go:175] Transferring 1103 bytes to /var/lib/minikube/certs/proxy-client.crt
                I0110 12:51:30.492038   10292 ssh_runner.go:194] proxy-client.crt: copied 1103 bytes
                I0110 12:51:30.528134   10292 ssh_runner.go:156] Checked if /var/lib/minikube/certs/proxy-client.key exists, but got error: Process exited with status 1
                I0110 12:51:30.528595   10292 ssh_runner.go:175] Transferring 1675 bytes to /var/lib/minikube/certs/proxy-client.key
                I0110 12:51:30.530077   10292 ssh_runner.go:194] proxy-client.key: copied 1675 bytes
                I0110 12:51:30.568196   10292 ssh_runner.go:156] Checked if /usr/share/ca-certificates/minikubeCA.pem exists, but got error: Process exited with status 1
                I0110 12:51:30.568656   10292 ssh_runner.go:175] Transferring 1066 bytes to /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:51:30.569814   10292 ssh_runner.go:194] minikubeCA.pem: copied 1066 bytes
                I0110 12:51:30.592630   10292 ssh_runner.go:175] Transferring 428 bytes to /var/lib/minikube/kubeconfig
                I0110 12:51:30.593442   10292 ssh_runner.go:194] kubeconfig: copied 428 bytes
                I0110 12:51:30.615013   10292 ssh_runner.go:102] Run: openssl version
                I0110 12:51:30.631637   10292 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/minikubeCA.pem
                I0110 12:51:30.643906   10292 ssh_runner.go:102] Run: sudo ln -s /usr/share/ca-certificates/minikubeCA.pem /etc/ssl/certs/minikubeCA.pem
                I0110 12:51:30.655153   10292 ssh_runner.go:102] Run: openssl x509 -hash -noout -in /usr/share/ca-certificates/minikubeCA.pem
                I0110 12:51:30.691024   10292 ssh_runner.go:102] Run: sudo test -f /etc/ssl/certs/b5213941.0
                I0110 12:51:30.700616   10292 ssh_runner.go:102] Run: sudo ln -s /etc/ssl/certs/minikubeCA.pem /etc/ssl/certs/b5213941.0
                I0110 12:51:30.711042   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm config images pull --config /var/tmp/minikube/kubeadm.yaml"
                I0110 12:51:30.915182   10292 ssh_runner.go:102] Run: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd
                I0110 12:51:30.924080   10292 kubeadm.go:147] existence check: sudo ls /var/lib/kubelet/kubeadm-flags.env /var/lib/kubelet/config.yaml /var/lib/minikube/etcd: Process exited with status 2
                stdout:
                
                stderr:
                ls: cannot access '/var/lib/kubelet/kubeadm-flags.env': No such file or directory
                ls: cannot access '/var/lib/kubelet/config.yaml': No such file or directory
                ls: cannot access '/var/lib/minikube/etcd': No such file or directory
                I0110 12:51:30.924110   10292 kubeadm.go:150] StartCluster: {KubernetesVersion:v1.17.0 NodeIP:192.168.39.38 NodePort:8443 NodeName:minikube APIServerName:minikubeCA APIServerNames:[] APIServerIPs:[] DNSDomain:cluster.local ContainerRuntime:docker CRISocket: NetworkPlugin:cni FeatureGates:ServerSideApply=true ServiceCIDR:10.96.0.0/12 ImageRepository: ExtraOptions:[{Component:kubelet Key:network-plugin Value:cni} {Component:kubeadm Key:pod-network-cidr Value:192.168.111.111/16}] ShouldLoadCachedImages:true EnableDefaultCNI:false}
                I0110 12:51:30.924189   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap"
                I0110 12:51:31.012469   10292 kubeadm.go:152] StartCluster complete in 88.336973ms
                I0110 12:51:31.012591   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-apiserver --format="{{.ID}}"
                I0110 12:51:31.060343   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.060371   10292 logs.go:180] No container was found matching "kube-apiserver"
                I0110 12:51:31.060426   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_coredns --format="{{.ID}}"
                I0110 12:51:31.118095   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.118159   10292 logs.go:180] No container was found matching "coredns"
                I0110 12:51:31.118232   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-scheduler --format="{{.ID}}"
                I0110 12:51:31.177628   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.177662   10292 logs.go:180] No container was found matching "kube-scheduler"
                I0110 12:51:31.177735   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-proxy --format="{{.ID}}"
                I0110 12:51:31.241021   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.241059   10292 logs.go:180] No container was found matching "kube-proxy"
                I0110 12:51:31.241170   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-addon-manager --format="{{.ID}}"
                I0110 12:51:31.289684   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.289721   10292 logs.go:180] No container was found matching "kube-addon-manager"
                I0110 12:51:31.289794   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kubernetes-dashboard --format="{{.ID}}"
                I0110 12:51:31.335633   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.335663   10292 logs.go:180] No container was found matching "kubernetes-dashboard"
                I0110 12:51:31.335728   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_storage-provisioner --format="{{.ID}}"
                I0110 12:51:31.382218   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.382299   10292 logs.go:180] No container was found matching "storage-provisioner"
                I0110 12:51:31.382379   10292 ssh_runner.go:102] Run: docker ps -a --filter=name=k8s_kube-controller-manager --format="{{.ID}}"
                I0110 12:51:31.425976   10292 logs.go:178] 0 containers: []
                W0110 12:51:31.426052   10292 logs.go:180] No container was found matching "kube-controller-manager"
                I0110 12:51:31.426091   10292 logs.go:92] Gathering logs for kubelet ...
                I0110 12:51:31.426113   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u kubelet -n 400"
                I0110 12:51:31.440340   10292 logs.go:92] Gathering logs for dmesg ...
                I0110 12:51:31.440382   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo dmesg -PH -L=never --level warn,err,crit,alert,emerg | tail -n 400"
                I0110 12:51:31.457554   10292 logs.go:92] Gathering logs for Docker ...
                I0110 12:51:31.457585   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo journalctl -u docker -n 400"
                I0110 12:51:31.488245   10292 logs.go:92] Gathering logs for container status ...
                I0110 12:51:31.488302   10292 ssh_runner.go:102] Run: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a"
                I0110 12:51:33.663946   10292 ssh_runner.go:142] Completed: /bin/bash -c "sudo crictl ps -a || sudo docker ps -a": (2.175613588s)
                W0110 12:51:33.664117   10292 exit.go:101] Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:51:31.012879    2864 strict.go:54] error unmarshaling configuration schema.GroupVersionKind{Group:"kubeadm.k8s.io", Version:"v1beta2", Kind:"ClusterConfiguration"}: error converting YAML to JSON: yaml: unmarshal errors:
                  line 16: key "controllerManager" already set in map
                W0110 12:51:31.014184    2864 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                * 
                X Error starting cluster: init failed. cmd: "/bin/bash -c \"sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap\"": /bin/bash -c "sudo env PATH=/var/lib/minikube/binaries/v1.17.0:$PATH kubeadm init --config /var/tmp/minikube/kubeadm.yaml  --ignore-preflight-errors=DirAvailable--etc-kubernetes-manifests,DirAvailable--var-lib-minikube,DirAvailable--var-lib-minikube-etcd,FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml,FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml,FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml,FileAvailable--etc-kubernetes-manifests-etcd.yaml,Port-10250,Swap": Process exited with status 1
                stdout:
                
                stderr:
                W0110 12:51:31.012879    2864 strict.go:54] error unmarshaling configuration schema.GroupVersionKind{Group:"kubeadm.k8s.io", Version:"v1beta2", Kind:"ClusterConfiguration"}: error converting YAML to JSON: yaml: unmarshal errors:
                  line 16: key "controllerManager" already set in map
                W0110 12:51:31.014184    2864 strict.go:47] unknown configuration schema.GroupVersionKind{Group:"kubelet.config.k8s.io", Version:"v1beta2", Kind:"KubeletConfiguration"} for scheme definitions in "k8s.io/kubernetes/cmd/kubeadm/app/apis/kubeadm/scheme/scheme.go:31" and "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                no kind "KubeletConfiguration" is registered for version "kubelet.config.k8s.io/v1beta2" in scheme "k8s.io/kubernetes/cmd/kubeadm/app/componentconfigs/scheme.go:28"
                To see the stack trace of this error execute with --v=5 or higher
                
                * 
                * minikube is exiting due to an error. If the above message is not useful, open an issue:
                  - https://github.com/kubernetes/minikube/issues/new/choose
                
                ** /stderr **
            start_stop_delete_test.go:97: [out/minikube-linux-amd64 start -p newest-cni-20200110T124845.195538591-4968 --alsologtostderr -v=3 --wait=true --feature-gates ServerSideApply=true --network-plugin=cni --extra-config=kubelet.network-plugin=cni --extra-config=kubeadm.pod-network-cidr=192.168.111.111/16 --vm-driver=kvm2  --kubernetes-version=v1.17.0] failed: exit status 70
            panic.go:563: *** TestStartStop/group/newest-cni FAILED at 2020-01-10 12:51:33.667093535 +0000 UTC m=+1114.312112361
            panic.go:563: >>> TestStartStop/group/newest-cni FAILED: start of post-mortem logs >>>
            panic.go:563: (dbg) Run:  kubectl --context newest-cni-20200110T124845.195538591-4968 get po -A --show-labels
            panic.go:563: (dbg) Non-zero exit: kubectl --context newest-cni-20200110T124845.195538591-4968 get po -A --show-labels: exit status 1 (3.174096332s)
                
                ** stderr ** 
                The connection to the server 192.168.39.38:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context newest-cni-20200110T124845.195538591-4968 get po -A --show-labels: exit status 1
            panic.go:563: (dbg) kubectl --context newest-cni-20200110T124845.195538591-4968 get po -A --show-labels:
            panic.go:563: (dbg) Run:  kubectl --context newest-cni-20200110T124845.195538591-4968 describe node
            panic.go:563: (dbg) Non-zero exit: kubectl --context newest-cni-20200110T124845.195538591-4968 describe node: exit status 1 (420.941415ms)
                
                ** stderr ** 
                The connection to the server 192.168.39.38:8443 was refused - did you specify the right host or port?
                
                ** /stderr **
            panic.go:563: kubectl --context newest-cni-20200110T124845.195538591-4968 describe node: exit status 1
            panic.go:563: (dbg) Run:  out/minikube-linux-amd64 -p newest-cni-20200110T124845.195538591-4968 logs --problems
            panic.go:563: (dbg) Done: out/minikube-linux-amd64 -p newest-cni-20200110T124845.195538591-4968 logs --problems: (3.090136812s)
            panic.go:563: TestStartStop/group/newest-cni logs: 
            panic.go:563: <<< TestStartStop/group/newest-cni FAILED: end of post-mortem logs <<<
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p newest-cni-20200110T124845.195538591-4968
            helpers.go:167: (dbg) Done: out/minikube-linux-amd64 delete -p newest-cni-20200110T124845.195538591-4968: (1.252146577s)
        --- PASS: TestStartStop/group/old-docker (549.74s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:47:05.195248657 +0000 UTC m=+845.840267405 (sleeping 2m29.999442303s)  ...
            start_stop_delete_test.go:94: (dbg) Run:  out/minikube-linux-amd64 start -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3 --wait=true --kvm-network=default --kvm-qemu-uri=qemu:///system --disable-driver-mounts --keep-context=false --container-runtime=docker --vm-driver=kvm2  --kubernetes-version=v1.11.10
            start_stop_delete_test.go:94: (dbg) Done: out/minikube-linux-amd64 start -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3 --wait=true --kvm-network=default --kvm-qemu-uri=qemu:///system --disable-driver-mounts --keep-context=false --container-runtime=docker --vm-driver=kvm2  --kubernetes-version=v1.11.10: (3m27.138582391s)
            start_stop_delete_test.go:105: (dbg) Run:  kubectl --context old-docker-20200110T124705.195460521-4968 create -f testdata/busybox.yaml
            start_stop_delete_test.go:105: (dbg) Done: kubectl --context old-docker-20200110T124705.195460521-4968 create -f testdata/busybox.yaml: (5.193929779s)
            start_stop_delete_test.go:111: (dbg) TestStartStop/group/old-docker: waiting 8m0s for pods matching "integration-test=busybox" in namespace "default" ...
            helpers.go:268: "busybox" [cca1bc96-33a7-11ea-9cd0-b87347121001] Pending
            helpers.go:268: "busybox" [cca1bc96-33a7-11ea-9cd0-b87347121001] Pending / Ready:ContainersNotReady (containers with unready status: [busybox]) / ContainersReady:ContainersNotReady (containers with unready status: [busybox])
            helpers.go:268: "busybox" [cca1bc96-33a7-11ea-9cd0-b87347121001] Running
            start_stop_delete_test.go:111: (dbg) TestStartStop/group/old-docker: integration-test=busybox healthy within 18.294200468s
            start_stop_delete_test.go:117: (dbg) Run:  kubectl --context old-docker-20200110T124705.195460521-4968 exec busybox -- /bin/sh -c "ulimit -n"
            start_stop_delete_test.go:117: (dbg) Done: kubectl --context old-docker-20200110T124705.195460521-4968 exec busybox -- /bin/sh -c "ulimit -n": (8.028851547s)
            start_stop_delete_test.go:134: (dbg) Run:  out/minikube-linux-amd64 stop -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3
            start_stop_delete_test.go:134: (dbg) Done: out/minikube-linux-amd64 stop -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3: (18.507163127s)
            start_stop_delete_test.go:139: (dbg) Run:  out/minikube-linux-amd64 status --format={{.Host}} -p old-docker-20200110T124705.195460521-4968
            start_stop_delete_test.go:139: (dbg) Non-zero exit: out/minikube-linux-amd64 status --format={{.Host}} -p old-docker-20200110T124705.195460521-4968: exit status 1 (125.509145ms)
                -- stdout --
                Stopped
                -- /stdout --
            start_stop_delete_test.go:139: status error: exit status 1 (may be ok)
            helpers.go:376: No need to wait for start slot, it is already 2020-01-10 12:51:22.514199892 +0000 UTC m=+1103.159218669
            start_stop_delete_test.go:145: (dbg) Run:  out/minikube-linux-amd64 start -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3 --wait=true --kvm-network=default --kvm-qemu-uri=qemu:///system --disable-driver-mounts --keep-context=false --container-runtime=docker --vm-driver=kvm2  --kubernetes-version=v1.11.10
            start_stop_delete_test.go:145: (dbg) Done: out/minikube-linux-amd64 start -p old-docker-20200110T124705.195460521-4968 --alsologtostderr -v=3 --wait=true --kvm-network=default --kvm-qemu-uri=qemu:///system --disable-driver-mounts --keep-context=false --container-runtime=docker --vm-driver=kvm2  --kubernetes-version=v1.11.10: (2m15.214563197s)
            start_stop_delete_test.go:153: (dbg) Run:  out/minikube-linux-amd64 ssh -p old-docker-20200110T124705.195460521-4968 "sudo crictl images -o json"
            start_stop_delete_test.go:153: (dbg) Done: out/minikube-linux-amd64 ssh -p old-docker-20200110T124705.195460521-4968 "sudo crictl images -o json": (1.038314843s)
            start_stop_delete_test.go:171: Found non-minikube image: busybox:1.28.4-glibc
            start_stop_delete_test.go:171: Found non-minikube image: busybox:latest
            start_stop_delete_test.go:171: Found non-minikube image: k8s.gcr.io/pause:latest
            start_stop_delete_test.go:188: (dbg) TestStartStop/group/old-docker: waiting 4m0s for pods matching "integration-test=busybox" in namespace "default" ...
            helpers.go:268: "busybox" [cca1bc96-33a7-11ea-9cd0-b87347121001] Running / Ready:ContainersNotReady (containers with unready status: [busybox]) / ContainersReady:ContainersNotReady (containers with unready status: [busybox])
            helpers.go:268: "busybox" [cca1bc96-33a7-11ea-9cd0-b87347121001] Running
            start_stop_delete_test.go:188: (dbg) TestStartStop/group/old-docker: integration-test=busybox healthy within 5.035865907s
            start_stop_delete_test.go:192: (dbg) Run:  out/minikube-linux-amd64 status --format={{.Host}} -p old-docker-20200110T124705.195460521-4968
            start_stop_delete_test.go:199: (dbg) Run:  out/minikube-linux-amd64 delete -p old-docker-20200110T124705.195460521-4968
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p old-docker-20200110T124705.195460521-4968
        --- PASS: TestStartStop/group/crio (820.99s)
            helpers.go:373: Waiting for start slot at 2020-01-10 12:49:35.195248657 +0000 UTC m=+995.840267405 (sleeping 4m59.999060007s)  ...
            start_stop_delete_test.go:94: (dbg) Run:  out/minikube-linux-amd64 start -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3 --wait=true --container-runtime=crio --disable-driver-mounts --extra-config=kubeadm.ignore-preflight-errors=SystemVerification --vm-driver=kvm2  --kubernetes-version=v1.15.0
            start_stop_delete_test.go:94: (dbg) Done: out/minikube-linux-amd64 start -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3 --wait=true --container-runtime=crio --disable-driver-mounts --extra-config=kubeadm.ignore-preflight-errors=SystemVerification --vm-driver=kvm2  --kubernetes-version=v1.15.0: (3m52.170946572s)
            start_stop_delete_test.go:105: (dbg) Run:  kubectl --context crio-20200110T124935.195473411-4968 create -f testdata/busybox.yaml
            start_stop_delete_test.go:105: (dbg) Done: kubectl --context crio-20200110T124935.195473411-4968 create -f testdata/busybox.yaml: (1.799473993s)
            start_stop_delete_test.go:111: (dbg) TestStartStop/group/crio: waiting 8m0s for pods matching "integration-test=busybox" in namespace "default" ...
            helpers.go:268: "busybox" [43ec03a4-40db-436d-9c39-9c7826c2a5e0] Pending
            helpers.go:268: "busybox" [43ec03a4-40db-436d-9c39-9c7826c2a5e0] Pending / Ready:ContainersNotReady (containers with unready status: [busybox]) / ContainersReady:ContainersNotReady (containers with unready status: [busybox])
            helpers.go:268: "busybox" [43ec03a4-40db-436d-9c39-9c7826c2a5e0] Running
            start_stop_delete_test.go:111: (dbg) TestStartStop/group/crio: integration-test=busybox healthy within 16.125990064s
            start_stop_delete_test.go:117: (dbg) Run:  kubectl --context crio-20200110T124935.195473411-4968 exec busybox -- /bin/sh -c "ulimit -n"
            start_stop_delete_test.go:117: (dbg) Done: kubectl --context crio-20200110T124935.195473411-4968 exec busybox -- /bin/sh -c "ulimit -n": (1.265853257s)
            start_stop_delete_test.go:134: (dbg) Run:  out/minikube-linux-amd64 stop -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3
            start_stop_delete_test.go:134: (dbg) Done: out/minikube-linux-amd64 stop -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3: (1m35.054381087s)
            start_stop_delete_test.go:139: (dbg) Run:  out/minikube-linux-amd64 status --format={{.Host}} -p crio-20200110T124935.195473411-4968
            start_stop_delete_test.go:139: (dbg) Non-zero exit: out/minikube-linux-amd64 status --format={{.Host}} -p crio-20200110T124935.195473411-4968: exit status 1 (66.326942ms)
                -- stdout --
                Stopped
                -- /stdout --
            start_stop_delete_test.go:139: status error: exit status 1 (may be ok)
            helpers.go:376: No need to wait for start slot, it is already 2020-01-10 12:55:21.685692855 +0000 UTC m=+1342.330711613
            start_stop_delete_test.go:145: (dbg) Run:  out/minikube-linux-amd64 start -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3 --wait=true --container-runtime=crio --disable-driver-mounts --extra-config=kubeadm.ignore-preflight-errors=SystemVerification --vm-driver=kvm2  --kubernetes-version=v1.15.0
            start_stop_delete_test.go:145: (dbg) Done: out/minikube-linux-amd64 start -p crio-20200110T124935.195473411-4968 --alsologtostderr -v=3 --wait=true --container-runtime=crio --disable-driver-mounts --extra-config=kubeadm.ignore-preflight-errors=SystemVerification --vm-driver=kvm2  --kubernetes-version=v1.15.0: (2m25.306776997s)
            start_stop_delete_test.go:153: (dbg) Run:  out/minikube-linux-amd64 ssh -p crio-20200110T124935.195473411-4968 "sudo crictl images -o json"
            start_stop_delete_test.go:171: Found non-minikube image: docker.io/library/busybox:latest
            start_stop_delete_test.go:171: Found non-minikube image: k8s.gcr.io/pause:latest
            start_stop_delete_test.go:188: (dbg) TestStartStop/group/crio: waiting 4m0s for pods matching "integration-test=busybox" in namespace "default" ...
            helpers.go:268: "busybox" [43ec03a4-40db-436d-9c39-9c7826c2a5e0] Pending / Ready:ContainersNotReady (containers with unready status: [busybox]) / ContainersReady:ContainersNotReady (containers with unready status: [busybox])
            helpers.go:268: "busybox" [43ec03a4-40db-436d-9c39-9c7826c2a5e0] Running
            start_stop_delete_test.go:188: (dbg) TestStartStop/group/crio: integration-test=busybox healthy within 27.026206855s
            start_stop_delete_test.go:192: (dbg) Run:  out/minikube-linux-amd64 status --format={{.Host}} -p crio-20200110T124935.195473411-4968
            start_stop_delete_test.go:199: (dbg) Run:  out/minikube-linux-amd64 delete -p crio-20200110T124935.195473411-4968
            start_stop_delete_test.go:199: (dbg) Done: out/minikube-linux-amd64 delete -p crio-20200110T124935.195473411-4968: (1.208470146s)
            helpers.go:167: (dbg) Run:  out/minikube-linux-amd64 delete -p crio-20200110T124935.195473411-4968
FAIL
++ result=1
++ set +x
>> out/e2e-linux-amd64 exited with 1 at Fri Jan 10 12:58:16 UTC 2020

minikube: FAIL
>> Copying /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/testout.txt to gs://minikube-builds/logs/6150/KVM_Linuxout.txt
>> Attmpting to convert test logs to json
>> Running go test2json
>> Installing gopogh
go: finding github.com v0.0.17
go: finding github.com/medyagh v0.0.17
>> Running gopogh
completed with 23 / 46 failures in 25.28 minute(s).
>> uploading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/test.json
>> uploading /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25/test.html
>> Cleaning up after ourselves ...
>> /home/jenkins/minikube-integration/linux-amd64-kvm2-6150-2538-805f1177654a78e5b257bfb7a86bac15b7f86a25 completed at Fri Jan 10 12:58:36 UTC 2020
Build step 'Execute shell' marked build as failure
